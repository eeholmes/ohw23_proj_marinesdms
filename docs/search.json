[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "2023 Ocean Hackweek",
    "section": "",
    "text": "Click to hear our song! Inspired by Myranda and AI!\n\n\n\n\n\n\n\nThis tutorial was developed during OceanHackWeek2023 to provide a simple workflow to developing a marine Species Distribution Model (SDM) using R programming.\n\n\n\nSpecies Distribution Models are used to predict a species’ geographic and environmental range, typically incorporating environmental data into the analysis.\n\n\n\nMany tutorials exist to run SDM models, however most readily available tutorials focus on terrestrial-based models. Our goal through this tutorial is to highlight a marine-based SDM tutorial.\n\n\n\nBiological Data\nOur dataset includes biological presence-only data of four species of sea turtles found in the Indian Ocean. The presence dataset includes four species of sea turtles:\n\nLoggerhead, Caretta caretta\nGreen, Chelonia mydas\nOlive Ridley, Lepidochelys olivacea\nHawksbill, Eretmochelys imbricata\n\nHowever, for this tutorial example model, we will focus on Loggerhead sea turtles data from 2000 until 2023 sourced from the Ocean Biodiversity Information System (OBIS) via the robis package.\nEnvironmental Data\nThis tutorial focuses on regions in the northern Indian Sea, specifically the western Arabian Sea, Persian Gulf, Gulf of Oman, Gulf of Aden and Red Sea. Environmental predictor variables were sourced via the SMDpredictor R package and includes:\n-ENTER ALL FINAL PREDICTORS INCLUDED HERE\n\npaulo working on background–link to\n\n\n\n\nThis tutorial is based on the notes by Ben Tupper (Biglow Lab, Maine), and highlights modeling presence-only data via maxnet R package.\nTutorial roadmap\n\nPresence Data – obtain sea turtle data via robis\nAbsence Data – obtain random occurances within our area of interest using robis\nEnvironmental Data – obtain environmental predictors of interest using SDMpredictors\nModel – run species distribution model and predict using maxnet\nData Visualizations\n\n\n\n\n\nBosch S, Fernandez S (2022). sdmpredictors: Species Distribution Modelling Predictor Datasets. R package version 0.2.14, http://lifewatch.github.io/sdmpredictors/.\nOBIS (2023) Ocean Biodiversity Information System. Intergovernmental Oceanographic Commission of UNESCO. www.obis.org. Accessed: 2023-08-08.\nSteven J. Phillips, Miroslav Dudík, Robert E. Schapire. [Internet] Maxent software for modeling species niches and distributions (Version 3.4.1). Available from url: http://biodiversityinformatics.amnh.org/open_source/maxent/. Accessed on 2023-8-10.\n\n\n\n\n\nCatherine Courtier:\nMackenzie Fiss: Third-year PhD student at Northeastern University studying marine biogeochemistry (DOM) and microbial ecology.\nDenisse Fierro Arcos: PhD candidate at the Institute for Marine and Antarctic Studies (IMAS) and Data Officer at the Integrated Marine Observing System (IMOS)\n\nPaulo Freire: PhD candidate at the University of North Carolina at Charlotte (UNCC) studying marine microbial ecology.\nEli Holmes: Research Fisheries Biologist, Northwest Fisheries Science Center, NOAA Fisheries.\n\nJade Hong:\nTylar Murray: USF IMaRS Software Engineer - code whisperer, data viz enthusiast, scientific generalist, compulsive overengineerer, & UX PhD\n\nCaitlin O’Brien: Research Scientist, Columbia Basin Research, School of Aquatic Fishery and Sciences, University of Washington\n[Collins Ongore] ()\nMary Solokas: John A. Knauss Marine Policy Fellow, National Oceanic and Atmospheric Administration\nLaura Tsang:\nBen Tupper:\n\n\n\n\n\nSome experience programming in R is needed to make the most of this tutorial. To run this tutorial make sure you clone this repository into your local machine by creating a new project that uses version control (git).\nThe tutorial content was developed in a R version 4.2.2 for Linux. Full session information is included below:\nR version 4.2.2 (2022-10-31)\nPlatform: x86_64-conda-linux-gnu (64-bit)\nRunning under: Debian GNU/Linux 11 (bullseye)\n\nMatrix products: default\nBLAS/LAPACK: /opt/conda/lib/libopenblasp-r0.3.21.so\n\nlocale:\n [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8       \n [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8   \n [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C          \n[10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C   \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n[1] compiler_4.2.2 tools_4.2.2   \n\n\n\nIf you need additional support with R programming, you can check the following resources:\n- R for Data Science - 2nd edition by Wickham, Çetinkaya-Rundel and Grolemund.\n- Data analysis and visualisation in R for ecologists\nFor information on how to use git and GitHub with R, Happy Git and GitHub for the useR by Jenny Bryan is a great resource."
  },
  {
    "objectID": "individual-folders/Mackenzie/actual_SDM_attempt_MF.html",
    "href": "individual-folders/Mackenzie/actual_SDM_attempt_MF.html",
    "title": "Maxent SDM attempt",
    "section": "",
    "text": "You will need to install a new version of maxnet.\n\ndevtools::install_github(“BigelowLab/maxnet”)\n\n\nsuppressPackageStartupMessages(\n  {library(maxnet)\n  library(dplyr)\n  library(maxnet)\n  library(sf)\n  library(stars)\n  library(geodata)\n  library(dismo)\n  library(lubridate)\n  library(sdmpredictors)\n  library(zoon)\n  library(ggplot2)\n  library(cmocean)\n  library(janitor)\n  library(DT)\n})\n\n\n\n\n\npts.abs <- read.csv(\"/home/jovyan/R/ohw23_proj_marinesdms/data/raw-bio/pts_absence.csv\") # X is lon and Y is lat\n\nio.turtles <- read.csv(\"/home/jovyan/R/ohw23_proj_marinesdms/data/raw-bio/io-sea-turtles.csv\") \n\n\n\n\n\nspp <- c(\"Chelonia mydas\", \"Caretta caretta\", \"Eretmochelys imbricata\", \"Lepidochelys olivacea\", \"Natator depressus\", \"Dermochelys coriacea\") # turtle species we're interested in\n\nocc <- io.turtles %>% \n  subset(scientificName == spp) # subsetting all the occurence data to just those turtles \n\nWarning in scientificName == spp: longer object length is not a multiple of\nshorter object length\n\ntable(occ$scientificName) # seeing how often each species occurs\n\n\n       Caretta caretta         Chelonia mydas Eretmochelys imbricata \n                   891                   1307                     36 \n Lepidochelys olivacea \n                     9 \n\nocc <- occ %>% # but we also need to subset the occurences to include just those in the water (not the ones on land)\n  subset(bathymetry > 0 & \n                        shoredistance > 0 & \n                        coordinateUncertaintyInMeters < 200)\n\ntable(occ$scientificName) # seeing how often each species occurs now\n\n\nCaretta caretta  Chelonia mydas \n            874            1190 \n\n# Caretta caretta is Loggerhead and Chelonia mydas is Green sea turtles \n\nocc.sub <- occ[,c(2,4,5,6,9,11,13,14)] # choosing the cols I want\n\nocc.sub$eventDate <- lubridate::ymd_hms(occ.sub$eventDate) # changing to datetime format\n\ncolnames(occ.sub) <- c(\"sci.name\", \"obsv.datetime\", \"lat\", \"lon\", \"life.stage\", \"bathy\", \"SST\", \"SSS\") # renaming\n\n\n# format background/absence points\n\ncolnames(pts.abs) <- c(\"lon\",\"lat\")\npts.abs <- na.omit(pts.abs)\n\nabs.points <- sf::st_as_sf(pts.abs, coords = c(\"lon\", \"lat\"), crs = 4326)\n\n\n# format prescence/occurrence points\n\nocc.points <- sf::st_as_sf(occ.sub, coords = c(\"lon\", \"lat\"), crs = 4326)\nocc.points\n\nSimple feature collection with 2064 features and 6 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 43.07691 ymin: -0.1103 xmax: 64.78089 ymax: 26.781\nGeodetic CRS:  WGS 84\nFirst 10 features:\n          sci.name       obsv.datetime life.stage bathy   SST   SSS\n2  Caretta caretta 2011-04-12 19:12:41   Juvenile  3051 28.67 35.74\n7   Chelonia mydas 2018-03-31 06:44:00       <NA>    14 27.96 38.71\n13  Chelonia mydas 2019-05-28 12:15:00       <NA>     2 27.93 38.65\n14 Caretta caretta 2011-04-11 04:03:19   Juvenile  2736 26.92 36.10\n20 Caretta caretta 2011-03-24 14:33:23   Juvenile  2030 26.68 36.05\n25  Chelonia mydas 2018-04-05 23:33:00       <NA>     2 27.94 38.67\n37  Chelonia mydas 2017-04-30 13:38:00       <NA>     4 27.95 38.57\n43  Chelonia mydas 2016-08-12 03:05:00       <NA>     4    NA    NA\n61  Chelonia mydas 2018-03-26 06:48:00       <NA>     2 27.93 38.65\n62 Caretta caretta 2012-05-16 13:17:12   Juvenile  2833 26.88 36.10\n                    geometry\n2   POINT (59.87883 6.40193)\n7      POINT (53.201 24.508)\n13     POINT (53.083 24.577)\n14 POINT (54.28696 16.05778)\n20 POINT (53.83602 16.52469)\n25     POINT (53.092 24.549)\n37     POINT (52.949 24.367)\n43     POINT (55.837 25.743)\n61     POINT (53.044 24.574)\n62 POINT (54.71895 16.09641)\n\nocc.points <- occ.points %>% \n  mutate(common.name = case_when(sci.name == \"Caretta caretta\" ~ \"Loggerhead\",\n                                 sci.name == \"Chelonia mydas\" ~ \"Green\"))\n\n\n\n\nLoading in\n\ndatasets <- sdmpredictors::list_datasets(terrestrial = FALSE, marine = TRUE)\n\nlayers <- list_layers(datasets)\n#View(layers)\n\nChoosing and formatting\n\n#layercodes <- c(\"BO_sstmean\", \"BO_bathymin\", \"BO_bathymax\", \"BO_bathymean\", \"BO2_chlomax_bdmean\", \"BO2_dissoxmin_bdmean\", \"BO2_dissoxmean_bdmean\", \"BO2_dissoxrange_bdmean\", \"BO2_nitratemean_bdmean\", \"BO2_phosphatemean_bdmean\", \"BO2_tempmean_bdmean\", \"BO2_temprange_bdmean\", \"BO2_salinitymean_bdmean\", \"BO2_salinityrange_bdmean\", \"BO2_tempmean_ss\", \"BO2_temprange_ss\", \"BO2_chlomean_ss\") # my first go around with lots of env variables (hint this takes FORever)\n\nlayercodes = c(\"BO_sstmean\", \"BO_bathymean\", \"BO22_ph\", \"BO2_dissoxmean_bdmean\", \"BO2_salinitymean_ss\") # the env variables I chose from SDMpredictors\n\nenv <- load_layers(layercodes, rasterstack = T) # take out the equalarea arg or you will be sad AND add rasterstack = T\n\nWarning in get_datadir(datadir): file.path(tempdir(), \"sdmpredictors\") will be\nused as datadir, set options(sdmpredictors_datadir=\"<directory>\") to avoid\nre-downloading the data in every session or set the datadir parameter in\nload_layers\n\nenv.stars <- stars::st_as_stars(env) # convert to stars object\nenv.stars <- split(env.stars)\n\nlats <- c(-0.125, 32.125); lons <- c(41.875, 70.125) # IO lat/lon range\n# raster extent is defined by west lon, east lon, south lat, north lat\n\next <- raster::extent(lons[1], lons[2], lats[1], lats[2])\nextent_polygon <- as(ext, \"SpatialPolygons\") %>% \n  st_as_sf()\n# we need to assign a coordinate system; 4326 is the default for maps in sf\nsf::st_crs(extent_polygon) <- 4326 # applying a coordinate system\n\nplot(extent_polygon) # look a rectangle\n\n\n\nbb <- sf::st_bbox(extent_polygon) # make a bounding box (that maybe isn't what we need?)\nplot(env.stars[\"BO_bathymean\"] %>% sf::st_crop(bb)) # looking at bathymetry\n\n\n\nenv.obs <- stars::st_extract(env.stars,\n                             sf::st_coordinates(occ.points)) %>%\n  dplyr::as_tibble()\n\nio.rast <- raster::crop(env, extent(extent_polygon))\nplot(io.rast) # look NOT a rectangle- your env variables cropped to the Indian Ocean!\n\n\n\n\n\n\n\n\nenv.back <- stars::st_extract(env.stars, sf::st_coordinates(abs.points)) %>% \n  dplyr::as_tibble() %>% \n  na.omit()\nenv.back\n\n# A tibble: 992 × 5\n   BO_sstmean BO_bathymean BO22_ph BO2_dissoxmean_bdmean BO2_salinitymean_ss\n        <dbl>        <dbl>   <dbl>                 <dbl>               <dbl>\n 1       28.4        -2445    8.16                 111.                 36.2\n 2       26.9        -3142    8.12                 119.                 36.5\n 3       28.3        -4549    8.19                 159.                 36.0\n 4       27.1        -4970    8.17                 180.                 35.5\n 5       26.8        -3869    8.16                 156.                 36.0\n 6       28.0        -5095    8.17                 183.                 35.4\n 7       27.0        -4201    8.16                 151.                 36.1\n 8       27.2        -3998    8.15                 147.                 36.3\n 9       27.2        -4501    8.17                 182.                 35.3\n10       28.5        -1976    8.16                  62.6                36.3\n# … with 982 more rows\n\n\n\n\n\n\npoly <- occ.points %>%                                 # start with obs\n  sf::st_combine() %>%                          # combine into a single multipoint\n  sf::st_convex_hull() %>%                      # find convex hull\n  sf::st_transform(crs = sf::st_crs(5880)) %>%  # make planar\n  #sf::st_buffer(dist = 200000) |>             # buffer by 200000m\n  sf::st_transform(crs = sf::st_crs(4326))    # make spherical"
  },
  {
    "objectID": "individual-folders/Mackenzie/actual_SDM_attempt_MF.html#sdm-model",
    "href": "individual-folders/Mackenzie/actual_SDM_attempt_MF.html#sdm-model",
    "title": "Maxent SDM attempt",
    "section": "SDM Model",
    "text": "SDM Model\n\nRunning model\n\nenv.obs <- na.omit(env.obs); env.back <- na.omit(env.back) # remove NA values\n\npres <- c(rep(1, nrow(env.obs)), rep(0, nrow(env.back))) # create values of 1 for presence data and 0 for absence data\n\nsdm.model <- maxnet::maxnet(pres, rbind(env.obs, env.back))\n\n\n\nModel metrics\n\nresponses <- plot(sdm.model, type = \"cloglog\")"
  },
  {
    "objectID": "individual-folders/Mackenzie/actual_SDM_attempt_MF.html#predicting",
    "href": "individual-folders/Mackenzie/actual_SDM_attempt_MF.html#predicting",
    "title": "Maxent SDM attempt",
    "section": "Predicting",
    "text": "Predicting\n\nclamp <- TRUE       # see ?predict.maxnet for details\ntype <- \"cloglog\"\npredicted <- predict(sdm.model, env.stars %>% sf::st_crop(bb), clamp = clamp, type = type)\npredicted\n\nstars object with 2 dimensions and 1 attribute\nattribute(s):\n             Min.   1st Qu.    Median      Mean   3rd Qu.      Max.  NA's\npred  0.004106452 0.1069494 0.1595567 0.1780556 0.2291356 0.9997764 58655\ndimension(s):\n  from   to offset      delta                       refsys point values x/y\nx 2663 3002   -180  0.0833333 +proj=longlat +datum=WGS8...    NA   NULL [x]\ny  695 1082     90 -0.0833333 +proj=longlat +datum=WGS8...    NA   NULL [y]"
  },
  {
    "objectID": "individual-folders/Mackenzie/actual_SDM_attempt_MF.html#visualization",
    "href": "individual-folders/Mackenzie/actual_SDM_attempt_MF.html#visualization",
    "title": "Maxent SDM attempt",
    "section": "Visualization",
    "text": "Visualization\n\n# ggplot - with occurrence data points\n\nggplot() +\n  geom_stars(data = predicted) +\n  scale_fill_cmocean(name = \"ice\", direction = -1, guide = guide_colorbar(barwidth = 1, barheight = 10, ticks = FALSE, nbin = 1000, frame.colour = \"black\"), limits = c(0, 1)) +\n  theme_linedraw() +\n  theme(panel.background = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank()) +\n  labs(title = \"Loggerhead and green sea turtle species distribution model\",\n       x = \"Longitude\",\n       y = \"Latitude\",\n       fill = \"Probability\",\n       shape = \"Species (presence)\",\n       subtitle = \"Environmental predictors: mean SS temp, mean SS salinity, mean bathymetry, mean pH, mean DO\") +\n  geom_point(occ.points, mapping = aes(shape = common.name, geometry = geometry), stat = \"sf_coordinates\", alpha = 0.3, color = \"purple\") +\n  #scale_x_continuous(breaks = seq(40, 70, 10), limits = c(42, 70))+\n  scale_y_continuous(breaks = seq(0, 30, 10))\n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data\n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data\n\n\n\n\nggsave(\"SDM_loggerhead_green_w points.pdf\", height = 6, width = 8.5)\n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data\n\nWarning in st_point_on_surface.sfc(sf::st_zm(x)): st_point_on_surface may not\ngive correct results for longitude/latitude data\n\n  #+\n#  geom_point(abs.points, mapping = aes(geometry = geometry), stat = \"sf_coordinates\", alpha = 0.7, color = \"gray\")\n\n\n# ggplot - without occurrence data points\n\nggplot() +\n  geom_stars(data = predicted) +\n  scale_fill_cmocean(name = \"ice\", direction = -1, guide = guide_colorbar(barwidth = 1, barheight = 10, ticks = FALSE, nbin = 1000, frame.colour = \"black\"), limits = c(0, 1)) +\n  theme_linedraw() +\n  theme(panel.background = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank()) +\n  labs(title = \"Loggerhead and green sea turtle species distribution model\",\n       x = \"Longitude\",\n       y = \"Latitude\",\n       fill = \"Probability\",\n       shape = \"Species (presence)\",\n       subtitle = \"Environmental predictors: mean SS temp, mean SS salinity, mean bathymetry, mean pH, mean DO\") +\n  #geom_point(occ.points, mapping = aes(shape = common.name, geometry = geometry), stat = \"sf_coordinates\", alpha = 0.3, color = \"purple\") +\n  #scale_x_continuous(breaks = seq(40, 70, 10), limits = c(42, 70))+\n  scale_y_continuous(breaks = seq(0, 30, 10))\n\n\n\nggsave(\"SDM_loggerhead_green.pdf\", height = 6, width = 8.5)\n\n\n# base R\n\nplot(predicted, reset = F, main = \"Loggerhead and green sea turtle SDM\") # predicted model\nplot(occ.points, col = \"cyan\", add = TRUE, cex = 0.6, pch = 20) # occurrence points\n\nWarning in plot.sf(occ.points, col = \"cyan\", add = TRUE, cex = 0.6, pch = 20):\nignoring all but the first attribute\n\nplot(st_geometry(abs.points), add = T, cex = 0.6, col = \"green\", pch = 20, alpha = 0.2) # absence points\n\n\n\n# legend(x = \"topleft\", legend = c(\"presence\", \"absence\"), col = c(\"cyan\",\"green\"))"
  },
  {
    "objectID": "tutorial/Get_seaturtle_data.html",
    "href": "tutorial/Get_seaturtle_data.html",
    "title": "Exploring OBIS sea turtle observations",
    "section": "",
    "text": "In this section, we will explore Loggerhead sea turtle (Caretta caretta) data from 2000 until present from the Ocean Biodiversity Information System (OBIS). We will use the robis package to search the OBIS library and download relevant data. We will then check for quality control flags and remove problematic observations from the data (i.e., sea turtle observations on land)."
  },
  {
    "objectID": "tutorial/Get_seaturtle_data.html#explore-obis-results",
    "href": "tutorial/Get_seaturtle_data.html#explore-obis-results",
    "title": "Exploring OBIS sea turtle observations",
    "section": "Explore OBIS results",
    "text": "Explore OBIS results\nOur search produced 5269 results for the area of our interest. However, before we continue to use this data as input for our species distribution models, we must clean it first to ensure we have a good quality dataset.\nIn this section, we will explore the results of our OBIS search so we can design a data cleaning workflow. We will check the content of some of the columns in our data frame.\nYou may want to refer to the OBIS manual and the OBIS webpage about Data Access.\n\n#Checking values in basis of record column\ncaretta_obs %>% \n  distinct(basisOfRecord)\n\n# A tibble: 2 × 1\n  basisOfRecord     \n  <chr>             \n1 MachineObservation\n2 Occurrence        \n\n\nIn this context, MachineObservation refers to records obtained with satellite tags. While Occurrence refers to records obtained by human observers on the field. These two datasets cannot be treated in the same way as MachineObservation records are not independent as they record the movements of a single individual.\nWe can also check whether or not absence data is available for the loggerhead se a turtles in our area of interest.\n\ncaretta_obs %>% \n  distinct(absence)\n\n# A tibble: 1 × 1\n  absence\n  <lgl>  \n1 FALSE  \n\n\nWe only have presence data available, which is an important factor to consider when designing our species distribution model workflow.\nWe can also check the coordinateUncertaintyInMeters, which gives us an indication of the error associated with a particular record. If we look at the names of the columns printed at the beginning of the script, you may notice that this column has been read as characters. We will change it to numbers before looking at the values in the column.\n\n#Changing column from characters to numeric\ncaretta_obs <- caretta_obs %>% \n  mutate(coordinateUncertaintyInMeters = as.numeric(coordinateUncertaintyInMeters))\n\n#Checking uncertainty values for coordinates\ncaretta_obs %>% \n  distinct(coordinateUncertaintyInMeters)\n\n# A tibble: 3 × 1\n  coordinateUncertaintyInMeters\n                          <dbl>\n1                          0.11\n2                     111319.  \n3                         NA   \n\n\nIt is worth noting that not all providers share a measurement of uncertainty, but we can use this whenever is available to apply some sort of quality control to our data.\nHere, we see that some observations have uncertainty of centimeters (0.11 m), but there are other observations with uncertainty over 100 km. For this example, we will remove these observations with large uncertainties.\n<<<<<<< HEAD ## Quality control flags ======= ## Check quality control flags >>>>>>> e1113d9383b2e57473ce9195a510bd71774ecfda OBIS provides some quality control (QC) flags for each record that may help us identify observations of lower quality. For an explanation of OBIS flags, check this repository.\nFirst, we will check the quality flags included in our results.\n\ncaretta_obs %>% \n  distinct(flags)\n\n# A tibble: 4 × 1\n  flags             \n  <chr>             \n1 NO_DEPTH          \n2 NO_DEPTH,ON_LAND  \n3 DEPTH_EXCEEDS_BATH\n4 <NA>              \n\n\nWe will now plot our dataset on a map and use the information in the flags column to color code the observations. This can help us decide whether we should include or exclude them from further analyses.\n\n#Getting a world base map\nworld <- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\n#Starting a plot\nggplot()+\n  #Adding base layer (world map)\n  geom_sf(data = world)+\n  #Adding sea turtle observations\n  geom_point(data = caretta_obs, \n             #Using coordinates to plot and color based on value in flags column\n             aes(decimalLongitude, decimalLatitude, color = flags))+\n  #Constraining map to original bounding box\n  lims(x = c(st_bbox(extent_polygon)$xmin, st_bbox(extent_polygon)$xmax),\n       y = c(st_bbox(extent_polygon)$ymin, st_bbox(extent_polygon)$ymax))+\n  #Applying theme without background\n  theme_bw()\n\n\n\n\nFrom the plot above, we should consider removing at least some of the observations classified as NO_DEPTH,ON_LAND. This is because loggerhead sea turtles are not present inland. Instead, they are found in temperate and subtropical ocean waters and in sandy beaches.\nSome of these observations appear to be quite close to the shore, so they may have occurred in a sandy beach. We can check the proximity of the observation to the shore using the shoredistance column, which provides the distance to shore in meters.\n\ncaretta_obs %>% \n  filter(flags == \"NO_DEPTH,ON_LAND\") %>% \n  select(shoredistance) %>% \n  arrange(desc(shoredistance))\n\n# A tibble: 25 × 1\n   shoredistance\n           <int>\n 1          -231\n 2          -394\n 3          -971\n 4         -1403\n 5         -3895\n 6         -5896\n 7         -8319\n 8         -8562\n 9        -17661\n10        -19763\n# … with 15 more rows\n\n\nThe inland observations are at least 231 meters away from the coast and up to 515 kilometers. For simplicity, we will remove all points flagged as NO_DEPTH,ON_LAND, but it is recommended that locations are looked more in depth and determine how likely it was that an individual was present at that location.\nWe can also check if any other observations have been reported in land. We will filter out the NO_DEPTH,ON_LAND flags and check for any negative values in the shoredistance column.\n\ncaretta_obs %>% \n  filter(flags != \"NO_DEPTH,ON_LAND\" & shoredistance < 0)\n\n# A tibble: 0 × 103\n# … with 103 variables: associatedReferences <chr>, basisOfRecord <chr>,\n#   bibliographicCitation <chr>, catalogNumber <chr>, collectionCode <chr>,\n#   coordinatePrecision <chr>, coordinateUncertaintyInMeters <dbl>,\n#   datasetID <chr>, datasetName <chr>, dateIdentified <chr>,\n#   decimalLatitude <dbl>, decimalLongitude <dbl>, eventDate <chr>,\n#   eventTime <chr>, family <chr>, footprintWKT <chr>, genus <chr>,\n#   geodeticDatum <chr>, georeferencedDate <chr>, …\n\n\nNo observations were returned, which is good news.\nAnother feature worth pointing out in our data is that some of the observations appear to be gridded as they are evenly spaced. This is confirmed by the occurrenceRemarks column, which states that some observations are: Telemetry locations aggregated per species per 1-degree cell. This is not ideal and you may need to consider if the inclusion of these data points are suitable for your project. In this example, we will remove them from our analysis."
  },
  {
    "objectID": "tutorial/Get_seaturtle_data.html#problematic-observations",
    "href": "tutorial/Get_seaturtle_data.html#problematic-observations",
    "title": "Exploring OBIS sea turtle observations",
    "section": "Problematic observations",
    "text": "Problematic observations\nIn this step, we will remove observations with coordinate uncertainty over 100 km, any observations with the NO_DEPTH,ON_LAND flag, and any records that have been aggregated to a 1-degree cell.\n\n# caretta_obs %>% \n#   #Removing on land observations\n#   filter(flags != \"NO_DEPTH,ON_LAND\" | is.na(flags)) %>% \n#   #        | coordinateUncertaintyInMeters > 100000) %>% \n#   # filter(!str_detect(occurrenceRemarks, \"degree\"))"
  },
  {
    "objectID": "tutorial/Get_seaturtle_data.html#next-steps",
    "href": "tutorial/Get_seaturtle_data.html#next-steps",
    "title": "Exploring OBIS sea turtle observations",
    "section": "Next steps",
    "text": "Next steps\nNow that we’ve got explored the OBIS data we can finalize our dataset and import environmental data before running the SDM. For next steps, see SDM Workflow section."
  },
  {
    "objectID": "tutorial/background.html",
    "href": "tutorial/background.html",
    "title": "get background data",
    "section": "",
    "text": "Here we explore 2 approaches."
  },
  {
    "objectID": "tutorial/background.html#set-up",
    "href": "tutorial/background.html#set-up",
    "title": "get background data",
    "section": "Set up",
    "text": "Set up\n\nlibrary(ggplot2)\nlibrary(sf)\n\nLinking to GEOS 3.11.1, GDAL 3.6.2, PROJ 9.1.0; sf_use_s2() is TRUE\n\nlibrary(\"rnaturalearth\")\nlibrary(\"rnaturalearthdata\")\n\n\nAttaching package: 'rnaturalearthdata'\n\n\nThe following object is masked from 'package:rnaturalearth':\n\n    countries110\n\nlibrary(raster)\n\nLoading required package: sp\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ lubridate 1.9.2     ✔ tibble    3.1.8\n✔ purrr     1.0.1     ✔ tidyr     1.3.0\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::extract() masks raster::extract()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ dplyr::select()  masks raster::select()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\n\ndir_data <- file.path(here::here(), \"data\", \"raw-bio\")\ndir_env <- file.path(here::here(), \"data\", \"env\")\nredo <- TRUE"
  },
  {
    "objectID": "tutorial/background.html#define-the-region-of-interest",
    "href": "tutorial/background.html#define-the-region-of-interest",
    "title": "get background data",
    "section": "Define the region of interest",
    "text": "Define the region of interest\n\n# lon, lon, lat, lat\nlibrary(sf)\nlats <- c(-0.125, 32.125)\nlons <- c(41.875, 65.125)\n# raster extent is defined by west lon, east lon, south lat, north lat\next <- raster::extent(lons[1], lons[2], lats[1], lats[2])\nextent_polygon <- as(ext, \"SpatialPolygons\") %>% st_as_sf()\n# we need to assign a coordinate system; 4326 is the default for maps in sf\nsf::st_crs(extent_polygon)<-4326\n# convert to a WKT format\nwkt_geometry <- extent_polygon$geometry %>% st_as_text()\nwkt_geometry\n\n[1] \"POLYGON ((41.875 -0.125, 41.875 32.125, 65.125 32.125, 65.125 -0.125, 41.875 -0.125))\"\n\n\nMake a map of our region so we know we have the right area.\n\nworld <- ne_countries(scale = \"medium\", returnclass = \"sf\")\nggplot(data = world) + geom_sf() +\n  geom_sf(data = extent_polygon, color = \"red\", fill=NA)"
  },
  {
    "objectID": "tutorial/background.html#get-occurrence-data-from-robis",
    "href": "tutorial/background.html#get-occurrence-data-from-robis",
    "title": "get background data",
    "section": "Get occurrence data from robis",
    "text": "Get occurrence data from robis\n\ncols.to.use <- c(\"scientificName\", \"dateIdentified\", \"eventDate\", \"decimalLatitude\", \"decimalLongitude\", \"coordinateUncertaintyInMeters\", \"bathymetry\",  \"shoredistance\", \"sst\", \"sss\")\n\n\nlibrary(robis)\n\n\nAttaching package: 'robis'\n\n\nThe following object is masked from 'package:raster':\n\n    area\n\n# Alas no bathymetry is downloaded\ndf <- occurrence(geometry = wkt_geometry, wrims=TRUE, dna = FALSE, fields = cols.to.use)\n\n\nRetrieved 5000 records of approximately 21254 (23%)\n\n\n\nRetrieved 10000 records of approximately 21254 (47%)\nRetrieved 15000 records of\napproximately 21254 (70%)\nRetrieved 20000 records of approximately 21254\n(94%)\nRetrieved 21254 records of approximately 21254 (100%)\n\n\nSave the data to a file for later use.\n\nfil <- file.path(here::here(), \"data\", \"raw-bio\", \"io-background.csv\")\nwrite.csv(df, file=fil, quote=FALSE)\n\n\nRead in the background\n\nfil <- file.path(here::here(), \"data\", \"raw-bio\", \"io-background.csv\")\nback1 <- read.csv(fil)\n\n\n\nMake a plot of the background\nThis approach is not terribly random.\n\nlibrary(ggplot2)\nlibrary(\"ggspatial\")\nlibrary(\"sf\")\ntheme_set(theme_bw())\nworld <- st_make_valid(world)\nworld_points <- st_centroid(world)\n\nWarning in st_centroid.sf(world): st_centroid assumes attributes are constant\nover geometries of x\n\nworld_points <- cbind(world, st_coordinates(st_centroid(world$geometry)))\n\n\nplt <- ggplot(data = world) +\n    geom_sf(fill= \"antiquewhite\") +\n    geom_point(data = back1, aes(x=decimalLongitude, y=decimalLatitude), color = \"red\", size=0.1) +\n    annotation_scale(location = \"bl\", width_hint = 0.5) +\n    annotation_north_arrow(location = \"bl\", which_north = \"true\", \n        pad_x = unit(0.15, \"in\"), pad_y = unit(0.25, \"in\"),\n        style = north_arrow_fancy_orienteering) +\n    coord_sf(xlim = lons, ylim = lats) +\n    theme(panel.grid.major = element_line(color = gray(.5), linetype = \"dashed\", size = 0.5), panel.background = element_rect(fill = \"aliceblue\"))\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\nsf_use_s2(FALSE)\n\nSpherical geometry (s2) switched off\n\nplt + geom_text(data = world_points, aes(x=X, y=Y, label=name),\n          color = \"darkblue\", size=2, check_overlap = TRUE) +\n  xlab(\"longitude\") + ylab(\"latitude\")\n\nScale on map varies by more than 10%, scale bar may be inaccurate"
  },
  {
    "objectID": "tutorial/background.html#approach-2.-random-samples",
    "href": "tutorial/background.html#approach-2.-random-samples",
    "title": "get background data",
    "section": "Approach 2. Random samples",
    "text": "Approach 2. Random samples\nThis is adapted from here.\n\nGet a marine raster layer\nWe just need one because we use this to sample lat/lons from the marine environment.\n\n# set a default data directory\noptions(sdmpredictors_datadir = dir_env)\n\n# choosing marine\nenv_datasets <- sdmpredictors::list_datasets(terrestrial = FALSE, marine = TRUE)\nenv_layers <- sdmpredictors::list_layers(\"MARSPEC\")\nenv_stack <- sdmpredictors::load_layers(\"MS_bathy_5m\")\nenv_stack <- env_stack %>% raster::crop(ext)\n\nNow we can plot the bathymetry in our study region.\n\nplot(env_stack)\n\n\n\n\n\n\nNext we sample points from this\n\nnsamp <- 1000\nabsence <- dismo::randomPoints(env_stack[[1]], nsamp) %>% \n    as_tibble() %>% \n    st_as_sf(coords = c(\"x\", \"y\"), crs = 4326)\n\n\nmapview::mapview(absence, col.regions = \"gray\")\n\nWarning in cbind(`Feature ID` = fid, mat): number of rows of result is not a\nmultiple of vector length (arg 1)\n\n\n\n\n\n\n\nSave the absence locations to a file.\n\nabsence_geo <- file.path(dir_data, \"absence.geojson\")\npts_absence_csv <- file.path(dir_data, \"pts_absence.csv\")\nst_write(absence, pts_absence_csv, layer_options = \"GEOMETRY=AS_XY\", append=FALSE)\n\nDeleting layer `pts_absence' using driver `CSV'\nWriting layer `pts_absence' to data source \n  `/home/jovyan/R/ohw23_proj_marinesdms/data/raw-bio/pts_absence.csv' using driver `CSV'\noptions:        GEOMETRY=AS_XY \nUpdating existing layer pts_absence\nWriting 1000 features with 0 fields and geometry type Point."
  },
  {
    "objectID": "tutorial/maxent-sdm.html",
    "href": "tutorial/maxent-sdm.html",
    "title": "Marine Species Distribution Models",
    "section": "",
    "text": "This example steps through the process of presence-only modeling using the maxnet package. The example is based on the notes by Ben Tupper (Biglow Lab, Maine) https://github.com/BigelowLab/maxnet/wiki/stars"
  },
  {
    "objectID": "tutorial/maxent-sdm.html#step-1-define-the-region-of-interest",
    "href": "tutorial/maxent-sdm.html#step-1-define-the-region-of-interest",
    "title": "Marine Species Distribution Models",
    "section": "Step 1: Define the region of interest",
    "text": "Step 1: Define the region of interest\nWe are looking at the western Arabian Sea, Persian Gulf, Gulf of Oman, Gulf of Aden and Red Sea.\n\nlibrary(sf)\nlats <- c(-0.125, 32.125); lons <- c(41.875, 70.125)\n# raster extent is defined by west lon, east lon, south lat, north lat\next <- raster::extent(lons[1], lons[2], lats[1], lats[2])\nextent_polygon <- as(ext, \"SpatialPolygons\") %>% st_as_sf()\n# we need to assign a coordinate system; 4326 is the default for maps in sf\nsf::st_crs(extent_polygon)<-4326\n\nGet a polygon of the world.\n\nlibrary(\"rnaturalearth\")\nlibrary(\"rnaturalearthdata\")\n\n\nAttaching package: 'rnaturalearthdata'\n\n\nThe following object is masked from 'package:rnaturalearth':\n\n    countries110\n\nworld <- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\nMake a map of our region with the polygon of interest. reference\n\nlibrary(ggplot2)\nlibrary(sf)\nggplot(data = world) +\n    geom_sf() + \n  geom_sf(data = extent_polygon, color = \"red\", fill=NA)"
  },
  {
    "objectID": "tutorial/maxent-sdm.html#step-2-load-the-occurrence-data",
    "href": "tutorial/maxent-sdm.html#step-2-load-the-occurrence-data",
    "title": "Marine Species Distribution Models",
    "section": "Step 2: Load the occurrence data",
    "text": "Step 2: Load the occurrence data\nThis was queried using the robis package.\nspp <- c(\"Chelonia mydas\", \"Caretta caretta\", \"Eretmochelys imbricata\", \"Lepidochelys olivacea\", \"Natator depressus\", \"Dermochelys coriacea\")\nwkt_geometry <- extent_polygon$geometry %>% st_as_text()\ndf <- occurrence(spp, startdate = as.Date(\"2000-01-01\"), geometry = wkt_geometry)\n\nspp <- \"Chelonia mydas\"\nfil <- file.path(here::here(), \"data\", \"raw-bio\", \"io-sea-turtles.csv\")\nocc <- read.csv(fil)\nocc <- occ %>% subset(scientificName == spp)\n\nLook at the column names\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats 1.0.0     ✔ stringr 1.5.0\n✔ purrr   1.0.1     ✔ tibble  3.1.8\n✔ readr   2.1.4     ✔ tidyr   1.3.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::extract() masks raster::extract(), terra::extract()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ raster::select() masks dplyr::select()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\ncolnames(occ)\n\n [1] \"occurrenceID\"                  \"scientificName\"               \n [3] \"dateIdentified\"                \"eventDate\"                    \n [5] \"decimalLatitude\"               \"decimalLongitude\"             \n [7] \"coordinateUncertaintyInMeters\" \"individualCount\"              \n [9] \"lifeStage\"                     \"sex\"                          \n[11] \"bathymetry\"                    \"shoredistance\"                \n[13] \"sst\"                           \"sss\"                          \n[15] \"date\"                         \n\n\nMake sure the turtle was at sea.\n\nocc <- occ %>% subset(bathymetry > 0 & \n                        shoredistance > 0 & \n                        coordinateUncertaintyInMeters < 200)\ndim(occ)\n\n[1] 7060   15\n\n\nChange the occurrence data into an sf object with a coordinate system. Add a date column with YYYY-MM-DD format.\n\nocc$date <- as.Date(occ$eventDate)\nocc.sf <- sf::st_as_sf(occ, coords = c(\"decimalLongitude\", \"decimalLatitude\"), crs = 4326)\n\nPlot the occurrence data\n\nlibrary(ggplot2)\nlibrary(\"ggspatial\")\nlibrary(\"sf\")\ntheme_set(theme_bw())\nworld <- st_make_valid(world)\nworld_points <- st_centroid(world)\n\nWarning in st_centroid.sf(world): st_centroid assumes attributes are constant\nover geometries of x\n\nworld_points <- cbind(world, st_coordinates(st_centroid(world$geometry)))\n\n\nplt <- ggplot(data = world) +\n    geom_sf(fill= \"antiquewhite\") +\n    geom_point(data = occ, aes(x=decimalLongitude, y=decimalLatitude), color = \"red\", size=0.1) +\n    annotation_scale(location = \"bl\", width_hint = 0.5) +\n    annotation_north_arrow(location = \"bl\", which_north = \"true\", \n        pad_x = unit(0.15, \"in\"), pad_y = unit(0.25, \"in\"),\n        style = north_arrow_fancy_orienteering) +\n    coord_sf(xlim = lons, ylim = lats) +\n    theme(panel.grid.major = element_line(color = gray(.5), linetype = \"dashed\", size = 0.5), panel.background = element_rect(fill = \"aliceblue\"))\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\nsf_use_s2(FALSE)\n\nSpherical geometry (s2) switched off\n\nplt + geom_text(data = world_points, aes(x=X, y=Y, label=name),\n          color = \"darkblue\", size=2, check_overlap = TRUE) +\n  xlab(\"longitude\") + ylab(\"latitude\") + \n  ggtitle(spp, subtitle = \"occurences since 2000\")\n\nScale on map varies by more than 10%, scale bar may be inaccurate"
  },
  {
    "objectID": "tutorial/maxent-sdm.html#use-the-sdmpredictors-package-to-assemble-predictor-variable-data",
    "href": "tutorial/maxent-sdm.html#use-the-sdmpredictors-package-to-assemble-predictor-variable-data",
    "title": "Marine Species Distribution Models",
    "section": "Use the sdmpredictors package to assemble predictor variable data",
    "text": "Use the sdmpredictors package to assemble predictor variable data"
  },
  {
    "objectID": "tutorial/maxent-sdm.html#collect-background-points-within-the-region-occupied-by-the-presence-points-using-sf-package",
    "href": "tutorial/maxent-sdm.html#collect-background-points-within-the-region-occupied-by-the-presence-points-using-sf-package",
    "title": "Marine Species Distribution Models",
    "section": "Collect background points within the region occupied by the presence points using sf package",
    "text": "Collect background points within the region occupied by the presence points using sf package"
  },
  {
    "objectID": "tutorial/maxent-sdm.html#model-and-predict-using-the-maxnet-package",
    "href": "tutorial/maxent-sdm.html#model-and-predict-using-the-maxnet-package",
    "title": "Marine Species Distribution Models",
    "section": "Model and predict using the maxnet package",
    "text": "Model and predict using the maxnet package"
  },
  {
    "objectID": "tutorial/occ_env.html",
    "href": "tutorial/occ_env.html",
    "title": "Get environmental data for the occurrence locationa",
    "section": "",
    "text": "We need to get a data frame with the environmental data for the occurrence locations."
  },
  {
    "objectID": "tutorial/occ_env.html#set-up",
    "href": "tutorial/occ_env.html#set-up",
    "title": "Get environmental data for the occurrence locationa",
    "section": "Set up",
    "text": "Set up\n\nlibrary(ggplot2)\nlibrary(sdmpredictors)\n\nSet the directory where we will save environmental data layers.\n\ndir_env <- here::here(\"data\", \"env\")\noptions(sdmpredictors_datadir = dir_env)"
  },
  {
    "objectID": "tutorial/occ_env.html#add-datasets",
    "href": "tutorial/occ_env.html#add-datasets",
    "title": "Get environmental data for the occurrence locationa",
    "section": "Add datasets",
    "text": "Add datasets\nWe will use the sdmpredictors R package which has marine data layers.\n\n# choose marine\nenv_datasets <- sdmpredictors::list_datasets(terrestrial = FALSE, marine = TRUE)"
  },
  {
    "objectID": "tutorial/occ_env.html#show-the-available-variables",
    "href": "tutorial/occ_env.html#show-the-available-variables",
    "title": "Get environmental data for the occurrence locationa",
    "section": "Show the available variables",
    "text": "Show the available variables\nThe dataframe is large. We will use the DT package to make the table pretty in html.\n\nenv_layers <- sdmpredictors::list_layers(env_datasets$dataset_code)\nDT::datatable(env_layers)"
  },
  {
    "objectID": "tutorial/occ_env.html#variables",
    "href": "tutorial/occ_env.html#variables",
    "title": "Get environmental data for the occurrence locationa",
    "section": "Variables",
    "text": "Variables\n#Loading in environmental marine data datasets <- list_datasets(terrestrial = FALSE, marine = TRUE) layers <- list_layers(datasets) #View(layers) layercodes <- c(“BO_sstmean”,“BO_salinity”) env <- load_layers(layercodes)"
  },
  {
    "objectID": "tutorial/seaturtle_robis.html",
    "href": "tutorial/seaturtle_robis.html",
    "title": "get turtle data",
    "section": "",
    "text": "Here we download from OBIS using the robis package."
  },
  {
    "objectID": "tutorial/seaturtle_robis.html#step-1-define-the-region-of-interest",
    "href": "tutorial/seaturtle_robis.html#step-1-define-the-region-of-interest",
    "title": "get turtle data",
    "section": "Step 1 define the region of interest",
    "text": "Step 1 define the region of interest\n\n# lon, lon, lat, lat\nlibrary(sf)\n\nLinking to GEOS 3.11.1, GDAL 3.6.2, PROJ 9.1.0; sf_use_s2() is TRUE\n\nlats <- c(-0.125, 32.125)\nlons <- c(41.875, 65.125)\n# raster extent is defined by west lon, east lon, south lat, north lat\next <- raster::extent(lons[1], lons[2], lats[1], lats[2])\nextent_polygon <- as(ext, \"SpatialPolygons\") %>% st_as_sf()\n# we need to assign a coordinate system; 4326 is the default for maps in sf\nsf::st_crs(extent_polygon)<-4326\n# convert to a WKT format\nwkt_geometry <- extent_polygon$geometry %>% st_as_text()\nwkt_geometry\n\n[1] \"POLYGON ((41.875 -0.125, 41.875 32.125, 65.125 32.125, 65.125 -0.125, 41.875 -0.125))\"\n\n\nMake a map of our region so we know we have the right area.\n\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(\"rnaturalearth\")\nlibrary(\"rnaturalearthdata\")\n\n\nAttaching package: 'rnaturalearthdata'\n\n\nThe following object is masked from 'package:rnaturalearth':\n\n    countries110\n\nworld <- ne_countries(scale = \"medium\", returnclass = \"sf\")\nggplot(data = world) + geom_sf() +\n  geom_sf(data = extent_polygon, color = \"red\", fill=NA)"
  },
  {
    "objectID": "tutorial/seaturtle_robis.html#get-occurrence-data-from-robis",
    "href": "tutorial/seaturtle_robis.html#get-occurrence-data-from-robis",
    "title": "get turtle data",
    "section": "Get occurrence data from robis",
    "text": "Get occurrence data from robis\nDownload data for four species\nWe will download data for four sea turtles found in the Arabian sea and save to one file. We will use the occurrence() function in the robis package.\n\nlibrary(robis)\nspp <- c(\"Chelonia mydas\", \"Caretta caretta\", \"Eretmochelys imbricata\", \"Lepidochelys olivacea\", \"Natator depressus\", \"Dermochelys coriacea\")\n\nobs <- robis::occurrence(spp, startdate = as.Date(\"2000-01-01\"), geometry = wkt_geometry)\n\nThis has many columns that we don’t need. We will reduce to fewer columns.\n\ncols.to.use <- c(\"occurrenceID\", \"scientificName\", \n                 \"dateIdentified\", \"eventDate\", \n                 \"decimalLatitude\", \"decimalLongitude\", \"coordinateUncertaintyInMeters\",\n                 \"individualCount\",\"lifeStage\", \"sex\",\n                 \"bathymetry\",  \"shoredistance\", \"sst\", \"sss\")\nobs <- obs[,cols.to.use]\n\nWe will also add a cleaner date with YYYY-MM-DD format.\n\nobs$date <- as.Date(obs$eventDate)"
  },
  {
    "objectID": "tutorial/seaturtle_robis.html#save-our-data",
    "href": "tutorial/seaturtle_robis.html#save-our-data",
    "title": "get turtle data",
    "section": "Save our data",
    "text": "Save our data\nSet up the file names\n\ndir_data <- here::here(\"data\", \"raw-bio\")\nfilname <- \"io-sea-turtles\"\nobs_csv <- file.path(dir_data, paste0(filname, \".csv\"))\nobs_geo <- file.path(dir_data, paste0(filname, \".geojson\"))\nobs_gpkg <- file.path(dir_data, paste0(filname, \".gpkg\"))\n\nChange the data frame to a sf dataframe.\n\nobs_sf <- obs %>% \n    sf::st_as_sf(\n      coords = c(\"decimalLongitude\", \"decimalLatitude\"),\n      crs = st_crs(4326))\n\nSave files in different formats.\n\nredo   <- TRUE\n\nif (!file.exists(obs_csv) | redo)  readr::write_csv(obs, obs_csv)\nif (!file.exists(obs_geo) | redo)  sf::write_sf(obs_sf, obs_geo, delete_dsn=TRUE)\nif (!file.exists(obs_gpkg) | redo)  sf::write_sf(obs_sf, obs_gpkg, delete_dsn=TRUE)\n\nWe can reload our data as\n\ntmp <- sf::read_sf(obs_gpkg)\nclass(tmp)"
  }
]