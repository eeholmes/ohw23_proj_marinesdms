[
  {
    "objectID": "tutorial/Steps_visualization.html",
    "href": "tutorial/Steps_visualization.html",
    "title": "Visualization",
    "section": "",
    "text": "Load the needed packages.\n\nsuppressPackageStartupMessages({\nlibrary(dplyr)\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(cmocean)\nlibrary(maxnet)\nlibrary(stars)\n})\n\nSet the file location.\n\nhere::i_am(\"tutorial/Steps_visualization.Rmd\")\n\nhere() starts at /Users/eli.holmes/Documents/GitHub/ohw23_proj_marinesdms",
    "crumbs": [
      "SDM Steps",
      "Visualization"
    ]
  },
  {
    "objectID": "tutorial/Steps_visualization.html#set-up",
    "href": "tutorial/Steps_visualization.html#set-up",
    "title": "Visualization",
    "section": "",
    "text": "Load the needed packages.\n\nsuppressPackageStartupMessages({\nlibrary(dplyr)\nlibrary(sf)\nlibrary(ggplot2)\nlibrary(cmocean)\nlibrary(maxnet)\nlibrary(stars)\n})\n\nSet the file location.\n\nhere::i_am(\"tutorial/Steps_visualization.Rmd\")\n\nhere() starts at /Users/eli.holmes/Documents/GitHub/ohw23_proj_marinesdms",
    "crumbs": [
      "SDM Steps",
      "Visualization"
    ]
  },
  {
    "objectID": "tutorial/Steps_visualization.html#load-the-model",
    "href": "tutorial/Steps_visualization.html#load-the-model",
    "title": "Visualization",
    "section": "Load the model",
    "text": "Load the model\nWe saved this in the previous step. Has the sdm.model, occ.points, abs.points, and env.stars.crop.\n\nfil &lt;- here::here(\"data\", \"models\", \"io-turtle.RData\")\nload(fil)\n\nLoad region files. We created our region objects in a separate file Region data and saved these in data/region. We will load these now.\nLoad the bounding box polygon and create a bounding box.\n\n#Loading bounding box for the area of interest\nfil &lt;- here::here(\"data\", \"region\", \"BoundingBox.shp\")\nextent_polygon &lt;- sf::read_sf(fil)\nbbox &lt;- sf::st_bbox(extent_polygon)",
    "crumbs": [
      "SDM Steps",
      "Visualization"
    ]
  },
  {
    "objectID": "tutorial/Steps_visualization.html#predicting",
    "href": "tutorial/Steps_visualization.html#predicting",
    "title": "Visualization",
    "section": "Predicting",
    "text": "Predicting\n\nclamp &lt;- TRUE       # see ?predict.maxnet for details\ntype &lt;- \"cloglog\"\npredicted &lt;- predict(sdm.model, env.stars.crop, clamp = clamp, type = type)\npredicted\n\nstars object with 2 dimensions and 1 attribute\nattribute(s):\n           Min.   1st Qu.    Median      Mean   3rd Qu.      Max.  NA's\npred  0.0047245 0.1095251 0.1561052 0.1812027 0.2369365 0.9996747 52802\ndimension(s):\n  from   to offset    delta                       refsys x/y\nx 2663 2942   -180  0.08333 +proj=longlat +datum=WGS8... [x]\ny  695 1082     90 -0.08333 +proj=longlat +datum=WGS8... [y]",
    "crumbs": [
      "SDM Steps",
      "Visualization"
    ]
  },
  {
    "objectID": "tutorial/Steps_visualization.html#visualization",
    "href": "tutorial/Steps_visualization.html#visualization",
    "title": "Visualization",
    "section": "Visualization",
    "text": "Visualization\n\nggplot() +\n  geom_stars(data = predicted) +\n  scale_fill_cmocean(name = \"ice\", direction = -1, guide = guide_colorbar(barwidth = 1, barheight = 10, ticks = FALSE, nbin = 1000, frame.colour = \"black\"), limits = c(0, 1)) +\n  theme_linedraw() +\n  coord_equal() +\n  theme(panel.background = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank()) +\n  labs(title = \"Loggerhead and green sea turtle SDM in the Arabian Sea\",\n       x = \"Longitude\",\n       y = \"Latitude\",\n       fill = \"Probability\",\n       shape = \"Species (presence)\",\n       subtitle = \"Environmental predictors: mean SS temp, mean SS salinity, mean bathymetry, \\nmean pH, mean DO, mean SS chlorophyll-a, mean SS nitrate\") +\n  geom_point(occ.points, mapping = aes(shape = common.name, geometry = geometry), stat = \"sf_coordinates\", alpha = 0.3, color = \"purple\") +\n  #scale_x_continuous(breaks = seq(40, 70, 10), limits = c(42, 70))+\n  scale_y_continuous(breaks = seq(0, 30, 10))\n\n\n\n\n\n# ggsave(\"SDM_loggerhead_green_w points.pdf\", height = 6, width = 8.5)\n\n\n# ggplot - without occurrence data points\n\nggplot() +\n  geom_stars(data = predicted) +\n  scale_fill_cmocean(name = \"ice\", direction = -1, guide = guide_colorbar(barwidth = 1, barheight = 10, ticks = FALSE, nbin = 1000, frame.colour = \"black\"), limits = c(0, 1)) +\n  theme_linedraw() +\n  theme(panel.background = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank()) +\n  labs(title = \"Loggerhead and green sea turtle SDM in the Arabian Sea\",\n       x = \"Longitude\",\n       y = \"Latitude\",\n       fill = \"Probability\",\n       shape = \"Species (presence)\",\n       subtitle = \"Environmental predictors: mean SS temp, mean SS salinity, mean bathymetry,\\nmean pH, mean DO, mean SS chlorophyll-a, mean SS nitrate\") +\n  #geom_point(occ.points, mapping = aes(shape = common.name, geometry = geometry), stat = \"sf_coordinates\", alpha = 0.3, color = \"purple\") +\n  #scale_x_continuous(breaks = seq(40, 70, 10), limits = c(42, 70))+\n  scale_y_continuous(breaks = seq(0, 30, 10))\n\n\n\n# ggsave(\"SDM_loggerhead_green.pdf\", height = 6, width = 8.5)\n\n\n# ggplot - with occurrence (purple) and absence (green) data points\n\nggplot() +\n  geom_stars(data = predicted) +\n  scale_fill_cmocean(name = \"ice\", direction = -1, guide = guide_colorbar(barwidth = 1, barheight = 10, ticks = FALSE, nbin = 1000, frame.colour = \"black\"), limits = c(0, 1)) +\n  theme_linedraw() +\n  theme(panel.background = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank()) +\n  labs(title = \"Loggerhead and green sea turtle SDM in the Arabian Sea\",\n       x = \"Longitude\",\n       y = \"Latitude\",\n       fill = \"Probability\",\n       shape = \"Species (presence)\",\n       subtitle = \"Environmental predictors: mean SS temp, mean SS salinity, mean bathymetry, \\nmean pH, mean DO, mean SS chlorophyll-a, mean SS nitrate\") +\n  geom_point(occ.points, mapping = aes(shape = common.name, geometry = geometry), stat = \"sf_coordinates\", alpha = 0.3, color = \"purple\") +\n  #scale_x_continuous(breaks = seq(40, 70, 10), limits = c(42, 70))+\n  scale_y_continuous(breaks = seq(0, 30, 10)) +\n  geom_point(abs.points, mapping = aes(geometry = geometry), stat = \"sf_coordinates\", alpha = 0.3, color = \"green\") # adding in absence data",
    "crumbs": [
      "SDM Steps",
      "Visualization"
    ]
  },
  {
    "objectID": "tutorial/Steps_occurences.html",
    "href": "tutorial/Steps_occurences.html",
    "title": "Get turtle data",
    "section": "",
    "text": "Here we download from OBIS using the robis package.",
    "crumbs": [
      "SDM Steps",
      "Save presence data"
    ]
  },
  {
    "objectID": "tutorial/Steps_occurences.html#set-up",
    "href": "tutorial/Steps_occurences.html#set-up",
    "title": "Get turtle data",
    "section": "Set up",
    "text": "Set up\n\nlibrary(ggplot2)\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\nlibrary(\"rnaturalearth\")\nlibrary(\"rnaturalearthdata\")\n\n\nAttaching package: 'rnaturalearthdata'\n\n\nThe following object is masked from 'package:rnaturalearth':\n\n    countries110\n\nlibrary(raster)\n\nLoading required package: sp\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ lubridate 1.9.2     ✔ tibble    3.2.1\n✔ purrr     1.0.1     ✔ tidyr     1.3.0\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::extract() masks raster::extract()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ dplyr::select()  masks raster::select()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\nlibrary(robis)\n\n\nAttaching package: 'robis'\n\nThe following object is masked from 'package:raster':\n\n    area",
    "crumbs": [
      "SDM Steps",
      "Save presence data"
    ]
  },
  {
    "objectID": "tutorial/Steps_occurences.html#load-the-region-info",
    "href": "tutorial/Steps_occurences.html#load-the-region-info",
    "title": "Get turtle data",
    "section": "Load the region info",
    "text": "Load the region info\nLoad the bounding box polygon and create a bounding box.\n\n#Loading bounding box for the area of interest\nfil &lt;- here::here(\"data\", \"region\", \"BoundingBox.shp\")\nextent_polygon &lt;- sf::read_sf(fil)\nbbox &lt;- sf::st_bbox(extent_polygon)\nwkt_geometry &lt;- extent_polygon$geometry %&gt;% st_as_text()\n\nMake a map of our region so we know we have the right area.\n\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nggplot(data = world) + geom_sf() +\n  geom_sf(data = extent_polygon, color = \"red\", fill=NA)",
    "crumbs": [
      "SDM Steps",
      "Save presence data"
    ]
  },
  {
    "objectID": "tutorial/Steps_occurences.html#get-occurrence-data-from-robis",
    "href": "tutorial/Steps_occurences.html#get-occurrence-data-from-robis",
    "title": "Get turtle data",
    "section": "Get occurrence data from robis",
    "text": "Get occurrence data from robis\nWe will download data for four sea turtles found in the Arabian sea and save to one file. We will use the occurrence() function in the robis package.\n\nspp &lt;- c(\"Chelonia mydas\", \"Caretta caretta\", \"Eretmochelys imbricata\", \"Lepidochelys olivacea\", \"Natator depressus\", \"Dermochelys coriacea\")\n\nobs &lt;- robis::occurrence(spp, startdate = as.Date(\"2000-01-01\"), geometry = wkt_geometry)\n\nThis has many columns that we don’t need. We reduced to fewer columns.\n\ncols.to.use &lt;- c(\"occurrenceID\", \"scientificName\", \n                 \"dateIdentified\", \"eventDate\", \n                 \"decimalLatitude\", \"decimalLongitude\", \"coordinateUncertaintyInMeters\",\n                 \"individualCount\",\"lifeStage\", \"sex\",\n                 \"bathymetry\",  \"shoredistance\", \"sst\", \"sss\")\nobs &lt;- obs[,cols.to.use]\n\nWe also added a cleaner date with YYYY-MM-DD format.\n\nobs$date &lt;- as.Date(obs$eventDate)",
    "crumbs": [
      "SDM Steps",
      "Save presence data"
    ]
  },
  {
    "objectID": "tutorial/Steps_occurences.html#save-our-data",
    "href": "tutorial/Steps_occurences.html#save-our-data",
    "title": "Get turtle data",
    "section": "Save our data",
    "text": "Save our data\nSet up the file names\n\ndir_data &lt;- here::here(\"data\", \"raw-bio\")\nfilname &lt;- \"io-sea-turtles\"\nobs_csv &lt;- file.path(dir_data, paste0(filname, \".csv\"))\nobs_geo &lt;- file.path(dir_data, paste0(filname, \".geojson\"))\nobs_gpkg &lt;- file.path(dir_data, paste0(filname, \".gpkg\"))\n\nChange the data frame to a sf dataframe.\n\nobs_sf &lt;- obs %&gt;% \n    sf::st_as_sf(\n      coords = c(\"decimalLongitude\", \"decimalLatitude\"),\n      crs = st_crs(4326))\n\nSave files in different formats to facilitate loading into geospatial packages.\n\nredo   &lt;- TRUE\n\nif (!file.exists(obs_csv) | redo)  readr::write_csv(obs, obs_csv)\nif (!file.exists(obs_geo) | redo)  sf::write_sf(obs_sf, obs_geo, delete_dsn=TRUE)\nif (!file.exists(obs_gpkg) | redo)  sf::write_sf(obs_sf, obs_gpkg, delete_dsn=TRUE)\n\nLater we can reload our data as\n\ntmp &lt;- sf::read_sf(obs_gpkg)\nclass(tmp)",
    "crumbs": [
      "SDM Steps",
      "Save presence data"
    ]
  },
  {
    "objectID": "tutorial/Steps_occurences.html#clean-and-prep-data",
    "href": "tutorial/Steps_occurences.html#clean-and-prep-data",
    "title": "Get turtle data",
    "section": "Clean and prep data",
    "text": "Clean and prep data\nHere we clean and prepare the data for our model and save to a new file name.\n\nLoad data in\n\n# presence data\nfil &lt;- here::here(\"data\", \"raw-bio\", \"io-sea-turtles.csv\")\nio.turtles &lt;- read.csv(fil)\n\n\n\nClean the data\nSelect species.\n\n# turtle species we're interested in\nspp &lt;- c(\"Chelonia mydas\", \"Caretta caretta\", \"Eretmochelys imbricata\", \"Lepidochelys olivacea\", \"Natator depressus\", \"Dermochelys coriacea\") \n\n# subsetting all the occurence data to just those turtles \nocc &lt;- io.turtles %&gt;% \n  subset(scientificName == spp) \n\n# subset the occurences to include just those in the water\nocc &lt;- occ %&gt;% \n  subset(bathymetry &gt; 0 & shoredistance &gt; 0 & coordinateUncertaintyInMeters &lt; 200)\n\n# seeing how often each species occurs\ntable(occ$scientificName) \n\n\nCaretta caretta  Chelonia mydas \n            874            1190 \n\n\nAfter cleaning we discover that we only have loggerhead and green sea turtles.\n\n\nSelect the needed columns\nSelect columns and add a common name column.\n\ncolnames(occ)\n\n [1] \"occurrenceID\"                  \"scientificName\"               \n [3] \"dateIdentified\"                \"eventDate\"                    \n [5] \"decimalLatitude\"               \"decimalLongitude\"             \n [7] \"coordinateUncertaintyInMeters\" \"individualCount\"              \n [9] \"lifeStage\"                     \"sex\"                          \n[11] \"bathymetry\"                    \"shoredistance\"                \n[13] \"sst\"                           \"sss\"                          \n[15] \"date\"                         \n\n\nWe want these. The last two are sea surface temperature and salinity.\n\ncols &lt;- c(\"scientificName\", \"eventDate\", \"decimalLatitude\", \"decimalLongitude\", \"lifeStage\", \"bathymetry\", \"sst\", \"sss\")\n\nSubset the columns.\n\nocc.sub &lt;- occ %&gt;% dplyr::select(all_of(cols))\n\nFix the event date to a date format.\n\nocc.sub$eventDate &lt;- lubridate::ymd_hms(occ.sub$eventDate) \n\nChange the column names.\n\ncolnames(occ.sub) &lt;- c(\"sci.name\", \"obsv.datetime\", \"lat\", \"lon\", \"life.stage\", \"bathy\", \"SST\", \"SSS\")\n\nAdd common.name column.\n\nocc.sub &lt;- occ.sub %&gt;% \n  mutate(common.name = case_when(sci.name == \"Caretta caretta\" ~ \"Loggerhead\",\n                                 sci.name == \"Chelonia mydas\" ~ \"Green\"))\n\n\n\nSave the cleaned file",
    "crumbs": [
      "SDM Steps",
      "Save presence data"
    ]
  },
  {
    "objectID": "tutorial/Steps_occurences.html#save-our-data-1",
    "href": "tutorial/Steps_occurences.html#save-our-data-1",
    "title": "Get turtle data",
    "section": "Save our data",
    "text": "Save our data\nSet up the file names\n\ndir_data &lt;- here::here(\"data\", \"raw-bio\")\nfil &lt;- \"io-sea-turtles-clean.csv\"\nobs_csv &lt;- here::here(dir_data, fil)\nif (!file.exists(obs_csv))  readr::write_csv(occ.sub, obs_csv)",
    "crumbs": [
      "SDM Steps",
      "Save presence data"
    ]
  },
  {
    "objectID": "tutorial/Steps_background.html",
    "href": "tutorial/Steps_background.html",
    "title": "Get background data",
    "section": "",
    "text": "We used the random samples within our region of interest to generate a file with the locations for our absences.",
    "crumbs": [
      "SDM Steps",
      "Save absence aata"
    ]
  },
  {
    "objectID": "tutorial/Steps_background.html#set-up",
    "href": "tutorial/Steps_background.html#set-up",
    "title": "Get background data",
    "section": "Set up",
    "text": "Set up\n\nlibrary(ggplot2)\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\nlibrary(\"rnaturalearth\")\nlibrary(\"rnaturalearthdata\")\n\n\nAttaching package: 'rnaturalearthdata'\n\n\nThe following object is masked from 'package:rnaturalearth':\n\n    countries110\n\nlibrary(raster)\n\nLoading required package: sp\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.3     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ lubridate 1.9.2     ✔ tibble    3.2.1\n✔ purrr     1.0.1     ✔ tidyr     1.3.0\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::extract() masks raster::extract()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ dplyr::select()  masks raster::select()\nℹ Use the conflicted package (&lt;http://conflicted.r-lib.org/&gt;) to force all conflicts to become errors\n\n\n\ndir_data &lt;- file.path(here::here(), \"data\", \"raw-bio\")\ndir_env &lt;- file.path(here::here(), \"data\", \"env\")\nredo &lt;- TRUE",
    "crumbs": [
      "SDM Steps",
      "Save absence aata"
    ]
  },
  {
    "objectID": "tutorial/Steps_background.html#load-region-info",
    "href": "tutorial/Steps_background.html#load-region-info",
    "title": "Get background data",
    "section": "Load region info",
    "text": "Load region info\nLoad the bounding box polygon and create a bounding box.\n\n#Loading bounding box for the area of interest\nfil &lt;- here::here(\"data\", \"region\", \"BoundingBox.shp\")\nextent_polygon &lt;- sf::read_sf(fil)\nbbox &lt;- sf::st_bbox(extent_polygon)\nwkt_geometry &lt;- extent_polygon$geometry %&gt;% st_as_text()\n\nMake a map of our region so we know we have the right area.\n\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\nggplot(data = world) + geom_sf() +\n  geom_sf(data = extent_polygon, color = \"red\", fill=NA)",
    "crumbs": [
      "SDM Steps",
      "Save absence aata"
    ]
  },
  {
    "objectID": "tutorial/Steps_background.html#random-samples",
    "href": "tutorial/Steps_background.html#random-samples",
    "title": "Get background data",
    "section": "Random samples",
    "text": "Random samples\nThis is adapted from here.\n\nGet a marine raster layer\nWe just need one because we use this to sample lat/lons from the marine environment.\n\n# set a default data directory\noptions(sdmpredictors_datadir = dir_env)\n\n# choosing marine\nenv_datasets &lt;- sdmpredictors::list_datasets(terrestrial = FALSE, marine = TRUE)\nenv_layers &lt;- sdmpredictors::list_layers(\"MARSPEC\")\nenv_stack &lt;- sdmpredictors::load_layers(\"MS_bathy_5m\")\nenv_stack &lt;- env_stack %&gt;% raster::crop(extent_polygon)\n\nPlot to check that the layer looks ok. This is bathymetry.\n\nplot(env_stack)\n\n\n\n\n\n\nNext we sample points from this\nIt returns a sf points object.\n\nnsamp &lt;- 1000\nabsence &lt;- dismo::randomPoints(env_stack[[1]], nsamp) %&gt;% \n    as_tibble() %&gt;% \n    st_as_sf(coords = c(\"x\", \"y\"), crs = 4326)\n\n\nmapview::mapview(absence, col.regions = \"gray\")\n\nWarning in cbind(`Feature ID` = fid, mat): number of rows of result is not a\nmultiple of vector length (arg 1)",
    "crumbs": [
      "SDM Steps",
      "Save absence aata"
    ]
  },
  {
    "objectID": "tutorial/Steps_background.html#save",
    "href": "tutorial/Steps_background.html#save",
    "title": "Get background data",
    "section": "Save",
    "text": "Save\nSave the absence locations to a file.\n\nabsence_geo &lt;- file.path(dir_data, \"absence.geojson\")\npts_absence_csv &lt;- file.path(dir_data, \"pts_absence.csv\")\nst_write(absence, pts_absence_csv, layer_options = \"GEOMETRY=AS_XY\", append=FALSE)\n\nDeleting layer `pts_absence' using driver `CSV'\nWriting layer `pts_absence' to data source \n  `/Users/eli.holmes/Documents/GitHub/ohw23_proj_marinesdms/data/raw-bio/pts_absence.csv' using driver `CSV'\noptions:        GEOMETRY=AS_XY \nUpdating existing layer pts_absence\nWriting 1000 features with 0 fields and geometry type Point.",
    "crumbs": [
      "SDM Steps",
      "Save absence aata"
    ]
  },
  {
    "objectID": "tutorial/05_models.html",
    "href": "tutorial/05_models.html",
    "title": "Species Distribution Models",
    "section": "",
    "text": "Species distribution modeling (SDM) involves various statistical and machine learning techniques to predict the spatial distribution of species based on environmental variables. The classic SDM model takes the form:\nProbability of observation at location x = \\(p_x\\) Probability of absence at location x = \\(1-p_x\\)\n\\(p_x\\) is some, perhaps complex, function of the values of the variables at location x. The goal is to find the best function that explains the observations and absences.\nSome of the main models used for SDMs include:\n\nMaxent (Maximum Entropy Model): Maxent is a widely used model for SDMs. It aims to find the distribution that is the most spread out (has the highest entropy) while satisfying the constraints of observed species presences and environmental variables. It’s particularly useful when dealing with presence-only data. More on Maxent\nGLM (Generalized Linear Model): GLMs are a broad class of models that include linear regression as a special case. In the context of SDMs, GLMs can be extended to model species presence or absence based on environmental predictors.\nRandom Forest: Random Forest is an ensemble learning technique that builds multiple decision trees and combines their predictions. It’s robust and can handle complex interactions between variables, making it suitable for SDMs.\nBoosted Regression Trees (BRT): BRT is another ensemble method that combines multiple decision trees, but unlike Random Forest, it builds trees sequentially, with each tree trying to correct the errors of the previous one.\nSVM (Support Vector Machine): SVMs are used for classification tasks and can be adapted to predict species presence or absence based on environmental variables.\nANN (Artificial Neural Networks): Neural networks can capture complex relationships in the data and have been used for SDMs, particularly for large datasets.\nGAM (Generalized Additive Model): GAMs extend GLMs by allowing non-linear relationships between predictors and the response variable. They’re useful for capturing complex species-environment relationships.\nMaxlike (Maximum Likelihood Model): Maxlike models use maximum likelihood estimation to predict species distribution based on observed data and environmental predictors.\nMARS (Multivariate Adaptive Regression Splines): MARS models can capture non-linear relationships and interactions between predictors. They’re particularly useful when the relationships are complex and not well represented by linear models.\nSDMs with Hierarchical Models: Some researchers use hierarchical models, such as Bayesian models, to incorporate prior knowledge and uncertainty in SDMs.\n\nThe choice of model depends on the nature of your data, the assumptions you’re willing to make, the complexity of relationships, and the specific goals of your analysis. It’s often recommended to compare multiple models and evaluate their performance using appropriate metrics before deciding on the best model for your SDM.",
    "crumbs": [
      "Background",
      "Types of models"
    ]
  },
  {
    "objectID": "tutorial/05_models.html#models",
    "href": "tutorial/05_models.html#models",
    "title": "Species Distribution Models",
    "section": "",
    "text": "Species distribution modeling (SDM) involves various statistical and machine learning techniques to predict the spatial distribution of species based on environmental variables. The classic SDM model takes the form:\nProbability of observation at location x = \\(p_x\\) Probability of absence at location x = \\(1-p_x\\)\n\\(p_x\\) is some, perhaps complex, function of the values of the variables at location x. The goal is to find the best function that explains the observations and absences.\nSome of the main models used for SDMs include:\n\nMaxent (Maximum Entropy Model): Maxent is a widely used model for SDMs. It aims to find the distribution that is the most spread out (has the highest entropy) while satisfying the constraints of observed species presences and environmental variables. It’s particularly useful when dealing with presence-only data. More on Maxent\nGLM (Generalized Linear Model): GLMs are a broad class of models that include linear regression as a special case. In the context of SDMs, GLMs can be extended to model species presence or absence based on environmental predictors.\nRandom Forest: Random Forest is an ensemble learning technique that builds multiple decision trees and combines their predictions. It’s robust and can handle complex interactions between variables, making it suitable for SDMs.\nBoosted Regression Trees (BRT): BRT is another ensemble method that combines multiple decision trees, but unlike Random Forest, it builds trees sequentially, with each tree trying to correct the errors of the previous one.\nSVM (Support Vector Machine): SVMs are used for classification tasks and can be adapted to predict species presence or absence based on environmental variables.\nANN (Artificial Neural Networks): Neural networks can capture complex relationships in the data and have been used for SDMs, particularly for large datasets.\nGAM (Generalized Additive Model): GAMs extend GLMs by allowing non-linear relationships between predictors and the response variable. They’re useful for capturing complex species-environment relationships.\nMaxlike (Maximum Likelihood Model): Maxlike models use maximum likelihood estimation to predict species distribution based on observed data and environmental predictors.\nMARS (Multivariate Adaptive Regression Splines): MARS models can capture non-linear relationships and interactions between predictors. They’re particularly useful when the relationships are complex and not well represented by linear models.\nSDMs with Hierarchical Models: Some researchers use hierarchical models, such as Bayesian models, to incorporate prior knowledge and uncertainty in SDMs.\n\nThe choice of model depends on the nature of your data, the assumptions you’re willing to make, the complexity of relationships, and the specific goals of your analysis. It’s often recommended to compare multiple models and evaluate their performance using appropriate metrics before deciding on the best model for your SDM.",
    "crumbs": [
      "Background",
      "Types of models"
    ]
  },
  {
    "objectID": "tutorial/05_models.html#maxent",
    "href": "tutorial/05_models.html#maxent",
    "title": "Species Distribution Models",
    "section": "Maxent",
    "text": "Maxent\nThe Maxent algorithm, short for “Maximum Entropy,” is a machine learning technique used primarily for species distribution modeling. It’s designed to model the probability distribution of a species across geographic space based on environmental variables. Maxent aims to find the distribution that is the most spread out or has the highest entropy while satisfying a set of constraints provided by the available data.\nHere’s a high-level overview of how the Maxent algorithm works:\n\nInput Data: Maxent requires two main types of input data: presence data (locations where the species is known to occur) and environmental variables (such as temperature, precipitation, land cover, etc.). The presence data provides information about where the species has been observed.\nFeature Creation: Maxent uses the presence data to create a set of features (combinations of environmental variables) that represent the observed conditions at the presence locations.\nModel Training: The goal of Maxent is to find a probability distribution of environmental conditions that matches the observed presence locations while maximizing entropy (spreading out the distribution as much as possible). It’s formulated as a constrained optimization problem, where the model seeks to find the distribution that is closest to uniform (highest entropy) while satisfying constraints based on the presence data.\nRegularization: Maxent uses regularization to avoid overfitting the model to the presence data. Regularization adds a penalty for overly complex models. This helps prevent the model from fitting the noise in the presence data.\nProbability Prediction: Once the Maxent model is trained, it can be used to predict the probability of species presence across the entire study area based on the input environmental variables.\nModel Evaluation: The model’s predictive performance can be evaluated using various metrics, such as Area Under the Receiver Operating Characteristic Curve (AUC-ROC) or Area Under the Precision-Recall Curve (AUC-PR), which assess how well the model discriminates between presence and absence locations.\n\nMaxent is popular for species distribution modeling because it’s able to handle presence-only data (locations where the species is known to occur) and work with complex relationships between species and environmental variables. However, it’s important to note that Maxent models can still be subject to bias and limitations based on data quality and the assumptions of the algorithm.",
    "crumbs": [
      "Background",
      "Types of models"
    ]
  },
  {
    "objectID": "tutorial/05_Link_env_to_pts.html",
    "href": "tutorial/05_Link_env_to_pts.html",
    "title": "Link environmental layer to points",
    "section": "",
    "text": "See the “Fit with Maxnet” for an example.",
    "crumbs": [
      "Background",
      "Link envionment"
    ]
  },
  {
    "objectID": "tutorial/02_Background_Data.html",
    "href": "tutorial/02_Background_Data.html",
    "title": "Getting background data from OBIS",
    "section": "",
    "text": "In this notebook, we will explore three approaches to create background samples, aka pseudo absences. These are points where turtles were not recorded. These absences are needed for our choice of species distribution model algorithm. “Absences” does not mean that turtle could not be sighted here but that we have no records at these locations, either because we didn’t look or looked and didn’t see them.\nThese three approaches are as follows:\nIn both cases, points will be constrained to fit within our area of interest.",
    "crumbs": [
      "Background",
      "Absence data"
    ]
  },
  {
    "objectID": "tutorial/02_Background_Data.html#loading-libraries",
    "href": "tutorial/02_Background_Data.html#loading-libraries",
    "title": "Getting background data from OBIS",
    "section": "Loading libraries",
    "text": "Loading libraries\n\n#Deal with spatial data\nlibrary(sf)\n#Base maps and plotting spatial data\nlibrary(rnaturalearth)\nlibrary(mapview)\nlibrary(raster)\n#Data visualisation and manipulation\nlibrary(tidyverse)\n#Find files easily\nlibrary(here)\n#Access to OBIS\nlibrary(robis)\n#SDM\nlibrary(sdmpredictors)\nlibrary(dismo)\nlibrary(ggspatial)",
    "crumbs": [
      "Background",
      "Absence data"
    ]
  },
  {
    "objectID": "tutorial/02_Background_Data.html#set-up",
    "href": "tutorial/02_Background_Data.html#set-up",
    "title": "Getting background data from OBIS",
    "section": "Set-up",
    "text": "Set-up\n\nSetting base directories\nThese directories contain the biological data (i.e., presence locations of loggerhead sea turtles) and environmental data.\n\n#Setting directories containing input data\ndir_data &lt;- file.path(here::here(), \"data/raw-bio\")\ndir_env &lt;- file.path(here::here(), \"data/env\")\n\n\n\nLoading bounding box for region of interest\nIn the Region page, we created a bounding box for our region of interest. We will load this bounding box here to spatially constrain our data.\n\n#Loading bounding box for the area of interest\nfil &lt;- here::here(\"data\", \"region\", \"BoundingBox.shp\")\nextent_polygon &lt;- read_sf(fil)\n\n#Extract polygon geometry \npol_geometry &lt;- st_as_text(extent_polygon$geometry)",
    "crumbs": [
      "Background",
      "Absence data"
    ]
  },
  {
    "objectID": "tutorial/02_Background_Data.html#approach-1-use-other-species",
    "href": "tutorial/02_Background_Data.html#approach-1-use-other-species",
    "title": "Getting background data from OBIS",
    "section": "Approach 1: Use other species",
    "text": "Approach 1: Use other species\nIn this approach we use other marine species presence locations as our locations for our background samples.\n\nGetting occurrence data from OBIS\nWe will use robis to get observations for marine species from OBIS within our bounding box. OBIS data includes about 100 different columns, but not all of these columns are relevant to us. We will define the columns that we need and then we will perform a search of the OBIS database.\n\n\nDefining relevant columns\n\ncols.to.use &lt;- c(\"scientificName\", \"dateIdentified\", \"eventDate\", \"decimalLatitude\", \"decimalLongitude\", \"coordinateUncertaintyInMeters\", \"bathymetry\",  \"shoredistance\", \"sst\", \"sss\")\n\n\n\nQuerying OBIS\nBy setting the wrims parameter to TRUE we include observations of species registerd in the World Register of Introduced Marine Species (WRiMS).\n\n#Applying bounding box and including WRiMS species\nbackground &lt;- occurrence(geometry = pol_geometry, wrims = TRUE, \n                         #DNA data is not needed, subsetting columns of interest\n                         dna = FALSE, fields = cols.to.use,\n                         #Excluding records labelled as being on land\n                         exclude = \"ON_LAND\")\n\n\nRetrieved 5000 records of approximately 20511 (24%)\nRetrieved 10000 records of\napproximately 20511 (48%)\nRetrieved 15000 records of approximately 20511\n(73%)\nRetrieved 20000 records of approximately 20511 (97%)\nRetrieved 20511\nrecords of approximately 20511 (100%)\n\n\n\n\nSaving background data\n\n#Setting full file path to save background information\nfile_path_out &lt;- file.path(dir_data, \"io-background.csv\")\n\n#Saving background data as csv\nwrite_csv(background, file_path_out)\n\n\n\n(Optional) Load background data\nIf you have previously downloaded the background data, you can simply load the data to the environment instead of downloading it again. To do this, you can use the code below.\n\n#Find background file in our biological data folder\nfile_path_bg &lt;- list.files(dir_data, pattern = \"background\", full.names = TRUE)\n\n#Load file\nbackground_1 &lt;- read_csv(file_path_bg)\n\n\n\nPlotting background data\nWe will create a map with all the observations we obtained from OBIS within our region of interest.\nFirst we will load the region map that was saved in the Region page\n\nfil &lt;- here::here(\"data\", \"region\", \"region_map_label.rda\")\nload(fil)\n\nSaving map into variable\n\n# load our base map and add points\nregion_map_label +\n  geom_point(data = background, \n             #Point to coordinates for background points\n             aes(x = decimalLongitude, y = decimalLatitude), \n             #Changing color and size of points for background data\n             color = \"red\", size = 0.1)\n\nScale on map varies by more than 10%, scale bar may be inaccurate\n\n\nWarning: Removed 231 rows containing missing values (`geom_text()`).\n\n\n\n\n\nAs you can see from the map above, this approach is not truly random. This is why we are including a second method to create background samples.",
    "crumbs": [
      "Background",
      "Absence data"
    ]
  },
  {
    "objectID": "tutorial/02_Background_Data.html#approach-2.-random-points-in-our-region",
    "href": "tutorial/02_Background_Data.html#approach-2.-random-points-in-our-region",
    "title": "Getting background data from OBIS",
    "section": "Approach 2. Random points in our region",
    "text": "Approach 2. Random points in our region\nThis section has been adapted from this online tutorial.\n\nLoading raster layer for area of interest\nWe will be using sdmpredictors for our environmental data layers (variables). We need to load a raster layer from sdmpredictors so we can sample locations from this raster. It doesn’t matter what variable we use, it just needs to not have NAs. Using a marine layer from sdmpredictors ensures that we will not sample from the land. See the sdmpredictors section for discussion of accessing rasters with sdmpredictors and how to find out what layers are available.\nWe used a bathymetery layer: “MS_bathy_5m”. We will load this data and crop it using our bounding box.\n\n#Set default directory for environmental data\noptions(sdmpredictors_datadir = dir_env)\n#Loading bathymetry\nenv_stack &lt;- load_layers(\"MS_bathy_5m\") %&gt;% \n  #Cropping to our area of interest\n  crop(extent_polygon)\n\nWe can plot the cropped bathymetry to ensure it matches our study region and we did not make any mistakes.\n\nplot(env_stack)\n\n\n\n\nWe can see the outline of our area of interest. Now we can continue with creating our background points.\n\n\nSample points from bathymetry layer\nUsing the dismo package, we will create random points over the bathymetry layer that we will use as background points. In this example, we have chosen to produce 1000 background points.\nIt is worth noting that the distribution and number of background points has a strong influence on SDM results. See the README file for resources discussing this issue.\n\n#Setting seed for reproducibility\nset.seed(42)\n\n#Setting number of background points required\nnsamp &lt;- 1000\n\n#Create background points\nbackground &lt;- randomPoints(env_stack, nsamp) %&gt;% \n  #Transform to tibble\n  as_tibble() %&gt;% \n  #Transform to sf object\n  st_as_sf(coords = c(\"x\", \"y\"), crs = 4326)\n\n\n\nPlotting results\nWe will plot results to make sure our background points are in the ocean only. Here we use an alternate why to plot points on a map.\n\nmapview(background, col.regions = \"gray\")\n\nWarning in cbind(`Feature ID` = fid, mat): number of rows of result is not a\nmultiple of vector length (arg 1)\n\n\n\n\n\n\n\n\nSaving background samples\nWe can now save the background locations to our local machine.\n\nabsence_geo &lt;- file.path(dir_data, \"absence.geojson\")\npts_absence_csv &lt;- file.path(dir_data, \"pts_absence.csv\")\nst_write(background, pts_absence_csv, layer_options = \"GEOMETRY=AS_XY\", append = FALSE)\n\nDeleting layer `pts_absence' using driver `CSV'\nWriting layer `pts_absence' to data source \n  `/Users/eli.holmes/Documents/GitHub/ohw23_proj_marinesdms/data/raw-bio/pts_absence.csv' using driver `CSV'\noptions:        GEOMETRY=AS_XY \nUpdating existing layer pts_absence\nWriting 1000 features with 0 fields and geometry type Point.",
    "crumbs": [
      "Background",
      "Absence data"
    ]
  },
  {
    "objectID": "tutorial/02_Background_Data.html#approach-3.-random-points-a-convex-hull",
    "href": "tutorial/02_Background_Data.html#approach-3.-random-points-a-convex-hull",
    "title": "Getting background data from OBIS",
    "section": "Approach 3. Random points a convex hull",
    "text": "Approach 3. Random points a convex hull\nThis section has been adapted from this online tutorial and this online tutorial.\nThe next notebook will discuss how to get environmental data that we will use as inputs in our SDM from the sdmpredictors package.",
    "crumbs": [
      "Background",
      "Absence data"
    ]
  },
  {
    "objectID": "tutorial/00_Roadmap.html",
    "href": "tutorial/00_Roadmap.html",
    "title": "SDM Roadmap",
    "section": "",
    "text": "This section (Background) discusses the steps of the Species Distribution Model (SDM) Workflow and shows some different approaches that you might take.",
    "crumbs": [
      "Background"
    ]
  },
  {
    "objectID": "tutorial/00_Roadmap.html#sdm-workflow",
    "href": "tutorial/00_Roadmap.html#sdm-workflow",
    "title": "SDM Roadmap",
    "section": "SDM Workflow",
    "text": "SDM Workflow\nCreating a Species Distribution Model (SDM) has general steps: 1) plan, 2) data preparation, 3) model fitting, 4) assessment and 5) predictions. These are the same for all SDMs independent of the particular algorithm used.\nIn this tutorial, we discuss these steps in the context of marine SDMs using the example of the sea turtles in the Arabian Sea. In the “SDM Steps” section, we show the specific approaches that we use in the sea turtle SDM tutorial. This is a tutorial to get you more comfortable with the steps. They actual sea turtle model we produce is a “toy” example.\n\nSpecify the region\n– shows how to create a bounding box for the region and some base maps\nObtain presence Data\n– shows how to obtain sea turtle presence data from OBIS via robis\nCreate Absence (also called background) Points\n– discusses three methods to create random background points within a area of interest\nExtract environmental variables\n– shows how to obtain environmental predictors of interest using sdmpredictors\nModels\n– discusses different SDM modeling options and discusses the maxent model that we use in this tutorial\nData Visualizations",
    "crumbs": [
      "Background"
    ]
  },
  {
    "objectID": "tutorial/00_Roadmap.html#references",
    "href": "tutorial/00_Roadmap.html#references",
    "title": "SDM Roadmap",
    "section": "References",
    "text": "References\n\nThe zoon project has a nice summary of the steps to preparing a SDM.",
    "crumbs": [
      "Background"
    ]
  },
  {
    "objectID": "tutorial/**_Extracting_environmental_data.html",
    "href": "tutorial/**_Extracting_environmental_data.html",
    "title": "Extracting environmental data from zarr files",
    "section": "",
    "text": "This notebook shows how to load zarr files containing environmental data for our area of interest. We will then use the locations of sea turtles observations we downloaded from OBIS to extract environmental data for points where sea turtles have been reported."
  },
  {
    "objectID": "tutorial/**_Extracting_environmental_data.html#loading-libraries",
    "href": "tutorial/**_Extracting_environmental_data.html#loading-libraries",
    "title": "Extracting environmental data from zarr files",
    "section": "Loading libraries",
    "text": "Loading libraries\n\n#Deals with zarr files\nimport xarray as xr\n#Plotting\nimport matplotlib.pyplot as plt\n#Deals with data frames\nimport pandas as pd\n%matplotlib inline\n\n\nxr.set_options(display_style = 'text')\n\n&lt;xarray.core.options.set_options at 0x7eff805cdaf0&gt;"
  },
  {
    "objectID": "tutorial/**_Extracting_environmental_data.html#loading-environmental-data",
    "href": "tutorial/**_Extracting_environmental_data.html#loading-environmental-data",
    "title": "Extracting environmental data from zarr files",
    "section": "Loading environmental data",
    "text": "Loading environmental data\nThis dataset was provides by Eli Holmes. Source?\n\nds = xr.open_zarr(\"/home/jovyan/shared/marine-SDMs/INDIAN_OCEAN_025GRID_DAILY.zarr/\")\n\nWe can now check the names of the environmental variables included in the dataset.\n\nds.data_vars\n\nData variables:\n    CHL              (time, lat, lon) float32 dask.array&lt;chunksize=(100, 177, 241), meta=np.ndarray&gt;\n    CHL_uncertainty  (time, lat, lon) float32 dask.array&lt;chunksize=(100, 177, 241), meta=np.ndarray&gt;\n    adt              (time, lat, lon) float32 dask.array&lt;chunksize=(100, 177, 241), meta=np.ndarray&gt;\n    air_temp         (time, lat, lon) float32 dask.array&lt;chunksize=(100, 177, 241), meta=np.ndarray&gt;\n    curr_dir         (time, lat, lon) float32 dask.array&lt;chunksize=(100, 177, 241), meta=np.ndarray&gt;\n    curr_speed       (time, lat, lon) float32 dask.array&lt;chunksize=(100, 177, 241), meta=np.ndarray&gt;\n    mlotst           (time, lat, lon) float32 dask.array&lt;chunksize=(500, 177, 241), meta=np.ndarray&gt;\n    sla              (time, lat, lon) float32 dask.array&lt;chunksize=(100, 177, 241), meta=np.ndarray&gt;\n    so               (time, lat, lon) float32 dask.array&lt;chunksize=(500, 177, 241), meta=np.ndarray&gt;\n    sst              (time, lat, lon) float32 dask.array&lt;chunksize=(100, 177, 241), meta=np.ndarray&gt;\n    topo             (lat, lon) float64 dask.array&lt;chunksize=(177, 241), meta=np.ndarray&gt;\n    u_curr           (time, lat, lon) float32 dask.array&lt;chunksize=(100, 177, 241), meta=np.ndarray&gt;\n    u_wind           (time, lat, lon) float32 dask.array&lt;chunksize=(100, 177, 241), meta=np.ndarray&gt;\n    ug_curr          (time, lat, lon) float32 dask.array&lt;chunksize=(100, 177, 241), meta=np.ndarray&gt;\n    v_curr           (time, lat, lon) float32 dask.array&lt;chunksize=(100, 177, 241), meta=np.ndarray&gt;\n    v_wind           (time, lat, lon) float32 dask.array&lt;chunksize=(100, 177, 241), meta=np.ndarray&gt;\n    vg_curr          (time, lat, lon) float32 dask.array&lt;chunksize=(100, 177, 241), meta=np.ndarray&gt;\n    wind_dir         (time, lat, lon) float32 dask.array&lt;chunksize=(100, 177, 241), meta=np.ndarray&gt;\n    wind_speed       (time, lat, lon) float32 dask.array&lt;chunksize=(100, 177, 241), meta=np.ndarray&gt;"
  },
  {
    "objectID": "tutorial/**_Extracting_environmental_data.html#plotting-data",
    "href": "tutorial/**_Extracting_environmental_data.html#plotting-data",
    "title": "Extracting environmental data from zarr files",
    "section": "Plotting data",
    "text": "Plotting data\nWe will use chlorophyll (CHL) as an example. We will select all data for the year 2022, calculate a mean for that year and plot a map of the mean chlorophyll.\n\nds.CHL.sel(time = '2022').mean('time').plot()\n\n\n\n\nWe can see that chlorophyll levels are very low for most the area in the region included in the dataset. But areas near the coast show a higher chlorophyll level."
  },
  {
    "objectID": "tutorial/**_Extracting_environmental_data.html#loading-biological-data",
    "href": "tutorial/**_Extracting_environmental_data.html#loading-biological-data",
    "title": "Extracting environmental data from zarr files",
    "section": "Loading biological data",
    "text": "Loading biological data\nWe will now load the sea turtle observations obtained in the previous steps. We will use this data to extract data for environmental factors that are relevant to sea turtle distribution. Here, we will use CHL as an example.\n\nsea_turtle = pd.read_csv(\"/home/jovyan/ohw23_proj_marinesdms/data/raw-bio/io-sea-turtles.csv\")\nsea_turtle.head()\n\n\n\n\n\n\n\n\noccurrenceID\nscientificName\ndateIdentified\neventDate\ndecimalLatitude\ndecimalLongitude\ncoordinateUncertaintyInMeters\nindividualCount\nlifeStage\nsex\nbathymetry\nshoredistance\nsst\nsss\ndate\n\n\n\n\n0\n1014_8853\nCaretta caretta\n2012-03-30T08:55:10\n2012-03-30T08:55:10\n9.14804\n50.69448\n0.11\n1.0\nJuvenile\nNaN\n35\n4680\n26.21\n35.63\n2012-03-30\n\n\n1\n1014_9766\nCaretta caretta\n2011-04-12T19:12:41\n2011-04-12T19:12:41\n6.40193\n59.87883\n0.11\n1.0\nJuvenile\nNaN\n3051\n899682\n28.67\n35.74\n2011-04-12\n\n\n2\n2069_333\nChelonia mydas\n2016-07-24T15:18:00\n2016-07-24T15:18:00\n25.69900\n55.78900\n111.32\n1.0\nNaN\nNaN\n8\n-67\n28.19\n38.72\n2016-07-24\n\n\n3\n1014_8861\nCaretta caretta\n2012-03-31T02:43:31\n2012-03-31T02:43:31\n9.21307\n50.82211\n0.11\n1.0\nJuvenile\nNaN\n136\n12208\n26.21\n35.65\n2012-03-31\n\n\n4\n1014_15706\nCaretta caretta\n2011-05-14T17:53:55\n2011-05-14T17:53:55\n15.39172\n55.71303\n0.11\n1.0\nJuvenile\nNaN\n2784\n193567\n27.00\n36.09\n2011-05-14"
  },
  {
    "objectID": "tutorial/**_Extracting_environmental_data.html#plotting-both-datasets-into-a-single-map",
    "href": "tutorial/**_Extracting_environmental_data.html#plotting-both-datasets-into-a-single-map",
    "title": "Extracting environmental data from zarr files",
    "section": "Plotting both datasets into a single map",
    "text": "Plotting both datasets into a single map\nWe can visually inspect that our datasets contain data for the region of our interest.\n\n#Initialise figure\nfig = plt.figure()\n#Add a plot\nax = fig.add_subplot(111)\n#We will calculate the mean chlorophyll values for 2022 and plot them\nds.CHL.sel(time = '2022').mean('time').plot(ax = ax)\n#We will now plot the sea turtle data as green dots\nsea_turtle.plot.scatter(y = 'decimalLatitude', x = 'decimalLongitude', ax = ax, marker = 'o', color = 'green')"
  },
  {
    "objectID": "tutorial/**_Extracting_environmental_data.html#extracting-environmental-data",
    "href": "tutorial/**_Extracting_environmental_data.html#extracting-environmental-data",
    "title": "Extracting environmental data from zarr files",
    "section": "Extracting environmental data",
    "text": "Extracting environmental data\nWe will now use the coordinates (i.e., lat/lon pairs) of the sea turtle locations to extract environmental data.\n\n#We create data arrays with latitude and longitude values for sea turtle observation\nlat = xr.DataArray(sea_turtle.decimalLatitude)\nlon = xr.DataArray(sea_turtle.decimalLongitude)\n\nWe will now use these coordinates to extract CHL data for all years. Note that we use nearest as method because our environmental data is gridded and it uses the centre of the grid cell as the coordinate to be matched.\n\nenv_turtles = ds.CHL.sel(lat = lat, lon = lon, method = 'nearest')\n\nWe can check what the data looks like by simply calling the env_turtles variable.\n\nenv_turtles\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n\n&lt;xarray.DataArray 'CHL' (time: 16071, dim_0: 13210)&gt;\ndask.array&lt;transpose, shape=(16071, 13210), dtype=float32, chunksize=(100, 13210), chunktype=numpy.ndarray&gt;\nCoordinates:\n    lat      (dim_0) float32 9.25 6.5 25.75 9.25 15.5 ... 24.75 25.75 24.75 15.5\n    lon      (dim_0) float32 50.75 60.0 55.75 50.75 ... 53.0 55.75 53.0 55.5\n  * time     (time) datetime64[ns] 1979-01-01 1979-01-02 ... 2022-12-31\n  * dim_0    (dim_0) int64 0 1 2 3 4 5 6 ... 13204 13205 13206 13207 13208 13209\nAttributes:\n    _ChunkSizes:                [1, 256, 256]\n    ancillary_variables:        flags CHL_uncertainty\n    coverage_content_type:      modelResult\n    input_files_reprocessings:  Processors versions: MODIS R2022.0NRT/VIIRSN ...\n    long_name:                  Chlorophyll-a concentration - Mean of the bin...\n    standard_name:              mass_concentration_of_chlorophyll_a_in_sea_water\n    type:                       surface\n    units:                      milligram m-3\n    valid_max:                  1000.0\n    valid_min:                  0.0xarray.DataArray'CHL'time: 16071dim_0: 13210dask.array&lt;chunksize=(100, 13210), meta=np.ndarray&gt;\n\n\n\n\n\n\n\n\n\n\n\nArray\nChunk\n\n\n\n\nBytes\n809.85 MiB\n5.04 MiB\n\n\nShape\n(16071, 13210)\n(100, 13210)\n\n\nDask graph\n161 chunks in 4 graph layers\n\n\nData type\nfloat32 numpy.ndarray\n\n\n\n\n\n\n\nCoordinates: (4)lat(dim_0)float329.25 6.5 25.75 ... 25.75 24.75 15.5long_name :latitudestandard_name :latitudeunits :degrees_northarray([ 9.25,  6.5 , 25.75, ..., 25.75, 24.75, 15.5 ], dtype=float32)lon(dim_0)float3250.75 60.0 55.75 ... 53.0 55.5long_name :longitudestandard_name :longitudeunits :degrees_eastarray([50.75, 60.  , 55.75, ..., 55.75, 53.  , 55.5 ], dtype=float32)time(time)datetime64[ns]1979-01-01 ... 2022-12-31axis :Tcomment :Data is averaged over the daylong_name :time centered on the daystandard_name :timetime_bounds :2000-01-01 00:00:00 to 2000-01-01 23:59:59array(['1979-01-01T00:00:00.000000000', '1979-01-02T00:00:00.000000000',\n       '1979-01-03T00:00:00.000000000', ..., '2022-12-29T00:00:00.000000000',\n       '2022-12-30T00:00:00.000000000', '2022-12-31T00:00:00.000000000'],\n      dtype='datetime64[ns]')dim_0(dim_0)int640 1 2 3 ... 13206 13207 13208 13209array([    0,     1,     2, ..., 13207, 13208, 13209])Attributes: (10)_ChunkSizes :[1, 256, 256]ancillary_variables :flags CHL_uncertaintycoverage_content_type :modelResultinput_files_reprocessings :Processors versions: MODIS R2022.0NRT/VIIRSN R2022.0NRT/OLCIA 07.02/VIIRSJ1 R2022.0NRT/OLCIB 07.02long_name :Chlorophyll-a concentration - Mean of the binned pixelsstandard_name :mass_concentration_of_chlorophyll_a_in_sea_watertype :surfaceunits :milligram m-3valid_max :1000.0valid_min :0.0\n\n\nThis dataset contains CHL data for all coordinate pairs across all times. We will now select a single date (2022-01-01) and turn the results into a data frame.\n\nchl_2022_01_01 = env_turtles.sel(time = '2022-01-01').to_dataframe()\nchl_2022_01_01\n\n\n\n\n\n\n\n\nlat\nlon\ntime\nCHL\n\n\ndim_0\n\n\n\n\n\n\n\n\n0\n9.25\n50.75\n2022-01-01\n0.398237\n\n\n1\n6.50\n60.00\n2022-01-01\n0.196541\n\n\n2\n25.75\n55.75\n2022-01-01\n1.091021\n\n\n3\n9.25\n50.75\n2022-01-01\n0.398237\n\n\n4\n15.50\n55.75\n2022-01-01\n0.508613\n\n\n...\n...\n...\n...\n...\n\n\n13205\n19.75\n61.50\n2022-01-01\n0.671600\n\n\n13206\n24.75\n53.00\n2022-01-01\n0.545474\n\n\n13207\n25.75\n55.75\n2022-01-01\n1.091021\n\n\n13208\n24.75\n53.00\n2022-01-01\n0.545474\n\n\n13209\n15.50\n55.50\n2022-01-01\n0.605745\n\n\n\n\n13210 rows × 4 columns\n\n\n\nWe could save this information to our local machine with just one line (see below). But we probably need to match the dates to coordinates and only keep the data we need.\n\nchl_2022_01_01.to_csv('chl_2022_01_01.csv')"
  },
  {
    "objectID": "SDM/Turtle_maxnet.html",
    "href": "SDM/Turtle_maxnet.html",
    "title": "Maxent SDM",
    "section": "",
    "text": "You will need to install maxnet if you have not already. This checks if it is installed.\n\nif(!require(maxnet))\n   devtools::install_github(\"BigelowLab/maxnet\")\n\nLoad the necessary libraries. If you see errors that a library is not installed, you will need to install with install.packages(\"packagename\").\n\nsuppressPackageStartupMessages({\nlibrary(maxnet)\nlibrary(dplyr)\nlibrary(maxnet)\nlibrary(sf)\nlibrary(stars)\nlibrary(geodata)\nlibrary(dismo)\nlibrary(lubridate)\nlibrary(sdmpredictors)\nlibrary(ggplot2)\nlibrary(cmocean)\nlibrary(janitor)\nlibrary(DT)\nlibrary(here)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\nlibrary(raster)\nlibrary(ggspatial)\nlibrary(tidyverse)\nlibrary(robis)\n})\n\nTell R that the root should be where this RMarkdown file resides. All our data files will be stored here.\n\nsdm_dir &lt;- \"SDM\"\nhere::i_am(paste0(sdm_dir,\"/Turtle_maxnet.Rmd\"))\n\nhere() starts at /Users/eli.holmes/Documents/GitHub/tutorials_marine_sdm",
    "crumbs": [
      "Full SDM",
      "Maxnet"
    ]
  },
  {
    "objectID": "SDM/Turtle_maxnet.html#set-up",
    "href": "SDM/Turtle_maxnet.html#set-up",
    "title": "Maxent SDM",
    "section": "",
    "text": "You will need to install maxnet if you have not already. This checks if it is installed.\n\nif(!require(maxnet))\n   devtools::install_github(\"BigelowLab/maxnet\")\n\nLoad the necessary libraries. If you see errors that a library is not installed, you will need to install with install.packages(\"packagename\").\n\nsuppressPackageStartupMessages({\nlibrary(maxnet)\nlibrary(dplyr)\nlibrary(maxnet)\nlibrary(sf)\nlibrary(stars)\nlibrary(geodata)\nlibrary(dismo)\nlibrary(lubridate)\nlibrary(sdmpredictors)\nlibrary(ggplot2)\nlibrary(cmocean)\nlibrary(janitor)\nlibrary(DT)\nlibrary(here)\nlibrary(rnaturalearth)\nlibrary(rnaturalearthdata)\nlibrary(raster)\nlibrary(ggspatial)\nlibrary(tidyverse)\nlibrary(robis)\n})\n\nTell R that the root should be where this RMarkdown file resides. All our data files will be stored here.\n\nsdm_dir &lt;- \"SDM\"\nhere::i_am(paste0(sdm_dir,\"/Turtle_maxnet.Rmd\"))\n\nhere() starts at /Users/eli.holmes/Documents/GitHub/tutorials_marine_sdm",
    "crumbs": [
      "Full SDM",
      "Maxnet"
    ]
  },
  {
    "objectID": "SDM/Turtle_maxnet.html#set-up-the-spatial-region",
    "href": "SDM/Turtle_maxnet.html#set-up-the-spatial-region",
    "title": "Maxent SDM",
    "section": "Set up the spatial region",
    "text": "Set up the spatial region\n\nCreate a bounding box\nWe create a bounding box using minimum and maximum coordinate pairs and assign a standared WGS 84 coordinate reference system. This creates a sfs_POLYGON.\n\nextent_polygon &lt;- sf::st_bbox(c(xmin = 41.875, xmax = 65.125, \n                            ymax = -0.125, ymin = 32.125), \n                          crs = sf::st_crs(4326)) %&gt;% \n  sf::st_as_sfc()\n\nSave the bounding box for future use.\n\nfil &lt;- here::here(sdm_dir, \"sdm_data\", \"BoundingBox.shp\")\nsf::write_sf(extent_polygon, fil)\n\nGet the polygon in text format.\n\npol_geometry &lt;- sf::st_as_text(extent_polygon[[1]])\npol_geometry\n\n[1] \"POLYGON ((41.875 32.125, 65.125 32.125, 65.125 -0.125, 41.875 -0.125, 41.875 32.125))\"\n\n\n\n\nCreate a world map with our region\nThis allows us to check our polygon of interest is located in the correct region.\n\n#Getting base map\nworld &lt;- rnaturalearth::ne_countries(scale = \"medium\", returnclass = \"sf\")\n\n#Plotting map\nworld_box &lt;- ggplot() + \n  #Adding base map\n  geom_sf(data = world) +\n  #Adding bounding box\n  geom_sf(data = extent_polygon, color = \"red\", fill = NA)+\n  #Setting theme of plots to not include a grey background\n  theme_bw()\n\nworld_box\n\n\n\n\nSave the plot.\n\nfil &lt;- here::here(sdm_dir,  \"sdm_data\", \"world_box.rda\")\nsave(world_box, file=fil)\n\n\n\nCreate a region map\nCreate a base map of our region and save it.\n\nbase_region_map &lt;- ggplot()+\n  #Adding base layer (world map)\n  geom_sf(data = world, fill = \"antiquewhite\")+\n  #Constraining map to original bounding box\n  lims(x = c(st_bbox(extent_polygon)$xmin, sf::st_bbox(extent_polygon)$xmax),\n       y = c(sf::st_bbox(extent_polygon)$ymin, sf::st_bbox(extent_polygon)$ymax))\nbase_region_map\n\n\n\n\nSave it\n\nfil &lt;- here::here(sdm_dir,  \"sdm_data\", \"base_region_map.rda\")\nsave(base_region_map, file=fil)\n\nWe will add some more features to our map: colors, scale and compass.\n\nregion_map &lt;- base_region_map +\n  #Add scale bar on the top right of the plot\n  annotation_scale(location = \"tr\", width_hint = 0.5)+\n  #Add north arrow on the top left of plot\n  annotation_north_arrow(location = \"tl\", which_north = \"true\",\n                         #Include small buffer from plot edge\n                         pad_x = unit(0.01, \"in\"), pad_y = unit(0.05, \"in\"),\n                         #Set style of north arrow\n                         style = north_arrow_fancy_orienteering) +\n  #Changing color, type and size of grid lines\n  theme(panel.grid.major = element_line(color = gray(.5), linetype = \"dashed\", size = 0.5), \n  #Change background of map\n  panel.background = element_rect(fill = \"aliceblue\")) +\n  labs(x = \"longitude\", y = \"latitude\")\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\nregion_map\n\nScale on map varies by more than 10%, scale bar may be inaccurate\n\n\n\n\n\nSave.\n\nfil &lt;- here::here(sdm_dir,  \"sdm_data\", \"region_map.rda\")\nsave(region_map, file=fil)\n\nWe add some labels for the countries.\n\n#Extracting labels for countries in base map\nworld_points &lt;- world %&gt;% \n  sf::st_make_valid(world) %&gt;%\n  #Getting centroids for all polygons in the world base map\n  sf::st_centroid(geometry) %&gt;% \n  #Getting coordinates for each centroid\n  sf::st_coordinates() %&gt;% \n  #Adding centroids to original base map\n  dplyr::bind_cols(world)\n\n#Do not use spherical geometry\nsf::sf_use_s2(FALSE)\n\n#Adding labels to map\nregion_map_label &lt;- region_map +\n  geom_text(data = world_points, \n            #Point to coordinates and column with country names\n            aes(x = X, y = Y, label = name),\n            #Changing color and size of labels\n            color = \"darkblue\", size = 3, \n            #Avoid label overlap\n            check_overlap = TRUE)\n# Save\nfil &lt;- here::here(sdm_dir,  \"sdm_data\",  \"region_map_label.rda\")\nsave(region_map_label, file=fil)\n\n#Checking final map\nregion_map_label\n\n\n\n\n\n\nLoading in the saved files\nLater when we need the extent polygon, we use\n\n#Loading bounding box for the area of interest\nfil &lt;- here::here(sdm_dir, \"sdm_data\", \"BoundingBox.shp\")\nextent_polygon &lt;- sf::read_sf(fil)\n\nWe often will need a sf bbox (bounding box object). To create that use\n\nbbox &lt;- sf::st_bbox(extent_polygon)\n\nWe load the maps as\n\nfil &lt;- here::here(sdm_dir, \"sdm_data\", \"region_map_label.rda\")\nload(fil)",
    "crumbs": [
      "Full SDM",
      "Maxnet"
    ]
  },
  {
    "objectID": "SDM/Turtle_maxnet.html#get-occurrence-data-from-robis",
    "href": "SDM/Turtle_maxnet.html#get-occurrence-data-from-robis",
    "title": "Maxent SDM",
    "section": "Get occurrence data from robis",
    "text": "Get occurrence data from robis\npol_geometry is defined above.\n\npol_geometry\n\n[1] \"POLYGON ((41.875 32.125, 65.125 32.125, 65.125 -0.125, 41.875 -0.125, 41.875 32.125))\"\n\n\nGet the data. We use eval=redo so that we do not redownload data if we do not need to.\n\nredo &lt;- FALSE\n\nSet the species we want\n\nspp &lt;- c(\"Chelonia mydas\", \"Caretta caretta\", \"Eretmochelys imbricata\", \"Lepidochelys olivacea\", \"Natator depressus\", \"Dermochelys coriacea\")\n\nDownload the data.\n\nobs &lt;- robis::occurrence(spp, startdate = as.Date(\"2000-01-01\"), geometry = pol_geometry)\n\nThis has many columns that we don’t need. We reduce to fewer columns.\n\ncols.to.use &lt;- c(\"occurrenceID\", \"scientificName\", \n                 \"dateIdentified\", \"eventDate\", \n                 \"decimalLatitude\", \"decimalLongitude\", \"coordinateUncertaintyInMeters\",\n                 \"individualCount\",\"lifeStage\", \"sex\",\n                 \"bathymetry\",  \"shoredistance\", \"sst\", \"sss\")\nobs &lt;- obs[,cols.to.use]\n\nWe also add a cleaner date with YYYY-MM-DD format.\n\nobs$date &lt;- as.Date(obs$eventDate)\n\nSave our data.\n\nobs_csv &lt;- here::here(sdm_dir,  \"sdm_data\", \"sdm_data_all.csv\")\nreadr::write_csv(obs, obs_csv)\n\n\nClean and prep data\nClean and prepare the data for our model and save to a new file name.\nLoad data in\n\n# presence data\nfil &lt;- here::here(sdm_dir, \"sdm_data\", \"occ_all.csv\")\nocc_all &lt;- read.csv(fil)\n\nWe will call the cleaned data occ.\n\n# subset the occurences to include just those in the water\nocc &lt;- occ_all %&gt;% \n  subset(bathymetry &gt; 0 & \n        shoredistance &gt; 0 & \n        coordinateUncertaintyInMeters &lt; 200)\n\n# seeing how often each species occurs\ntable(occ$scientificName) \n\n\nCaretta caretta  Chelonia mydas \n           5141            7060 \n\n\nAfter cleaning we discover that we only have loggerhead and green sea turtles. Also there are only juvenile loggerheads and we do not know the life-stage of the green turtles.\n\ntable(occ$lifeStage, occ$scientificName, useNA=\"ifany\")\n\n          \n           Caretta caretta Chelonia mydas\n  Juvenile            5141              0\n  &lt;NA&gt;                   0           7060\n\n\nSelect columns and add a common name column.\n\ncolnames(occ)\n\n [1] \"occurrenceID\"                  \"scientificName\"               \n [3] \"dateIdentified\"                \"eventDate\"                    \n [5] \"decimalLatitude\"               \"decimalLongitude\"             \n [7] \"coordinateUncertaintyInMeters\" \"individualCount\"              \n [9] \"lifeStage\"                     \"sex\"                          \n[11] \"bathymetry\"                    \"shoredistance\"                \n[13] \"sst\"                           \"sss\"                          \n[15] \"date\"                         \n\n\nWe want these. The last two are sea surface temperature and salinity.\n\ncols &lt;- c(\"scientificName\", \"date\", \"decimalLatitude\", \"decimalLongitude\", \"lifeStage\", \"bathymetry\", \"sst\", \"sss\")\n\nSubset the columns.\n\nocc.sub &lt;- occ %&gt;% dplyr::select(all_of(cols))\n\nChange the column names.\n\ncolnames(occ.sub) &lt;- c(\"sci.name\", \"date\", \"lat\", \"lon\", \"life.stage\", \"bathy\", \"SST\", \"SSS\")\n\nAdd common.name column.\n\nocc.sub &lt;- occ.sub %&gt;% \n  mutate(common.name = case_when(sci.name == \"Caretta caretta\" ~ \"Loggerhead\",\n                                 sci.name == \"Chelonia mydas\" ~ \"Green\"))\n\nSave the cleaned file\n\nfil &lt;- here::here(sdm_dir,  \"sdm_data\", \"occ_clean.csv\")\nif (redo) readr::write_csv(occ.sub, fil)",
    "crumbs": [
      "Full SDM",
      "Maxnet"
    ]
  },
  {
    "objectID": "SDM/Turtle_maxnet.html#create-background-data",
    "href": "SDM/Turtle_maxnet.html#create-background-data",
    "title": "Maxent SDM",
    "section": "Create background data",
    "text": "Create background data\nWe will get random samples from our region.\n\nGet a marine raster layer\nWe just need one because we use this to sample lat/lons from the marine environment. sdmpredictors will download many files so we need to specify a directory.\n\n# set a default data directory\noptions(sdmpredictors_datadir = here::here(sdm_dir, \"sdm_data\"))\n\n# choosing marine\nenv_datasets &lt;- sdmpredictors::list_datasets(terrestrial = FALSE, marine = TRUE)\nenv_stack &lt;- sdmpredictors::load_layers(\"MS_bathy_5m\")\nenv_stack &lt;- env_stack %&gt;% raster::crop(extent_polygon)\n\nPlot to check that the layer looks ok. This is bathymetry.\n\nplot(env_stack)\n\n\n\n\nLook at the raster to get some info on it.\n\nenv_stack\n\nclass      : RasterBrick \ndimensions : 388, 280, 108640, 1  (nrow, ncol, ncell, nlayers)\nresolution : 0.08333333, 0.08333333  (x, y)\nextent     : 41.83333, 65.16667, -0.1666667, 32.16667  (xmin, xmax, ymin, ymax)\ncrs        : +proj=longlat +datum=WGS84 +no_defs \nsource     : memory\nnames      : MS_bathy_5m \nmin values :       -5468 \nmax values :          -1 \n\n\n\n\nSample points from this\nIt returns a sf points object.\n\nnsamp &lt;- 1000\nabsence &lt;- dismo::randomPoints(env_stack[[1]], nsamp)\ncolnames(absence) &lt;- c(\"lon\", \"lat\")\n\nMake a plot.\n\nabsence_sf &lt;- absence %&gt;% \n    as_tibble() %&gt;% \n    sf::st_as_sf(coords = c(x=\"lon\", y=\"lat\"), crs = 4326)\nmapview::mapview(absence_sf, col.regions = \"gray\")\n\nWarning in cbind(`Feature ID` = fid, mat): number of rows of result is not a\nmultiple of vector length (arg 1)\n\n\n\n\n\n\nSave the absence locations to a file.\n\nfil &lt;- here::here(sdm_dir,  \"sdm_data\", \"absence.csv\")\nwrite.csv(absence, file=fil, row.names = FALSE)",
    "crumbs": [
      "Full SDM",
      "Maxnet"
    ]
  },
  {
    "objectID": "SDM/Turtle_maxnet.html#download-sdmpredictors-layers",
    "href": "SDM/Turtle_maxnet.html#download-sdmpredictors-layers",
    "title": "Maxent SDM",
    "section": "Download sdmpredictors layers",
    "text": "Download sdmpredictors layers\nSet datasets to marine.\n\ndatasets &lt;- sdmpredictors::list_datasets(terrestrial = FALSE, marine = TRUE)\nlayers &lt;- list_layers(datasets)\n#View(layers) # if you want to view\n\nChoose layers.\n\nlayercodes = c(\"BO_sstmean\", \"BO_bathymean\", \"BO22_ph\", \"BO2_dissoxmean_bdmean\", \"BO2_salinitymean_ss\", \"BO2_chlomean_ss\", \"BO21_nitratemean_ss\")\n\nDownload layers.\n\nenv &lt;- sdmpredictors::load_layers(layercodes, rasterstack = TRUE)\nenv_crop &lt;- env %&gt;% raster::crop(extent_polygon)\n\nLook at our layers.\n\nplot(env_crop)\n\n\n\n\nSave the raster brick for later reloading.\n\nenv.stars &lt;- stars::st_as_stars(env_crop) # convert to stars object\nfil &lt;- here::here(sdm_dir,  \"sdm_data\", \"env_stack.tif\")\nstars::write_stars(env.stars, fil)\n#y &lt;- stars::read_stars(fil)\n# We need to do this for sampling\nenv.stars &lt;- terra::split(env.stars)",
    "crumbs": [
      "Full SDM",
      "Maxnet"
    ]
  },
  {
    "objectID": "SDM/Turtle_maxnet.html#environmental-predictors-for-points",
    "href": "SDM/Turtle_maxnet.html#environmental-predictors-for-points",
    "title": "Maxent SDM",
    "section": "Environmental predictors for points",
    "text": "Environmental predictors for points\nWe will use the stars package to sample from our raster layers.\nLoad in our point data as data frames.\n\n# presence data\nfil &lt;- here::here(sdm_dir, \"sdm_data\", \"occ_clean.csv\")\ndf.occ &lt;- read.csv(fil) \n\n# absence data\nfil &lt;- here::here(sdm_dir, \"sdm_data\", \"absence.csv\")\ndf.abs &lt;- read.csv(fil)\n\nConvert data frames to sf points objects. This is what stars needs.\n\ndf.abs &lt;- na.omit(df.abs) # just in case\nsf.abs &lt;- sf::st_as_sf(df.abs, coords = c(\"lon\", \"lat\"), crs = 4326)\nsf.occ &lt;- sf::st_as_sf(df.occ, coords = c(\"lon\", \"lat\"), crs = 4326)\n\nGet environment values for the absence points. Each row in sf.abs is a row in env.abs.\n\nenv.abs &lt;- stars::st_extract(env.stars, sf::st_coordinates(sf.abs)) %&gt;% \n  dplyr::as_tibble() %&gt;% \n  na.omit()\n\nhead(env.abs)\n\n# A tibble: 6 × 7\n  BO_sstmean BO_bathymean BO22_ph BO2_dissoxmean_bdmean BO2_salinitymean_ss\n       &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;                 &lt;dbl&gt;               &lt;dbl&gt;\n1       27.7        -4108    8.19                161.                  36.0\n2       29.6        -4243    8.19                176.                  35.2\n3       27.1        -3462    8.13                128.                  36.5\n4       26.1          -52    8.14                219.                  38.9\n5       26.4        -3037    8.14                135.                  36.1\n6       26.3         -856    8.13                  4.43                36.2\n# ℹ 2 more variables: BO2_chlomean_ss &lt;dbl&gt;, BO21_nitratemean_ss &lt;dbl&gt;\n\n\nGet environment values for the occurence points. Each row in sf.occ is a row in env.occ.\n\nenv.occ &lt;- stars::st_extract(env.stars, sf::st_coordinates(sf.occ)) %&gt;% \n  dplyr::as_tibble() %&gt;% \n  na.omit()\n\nhead(env.occ)\n\n# A tibble: 6 × 7\n  BO_sstmean BO_bathymean BO22_ph BO2_dissoxmean_bdmean BO2_salinitymean_ss\n       &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;                 &lt;dbl&gt;               &lt;dbl&gt;\n1       26.4          -59    8.17                  183.                35.6\n2       28.6        -3158    8.18                  154.                35.7\n3       26.4          -92    8.17                  145.                35.6\n4       26.8        -2764    8.15                  130.                36.1\n5       27.9           -4    8.13                  198.                38.7\n6       27.6           -8    8.13                  198.                38.7\n# ℹ 2 more variables: BO2_chlomean_ss &lt;dbl&gt;, BO21_nitratemean_ss &lt;dbl&gt;\n\n\nNow make this into one data frame with a pa column for 1 is a occurrence row and 0 if an absence row.\n\npres &lt;- c(rep(1, nrow(env.occ)), rep(0, nrow(env.abs)))\nsdm_data &lt;- data.frame(pa = pres, rbind(env.occ, env.abs))\nhead(sdm_data)\n\n  pa BO_sstmean BO_bathymean BO22_ph BO2_dissoxmean_bdmean BO2_salinitymean_ss\n1  1     26.431          -59   8.173              182.6581            35.63274\n2  1     28.648        -3158   8.181              154.3245            35.73521\n3  1     26.428          -92   8.173              145.4299            35.64719\n4  1     26.822        -2764   8.148              130.0710            36.09258\n5  1     27.851           -4   8.133              197.8163            38.67305\n6  1     27.585           -8   8.133              197.6590            38.71139\n  BO2_chlomean_ss BO21_nitratemean_ss\n1        0.337094            2.043796\n2        0.107879            0.132562\n3        0.343290            2.086616\n4        0.217175            0.615217\n5        0.140721            0.000003\n6        0.141303            0.000003\n\n\nSave to a file. We will use for other models.\n\nfil &lt;- here::here(sdm_dir,  \"sdm_data\",  \"sdm_data.csv\")\nwrite.csv(sdm_data, row.names = FALSE, file=fil)",
    "crumbs": [
      "Full SDM",
      "Maxnet"
    ]
  },
  {
    "objectID": "SDM/Turtle_maxnet.html#fit-maxnet-model",
    "href": "SDM/Turtle_maxnet.html#fit-maxnet-model",
    "title": "Maxent SDM",
    "section": "Fit Maxnet model",
    "text": "Fit Maxnet model\nmaxnet::maxnet(pres, environ)\n\npres string of 1s and 0s for whether the row is a occurrence or a absence.\nenviron a data frame of the environmental variables only\n\n\npres &lt;- sdm_data$pa\nenviron &lt;- sdm_data %&gt;% dplyr::select(-pa)\nsdm.model &lt;- maxnet::maxnet(pres, environ)\n\n\nModel metrics\n\nresponses &lt;- plot(sdm.model, type = \"cloglog\")\n\n\n\n\nWe have some bathymetry values &gt; 0 which might be a problem.\n\ntable(environ$BO_bathymean&gt;0)\n\n\nFALSE  TRUE \n12617   277",
    "crumbs": [
      "Full SDM",
      "Maxnet"
    ]
  },
  {
    "objectID": "SDM/Turtle_maxnet.html#predicting",
    "href": "SDM/Turtle_maxnet.html#predicting",
    "title": "Maxent SDM",
    "section": "Predicting",
    "text": "Predicting\n\nclamp &lt;- TRUE       # see ?predict.maxnet for details\ntype &lt;- \"cloglog\"\nbb &lt;- sf::st_bbox(extent_polygon) # make a sf bounding box \npredicted &lt;- predict(sdm.model, \n                     env.stars %&gt;% sf::st_crop(bb), \n                     clamp = clamp, type = type)\n\nalthough coordinates are longitude/latitude, st_intersects assumes that they\nare planar\n\npredicted\n\nstars object with 2 dimensions and 1 attribute\nattribute(s):\n             Min.   1st Qu.    Median     Mean   3rd Qu.      Max.  NA's\npred  0.003818902 0.1137863 0.1655903 0.174387 0.2148277 0.9999996 52802\ndimension(s):\n  from  to offset    delta                       refsys x/y\nx    1 280  41.83  0.08333 +proj=longlat +datum=WGS8... [x]\ny    1 388  32.17 -0.08333 +proj=longlat +datum=WGS8... [y]",
    "crumbs": [
      "Full SDM",
      "Maxnet"
    ]
  },
  {
    "objectID": "SDM/Turtle_maxnet.html#visualization",
    "href": "SDM/Turtle_maxnet.html#visualization",
    "title": "Maxent SDM",
    "section": "Visualization",
    "text": "Visualization\nWe can plot the predictions like so, but the default palette is not great and are map is distorted.\n\nggplot() +\n    geom_stars(data = predicted)\n\n\n\n\nWe can try the cmocean palette and fix the coordinates.\n\nggplot() +\n  geom_stars(data = predicted) +\n  scale_fill_cmocean() +\n  coord_equal()\n\n\n\n\nOr other palettes and annotation.\n\npredplot &lt;- ggplot() +\n  geom_stars(data = predicted) +\n  scale_fill_cmocean(name = \"ice\", direction = -1, guide = guide_colorbar(barwidth = 1, barheight = 10, ticks = FALSE, nbin = 1000, frame.colour = \"black\"), limits = c(0, 1)) +\n  theme_linedraw() +\n  coord_equal() +\n  theme(panel.background = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank()) +\n  labs(title = \"Loggerhead and green sea turtle SDM in the Arabian Sea\",\n       x = \"Longitude\",\n       y = \"Latitude\",\n       fill = \"Probability\",\n       shape = \"Species (presence)\",\n       subtitle = \"Environmental predictors: mean SS temp, mean SS salinity, mean bathymetry, \\nmean pH, mean DO, mean SS chlorophyll-a, mean SS nitrate\")\n\npredplot\n\n\n\n# ggsave(\"SDM_loggerhead_green_w points.pdf\", height = 6, width = 8.5)\n\nWithout the occurrence data points.\n\npredplot +\n  geom_point(sf.occ, mapping = aes(shape = common.name, geometry = geometry), stat = \"sf_coordinates\", alpha = 0.3, color = \"purple\") +\n  geom_point(sf.abs, mapping = aes(geometry = geometry), stat = \"sf_coordinates\", alpha = 0.3, color = \"green\")\n\n\n\n# ggsave(\"SDM_loggerhead_green.pdf\", height = 6, width = 8.5)",
    "crumbs": [
      "Full SDM",
      "Maxnet"
    ]
  },
  {
    "objectID": "SDM/Turtle_maxnet.html#discussion",
    "href": "SDM/Turtle_maxnet.html#discussion",
    "title": "Maxent SDM",
    "section": "Discussion",
    "text": "Discussion\nWe did not do much cleaning of the data and we combined loggerheads and green sea turtles. We should separate these. Also some of the data are clearly tagging data and we should subsample that data to remove some of the temporal autocorrelation. We should also experiment with higher and lower numbers of background points.",
    "crumbs": [
      "Full SDM",
      "Maxnet"
    ]
  },
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "Marine SDMs",
    "section": "",
    "text": "Authors: Catherine Courtier, Mackenzie Fiss, Denisse Fierro Arcos, Paulo Freire, Jade Hong, Caitlin O’Brien, Mary Solokas, Laura Tsang, Eli Holmes, Tylar Murray, Ben Tupper\nClick to hear our song! Inspired by Myranda and AI!\n\n\n\n(Chorus) Under the sea, where turtles roam so free, Using models to unlock their mystery, Species distribution, a vital contribution, In the Arabian Sea, our quest for clarity!",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#marine-species-distribution-model-sdm-tutorial",
    "href": "index.html#marine-species-distribution-model-sdm-tutorial",
    "title": "Marine SDMs",
    "section": "",
    "text": "Authors: Catherine Courtier, Mackenzie Fiss, Denisse Fierro Arcos, Paulo Freire, Jade Hong, Caitlin O’Brien, Mary Solokas, Laura Tsang, Eli Holmes, Tylar Murray, Ben Tupper\nClick to hear our song! Inspired by Myranda and AI!\n\n\n\n(Chorus) Under the sea, where turtles roam so free, Using models to unlock their mystery, Species distribution, a vital contribution, In the Arabian Sea, our quest for clarity!",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "Marine SDMs",
    "section": "Overview",
    "text": "Overview\nThis tutorial was developed during OceanHackWeek2023 to provide a simple workflow to developing a marine Species Distribution Model (SDM) using R programming.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "Marine SDMs",
    "section": "Background",
    "text": "Background\nSpecies Distribution Modelling (SDM) also known as niche/environmental/ecological modelling uses an algorithm to predict the distribution of a species across space and time using environmental data. An understanding of the relationship between the species of interest and the physical environment they occupy will inform the selection of relevant environmental factors that will be included in the model.\nBiotic information is also needed by SDMs and at the very least locations of individuals are needed. Abundance or densities can also be used as inputs, but are not compulsory. It is worth noting that absences, that is, the locations where individuals of a species are NOT present is just as important because it provides information about the environmental conditions where individuals are not usually sighted. Often absences are not recorded in biological data, but we can use background points (also known as pseudo-absences), which provide information about the full range of environmental conditions available for the species interest in our study area.\nFor a review of the performance of different SDM algorithms, see the following publications:\n- Valavi, Guillera-Arroita, Lahoz-Monfort, Elith (2021). Predictive performance of presence-only species distribution models: a benchmark study with reproducible code. DOI: 10.1002/ecm.1486\n\nElith et al (2006). Novel methods improve prediction of species’ distributions from occurrence data. DOI: 10.1111/j.2006.0906-7590.04596.x",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#goals",
    "href": "index.html#goals",
    "title": "Marine SDMs",
    "section": "Goals",
    "text": "Goals\nMany tutorials exist to run SDM models, however, most readily available tutorials focus on terrestrial-based models. Our goal through this tutorial is to highlight a marine-based SDM tutorial.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#datasets",
    "href": "index.html#datasets",
    "title": "Marine SDMs",
    "section": "Datasets",
    "text": "Datasets\n\nBiological Data\nOur dataset includes biological presence-only data of four species of sea turtles found in the Indian Ocean. The four species of sea turtles included in our tutorial are:\n- Loggerhead, Caretta caretta - Green, Chelonia mydas - Olive Ridley, Lepidochelys olivacea - Hawksbill, Eretmochelys imbricata\nHowever, for this tutorial example model, we will focus on Loggerhead sea turtles data from 2000 until 2023 sourced from the Ocean Biodiversity Information System (OBIS) via the robis package.\n\n\nEnvironmental Data\nThis tutorial focuses on regions in the northern Indian Sea, specifically the western Arabian Sea, Persian Gulf, Gulf of Oman, Gulf of Aden and Red Sea. Environmental predictor variables were sourced via the SMDpredictor R package and includes:\n\n(https://oceanhackweek.org/ohw23_proj_marinesdms/tutorial/03_sdmpredictors-variables.html)",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#workflowroadmap",
    "href": "index.html#workflowroadmap",
    "title": "Marine SDMs",
    "section": "Workflow/Roadmap",
    "text": "Workflow/Roadmap\nThis tutorial is based on the notes by Ben Tupper (Biglow Lab, Maine), and highlights modeling presence-only data via maxnet R package.\nTutorial roadmap\n\nPresence Data – obtain sea turtle data via robis\nAbsence Data – obtain random occurances within our area of interest using robis\nEnvironmental Data – obtain environmental predictors of interest using SDMpredictors\nModel – run species distribution model and predict using maxnet\nData Visualizations",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "Marine SDMs",
    "section": "References",
    "text": "References\n\nBosch S, Fernandez S (2022). sdmpredictors: Species Distribution Modelling Predictor Datasets. R package version 0.2.14, http://lifewatch.github.io/sdmpredictors/.\nOBIS (2023) Ocean Biodiversity Information System. Intergovernmental Oceanographic Commission of UNESCO. www.obis.org. Accessed: 2023-08-08.\nSteven J. Phillips, Miroslav Dudík, Robert E. Schapire. [Internet] Maxent software for modeling species niches and distributions (Version 3.4.1). Available from url: http://biodiversityinformatics.amnh.org/open_source/maxent/. Accessed on 2023-08-10.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#tutorial-developers",
    "href": "index.html#tutorial-developers",
    "title": "Marine SDMs",
    "section": "Tutorial developers",
    "text": "Tutorial developers\n\nCatherine Courtier:\nMackenzie Fiss: Third-year PhD student at Northeastern University studying marine biogeochemistry (DOM) and microbial ecology.\nDenisse Fierro Arcos: PhD candidate at the Institute for Marine and Antarctic Studies (IMAS) and Data Officer at the Integrated Marine Observing System (IMOS)\n\nPaulo Freire: PhD candidate at the University of North Carolina at Charlotte (UNCC) studying marine microbial ecology.\nEli Holmes: Research Fisheries Biologist, Northwest Fisheries Science Center, NOAA Fisheries.\n\nJade Hong: Recently finished ungraduate studies majoring Biology and Marine Science at Boston University.\nTylar Murray: USF IMaRS Software Engineer - code whisperer, data viz enthusiast, scientific generalist, compulsive overengineerer, & UX PhD\n\nCaitlin O’Brien: Research Scientist, Columbia Basin Research, School of Aquatic Fishery and Sciences, University of Washington\nCollins Ongore\nMary Solokas: John A. Knauss Marine Policy Fellow, National Oceanic and Atmospheric Administration\nLaura Tsang:\nBen Tupper: Senior Research Associate at Bigelow Laboratory for Ocean Science",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#who-this-tutorial-is-intended",
    "href": "index.html#who-this-tutorial-is-intended",
    "title": "Marine SDMs",
    "section": "Who this tutorial is intended:",
    "text": "Who this tutorial is intended:\nSome experience programming in R is needed to make the most of this tutorial. To run this tutorial make sure you clone this repository into your local machine by creating a new project that uses version control (git).\nThe tutorial content was developed in a R version 4.2.2 for Linux. Full session information is included below:\nR version 4.2.2 (2022-10-31)\nPlatform: x86_64-conda-linux-gnu (64-bit)\nRunning under: Debian GNU/Linux 11 (bullseye)\n\nMatrix products: default\nBLAS/LAPACK: /opt/conda/lib/libopenblasp-r0.3.21.so\n\nlocale:\n [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8       \n [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8   \n [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C          \n[10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C   \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n[1] compiler_4.2.2 tools_4.2.2",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "index.html#additional-resources",
    "href": "index.html#additional-resources",
    "title": "Marine SDMs",
    "section": "Additional resources",
    "text": "Additional resources\nIf you need additional support with R programming, you can check the following resources:\n- R for Data Science - 2nd edition by Wickham, Çetinkaya-Rundel and Grolemund.\n- Data analysis and visualisation in R for ecologists\nFor information on how to use git and GitHub with R, Happy Git and GitHub for the useR by Jenny Bryan is a great resource.",
    "crumbs": [
      "Welcome"
    ]
  },
  {
    "objectID": "tutorial/00_Region.html",
    "href": "tutorial/00_Region.html",
    "title": "Setting up the region",
    "section": "",
    "text": "As a preliminary, we will define some shape files and plots of our region that we will use in later steps.",
    "crumbs": [
      "Background",
      "Region"
    ]
  },
  {
    "objectID": "tutorial/00_Region.html#load-libraries",
    "href": "tutorial/00_Region.html#load-libraries",
    "title": "Setting up the region",
    "section": "Load libraries",
    "text": "Load libraries\n\n#Dealing with spatial data\nlibrary(sf)\n#Getting base maps\nlibrary(rnaturalearth)\n#Data manipulation and visualisation\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(ggspatial)",
    "crumbs": [
      "Background",
      "Region"
    ]
  },
  {
    "objectID": "tutorial/00_Region.html#create-a-bounding-box",
    "href": "tutorial/00_Region.html#create-a-bounding-box",
    "title": "Setting up the region",
    "section": "Create a bounding box",
    "text": "Create a bounding box\nWe will use a bounding box for the region of our interest (Arabian Sea and the Bay of Bengal) to extract C. caretta data relevant to our study area.\n\n#We create a bounding box using minimum and maximum coordinate pairs\nextent_polygon &lt;- st_bbox(c(xmin = 41.875, xmax = 65.125, \n                            ymax = -0.125, ymin = 32.125), \n                          #Assign reference system\n                          crs = st_crs(4326)) %&gt;% \n  #Turn into sf object\n  st_as_sfc()\n\n#Extract polygon geometry \npol_geometry &lt;- st_as_text(extent_polygon[[1]])\n\n#Saving bounding box for future use\nfil &lt;- here::here(\"data\", \"region\", \"BoundingBox.shp\")\nwrite_sf(extent_polygon, fil)",
    "crumbs": [
      "Background",
      "Region"
    ]
  },
  {
    "objectID": "tutorial/00_Region.html#create-a-world-map",
    "href": "tutorial/00_Region.html#create-a-world-map",
    "title": "Setting up the region",
    "section": "Create a world map",
    "text": "Create a world map\nWe can create a world map to show where our study region is. ### Plotting region of interest This allows us to check our polygon of interest is located in the correct region.\n\n#Getting base map\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\n#Plotting map\nworld_box &lt;- ggplot() + \n  #Adding base map\n  geom_sf(data = world) +\n  #Adding bounding box\n  geom_sf(data = extent_polygon, color = \"red\", fill = NA)+\n  #Setting theme of plots to not include a grey background\n  theme_bw()\nfil &lt;- here::here(\"data\", \"region\", \"world_box.rda\")\nsave(world_box, file=fil)\n\nworld_box",
    "crumbs": [
      "Background",
      "Region"
    ]
  },
  {
    "objectID": "tutorial/00_Region.html#create-a-region-map",
    "href": "tutorial/00_Region.html#create-a-region-map",
    "title": "Setting up the region",
    "section": "Create a region map",
    "text": "Create a region map\nFirst we create a base map of our region and save it.\n\nbase_region_map &lt;- ggplot()+\n  #Adding base layer (world map)\n  geom_sf(data = world, fill = \"antiquewhite\")+\n  #Constraining map to original bounding box\n  lims(x = c(st_bbox(extent_polygon)$xmin, st_bbox(extent_polygon)$xmax),\n       y = c(st_bbox(extent_polygon)$ymin, st_bbox(extent_polygon)$ymax))\nfil &lt;- here::here(\"data\", \"region\", \"base_region_map.rda\")\nsave(base_region_map, file=fil)\n\nbase_region_map\n\n\n\n\nWe will add some more features to our map: colors, scale and compass.\n\nregion_map &lt;- base_region_map +\n  #Add scale bar on the top right of the plot\n  annotation_scale(location = \"tr\", width_hint = 0.5)+\n  #Add north arrow on the top left of plot\n  annotation_north_arrow(location = \"tl\", which_north = \"true\",\n                         #Include small buffer from plot edge\n                         pad_x = unit(0.01, \"in\"), pad_y = unit(0.05, \"in\"),\n                         #Set style of north arrow\n                         style = north_arrow_fancy_orienteering) +\n  #Changing color, type and size of grid lines\n  theme(panel.grid.major = element_line(color = gray(.5), linetype = \"dashed\", size = 0.5), \n  #Change background of map\n  panel.background = element_rect(fill = \"aliceblue\")) +\n  labs(x = \"longitude\", y = \"latitude\")\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\nfil &lt;- here::here(\"data\", \"region\", \"region_map.rda\")\nsave(region_map, file=fil)\n\nregion_map\n\nScale on map varies by more than 10%, scale bar may be inaccurate\n\n\n\n\n\nWe add some labels for the countries.\n\n#Extracting labels for countries in base map\nworld_points &lt;- world %&gt;% \n  st_make_valid(world) %&gt;%\n  #Getting centroids for all polygons in the world base map\n  st_centroid(geometry) %&gt;% \n  #Getting coordinates for each centroid\n  st_coordinates() %&gt;% \n  #Adding centroids to original base map\n  bind_cols(world)\n\n#Do not use spherical geometry\nsf_use_s2(FALSE)\n\n#Adding labels to map\nregion_map_label &lt;- region_map +\n  geom_text(data = world_points, \n            #Point to coordinates and column with country names\n            aes(x = X, y = Y, label = name),\n            #Changing color and size of labels\n            color = \"darkblue\", size = 3, \n            #Avoid label overlap\n            check_overlap = TRUE)\nfil &lt;- here::here(\"data\", \"region\", \"region_map_label.rda\")\nsave(region_map_label, file=fil)\n\n#Checking final map\nregion_map_label",
    "crumbs": [
      "Background",
      "Region"
    ]
  },
  {
    "objectID": "tutorial/01_Presence_Data.html",
    "href": "tutorial/01_Presence_Data.html",
    "title": "Obtaining presence data for loggerhead turtles from OBIS",
    "section": "",
    "text": "In this section, we will explore Loggerhead sea turtle (Caretta caretta) data from 2000 until present from the Ocean Biodiversity Information System (OBIS). We will use the robis package to search the OBIS library and download relevant data. We will then check for quality control flags and remove problematic observations from the data (i.e., sea turtle observations on land).",
    "crumbs": [
      "Background",
      "Presence data"
    ]
  },
  {
    "objectID": "tutorial/01_Presence_Data.html#load-libraries",
    "href": "tutorial/01_Presence_Data.html#load-libraries",
    "title": "Obtaining presence data for loggerhead turtles from OBIS",
    "section": "Load libraries",
    "text": "Load libraries\n\n#Dealing with spatial data\nlibrary(sf)\n#Getting base maps\nlibrary(rnaturalearth)\n#Access to OBIS\nlibrary(robis)\n#Data manipulation and visualisation\nlibrary(tidyverse)\nlibrary(janitor)",
    "crumbs": [
      "Background",
      "Presence data"
    ]
  },
  {
    "objectID": "tutorial/01_Presence_Data.html#load-the-region-data",
    "href": "tutorial/01_Presence_Data.html#load-the-region-data",
    "title": "Obtaining presence data for loggerhead turtles from OBIS",
    "section": "Load the region data",
    "text": "Load the region data\nWe defined our region and bounding box in the Region page.\nLoad the bounding box.\n\n#Loading bounding box for the area of interest\nfil &lt;- here::here(\"data\", \"region\", \"BoundingBox.shp\")\nextent_polygon &lt;- read_sf(fil)\n\n#Extract polygon geometry \npol_geometry &lt;- st_as_text(extent_polygon$geometry)",
    "crumbs": [
      "Background",
      "Presence data"
    ]
  },
  {
    "objectID": "tutorial/01_Presence_Data.html#get-observations",
    "href": "tutorial/01_Presence_Data.html#get-observations",
    "title": "Obtaining presence data for loggerhead turtles from OBIS",
    "section": "Get Observations",
    "text": "Get Observations\nWe will use the robis package to find observations of Loggerhead sea turtles (C. caretta) published in OBIS.\n\n#Search OBIS for loggerhead observations from 2000\ncaretta_obs &lt;- occurrence(\"Caretta caretta\", \n                          startdate = as.Date(\"2000-01-01\"),\n                          #Apply spatial constraint\n                          geometry = pol_geometry,\n                          #Include absence records if available\n                          absence = \"include\")\n\n\nRetrieved 5000 records of approximately 5269 (94%)\nRetrieved 5269 records of\napproximately 5269 (100%)\n\n#Check structure of results\nglimpse(caretta_obs)\n\nRows: 5,269\nColumns: 103\n$ associatedReferences          &lt;chr&gt; \"[{\\\"crossref\\\":{\\\"citeinfo\\\":{\\\"origin\\…\n$ basisOfRecord                 &lt;chr&gt; \"MachineObservation\", \"MachineObservatio…\n$ bibliographicCitation         &lt;chr&gt; \"[{\\\"crossref\\\":{\\\"citeinfo\\\":{\\\"origin\\…\n$ catalogNumber                 &lt;chr&gt; \"1014_8853\", \"1014_9766\", \"1014_8861\", \"…\n$ collectionCode                &lt;chr&gt; \"1014\", \"1014\", \"1014\", \"1014\", \"1014\", …\n$ coordinatePrecision           &lt;chr&gt; \"9.99999999999999955e-07\", \"9.9999999999…\n$ coordinateUncertaintyInMeters &lt;chr&gt; \"0.11\", \"0.11\", \"0.11\", \"0.11\", \"0.11\", …\n$ datasetID                     &lt;chr&gt; \"1014\", \"1014\", \"1014\", \"1014\", \"1014\", …\n$ datasetName                   &lt;chr&gt; \"IFREMER/Kélonia satellite tracked late …\n$ dateIdentified                &lt;chr&gt; \"2012-03-30T08:55:10\", \"2011-04-12T19:12…\n$ decimalLatitude               &lt;dbl&gt; 9.14804, 6.40193, 9.21307, 15.39172, 15.…\n$ decimalLongitude              &lt;dbl&gt; 50.69448, 59.87883, 50.82211, 55.71303, …\n$ eventDate                     &lt;chr&gt; \"2012-03-30T08:55:10\", \"2011-04-12T19:12…\n$ eventTime                     &lt;chr&gt; \"05:55:10Z\", \"15:12:41Z\", \"23:43:31Z\", \"…\n$ family                        &lt;chr&gt; \"Cheloniidae\", \"Cheloniidae\", \"Cheloniid…\n$ footprintWKT                  &lt;chr&gt; \"POINT(50.69448 9.14804)\", \"POINT(59.878…\n$ genus                         &lt;chr&gt; \"Caretta\", \"Caretta\", \"Caretta\", \"Carett…\n$ geodeticDatum                 &lt;chr&gt; \"EPSG:4326 WGS84\", \"EPSG:4326 WGS84\", \"E…\n$ georeferencedDate             &lt;chr&gt; \"2012-03-30T08:55:10\", \"2011-04-12T19:12…\n$ identificationRemarks         &lt;chr&gt; \"Identification Type:Telemetry\", \"Identi…\n$ individualCount               &lt;chr&gt; \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", …\n$ institutionCode               &lt;chr&gt; \"IFREMER and Kélonia\", \"IFREMER and Kélo…\n$ kingdom                       &lt;chr&gt; \"Animalia\", \"Animalia\", \"Animalia\", \"Ani…\n$ license                       &lt;chr&gt; \"http://creativecommons.org/licenses/by-…\n$ lifeStage                     &lt;chr&gt; \"Juvenile\", \"Juvenile\", \"Juvenile\", \"Juv…\n$ modified                      &lt;chr&gt; \"2013-10-25 13:35:20\", \"2013-10-25 13:35…\n$ nomenclaturalCode             &lt;chr&gt; \"WoRMS LSID\", \"WoRMS LSID\", \"WoRMS LSID\"…\n$ occurrenceID                  &lt;chr&gt; \"1014_8853\", \"1014_9766\", \"1014_8861\", \"…\n$ occurrenceRemarks             &lt;chr&gt; \"Telemetry\", \"Telemetry\", \"Telemetry\", \"…\n$ occurrenceStatus              &lt;chr&gt; \"present\", \"present\", \"present\", \"presen…\n$ order                         &lt;chr&gt; \"Testudines\", \"Testudines\", \"Testudines\"…\n$ organismID                    &lt;chr&gt; \"57684\", \"66818\", \"57684\", \"66839\", \"668…\n$ organismRemarks               &lt;chr&gt; \"Tagged animal. organismID may refer to …\n$ ownerInstitutionCode          &lt;chr&gt; \"IFREMER and Kélonia\", \"IFREMER and Kélo…\n$ phylum                        &lt;chr&gt; \"Chordata\", \"Chordata\", \"Chordata\", \"Cho…\n$ recordNumber                  &lt;chr&gt; \"1014_8853\", \"1014_9766\", \"1014_8861\", \"…\n$ scientificName                &lt;chr&gt; \"Caretta caretta\", \"Caretta caretta\", \"C…\n$ scientificNameAuthorship      &lt;chr&gt; \"(Linnaeus, 1758)\", \"(Linnaeus, 1758)\", …\n$ scientificNameID              &lt;chr&gt; \"urn:lsid:marinespecies.org:taxname:1372…\n$ specificEpithet               &lt;chr&gt; \"caretta\", \"caretta\", \"caretta\", \"carett…\n$ taxonRank                     &lt;chr&gt; \"Species\", \"Species\", \"Species\", \"Specie…\n$ taxonRemarks                  &lt;chr&gt; \"Taxon recorded as \\\"Caretta caretta\\\" b…\n$ taxonomicStatus               &lt;chr&gt; \"valid\", \"valid\", \"valid\", \"valid\", \"val…\n$ type                          &lt;chr&gt; \"Event\", \"Event\", \"Event\", \"Event\", \"Eve…\n$ verbatimEventDate             &lt;chr&gt; \"2012-03-30 08:55:10\", \"2011-04-12 19:12…\n$ vernacularName                &lt;chr&gt; \"Loggerhead Sea Turtle\", \"Loggerhead Sea…\n$ waterBody                     &lt;chr&gt; \"Reunion Island,Oman,South-Africa\", \"Reu…\n$ id                            &lt;chr&gt; \"000341f8-f206-4120-bc73-432a0c729d7a\", …\n$ dataset_id                    &lt;chr&gt; \"7687b242-05b7-48d7-a316-ba6dc34e72b5\", …\n$ node_id                       &lt;chr&gt; \"573654c1-4ce7-4ea2-b2f1-e4d42f8f9c31\", …\n$ date_start                    &lt;dbl&gt; 1.333066e+12, 1.302566e+12, 1.333152e+12…\n$ date_mid                      &lt;dbl&gt; 1.333066e+12, 1.302566e+12, 1.333152e+12…\n$ date_end                      &lt;dbl&gt; 1.333066e+12, 1.302566e+12, 1.333152e+12…\n$ date_year                     &lt;int&gt; 2012, 2011, 2012, 2011, 2011, 2011, 2011…\n$ dropped                       &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE…\n$ absence                       &lt;lgl&gt; FALSE, FALSE, FALSE, FALSE, FALSE, FALSE…\n$ marine                        &lt;lgl&gt; TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE…\n$ subphylum                     &lt;chr&gt; \"Vertebrata\", \"Vertebrata\", \"Vertebrata\"…\n$ infraphylum                   &lt;chr&gt; \"Gnathostomata\", \"Gnathostomata\", \"Gnath…\n$ megaclass                     &lt;chr&gt; \"Tetrapoda\", \"Tetrapoda\", \"Tetrapoda\", \"…\n$ superclass                    &lt;chr&gt; \"Reptilia\", \"Reptilia\", \"Reptilia\", \"Rep…\n$ suborder                      &lt;chr&gt; \"Cryptodira\", \"Cryptodira\", \"Cryptodira\"…\n$ superfamily                   &lt;chr&gt; \"Chelonioidea\", \"Chelonioidea\", \"Cheloni…\n$ species                       &lt;chr&gt; \"Caretta caretta\", \"Caretta caretta\", \"C…\n$ kingdomid                     &lt;int&gt; 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…\n$ phylumid                      &lt;int&gt; 1821, 1821, 1821, 1821, 1821, 1821, 1821…\n$ subphylumid                   &lt;int&gt; 146419, 146419, 146419, 146419, 146419, …\n$ infraphylumid                 &lt;int&gt; 1828, 1828, 1828, 1828, 1828, 1828, 1828…\n$ megaclassid                   &lt;int&gt; 1831, 1831, 1831, 1831, 1831, 1831, 1831…\n$ superclassid                  &lt;int&gt; 1838, 1838, 1838, 1838, 1838, 1838, 1838…\n$ orderid                       &lt;int&gt; 2689, 2689, 2689, 2689, 2689, 2689, 2689…\n$ suborderid                    &lt;int&gt; 148741, 148741, 148741, 148741, 148741, …\n$ superfamilyid                 &lt;int&gt; 987094, 987094, 987094, 987094, 987094, …\n$ familyid                      &lt;int&gt; 136999, 136999, 136999, 136999, 136999, …\n$ genusid                       &lt;int&gt; 137066, 137066, 137066, 137066, 137066, …\n$ speciesid                     &lt;int&gt; 137205, 137205, 137205, 137205, 137205, …\n$ aphiaID                       &lt;int&gt; 137205, 137205, 137205, 137205, 137205, …\n$ originalScientificName        &lt;chr&gt; \"Caretta caretta\", \"Caretta caretta\", \"C…\n$ category                      &lt;chr&gt; \"VU\", \"VU\", \"VU\", \"VU\", \"VU\", \"VU\", \"VU\"…\n$ flags                         &lt;chr&gt; \"NO_DEPTH\", \"NO_DEPTH\", \"NO_DEPTH\", \"NO_…\n$ bathymetry                    &lt;int&gt; 35, 3051, 136, 2784, 2453, 2736, 2880, 2…\n$ shoredistance                 &lt;int&gt; 4680, 899682, 12208, 193567, 143853, 100…\n$ sst                           &lt;dbl&gt; 26.21, 28.67, 26.21, 27.00, 26.92, 26.92…\n$ sss                           &lt;dbl&gt; 35.63, 35.74, 35.65, 36.09, 36.09, 36.10…\n$ dynamicProperties             &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ sex                           &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ continent                     &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ country                       &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ day                           &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ georeferenceRemarks           &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ locality                      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ maximumDepthInMeters          &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ maximumElevationInMeters      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ minimumDepthInMeters          &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ minimumElevationInMeters      &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ month                         &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ recordedBy                    &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ references                    &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ samplingProtocol              &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ year                          &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ depth                         &lt;dbl&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ superdomain                   &lt;chr&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ superdomainid                 &lt;int&gt; NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …",
    "crumbs": [
      "Background",
      "Presence data"
    ]
  },
  {
    "objectID": "tutorial/01_Presence_Data.html#explore-obis-results",
    "href": "tutorial/01_Presence_Data.html#explore-obis-results",
    "title": "Obtaining presence data for loggerhead turtles from OBIS",
    "section": "Explore OBIS results",
    "text": "Explore OBIS results\nOur search produced 5269 results for the area of our interest. However, before we continue to use this data as input for our species distribution models, we must clean it first to ensure we have a good quality dataset.\nIn this section, we will explore the results of our OBIS search so we can design a data cleaning workflow. We will check the content of some of the columns in our data frame.\nYou may want to refer to the OBIS manual and the OBIS webpage about Data Access.\n\n#Checking values in basis of record column\ncaretta_obs %&gt;% \n  distinct(basisOfRecord)\n\n# A tibble: 2 × 1\n  basisOfRecord     \n  &lt;chr&gt;             \n1 MachineObservation\n2 Occurrence        \n\n\nIn this context, MachineObservation refers to records obtained with satellite tags. While Occurrence refers to records obtained by human observers on the field. These two datasets cannot be treated in the same way as MachineObservation records are not independent as they record the movements of a single individual.\nWe can also check whether or not absence data is available for the loggerhead se a turtles in our area of interest.\n\ncaretta_obs %&gt;% \n  distinct(absence)\n\n# A tibble: 1 × 1\n  absence\n  &lt;lgl&gt;  \n1 FALSE  \n\n\nWe only have presence data available, which is an important factor to consider when designing our species distribution model workflow.\nWe can also check the coordinateUncertaintyInMeters, which gives us an indication of the error associated with a particular record. If we look at the names of the columns printed at the beginning of the script, you may notice that this column has been read as characters. We will change it to numbers before looking at the values in the column.\n\n#Changing column from characters to numeric\ncaretta_obs &lt;- caretta_obs %&gt;% \n  mutate(coordinateUncertaintyInMeters = as.numeric(coordinateUncertaintyInMeters))\n\n#Checking uncertainty values for coordinates\ncaretta_obs %&gt;% \n  distinct(coordinateUncertaintyInMeters)\n\n# A tibble: 3 × 1\n  coordinateUncertaintyInMeters\n                          &lt;dbl&gt;\n1                          0.11\n2                     111319.  \n3                         NA   \n\n\nIt is worth noting that not all providers share a measurement of uncertainty, but we can use this whenever is available to apply some sort of quality control to our data.\nHere, we see that some observations have uncertainty of centimeters (0.11 m), but there are other observations with uncertainty over 100 km. For this example, we will remove these observations with large uncertainties.",
    "crumbs": [
      "Background",
      "Presence data"
    ]
  },
  {
    "objectID": "tutorial/01_Presence_Data.html#quality-control-flags",
    "href": "tutorial/01_Presence_Data.html#quality-control-flags",
    "title": "Obtaining presence data for loggerhead turtles from OBIS",
    "section": "Quality control flags",
    "text": "Quality control flags\nOBIS provides some quality control (QC) flags for each record that may help us identify observations of lower quality. For an explanation of OBIS flags, check this repository.\nFirst, we will check the quality flags included in our results.\n\ncaretta_obs %&gt;% \n  distinct(flags)\n\n# A tibble: 4 × 1\n  flags             \n  &lt;chr&gt;             \n1 NO_DEPTH          \n2 NO_DEPTH,ON_LAND  \n3 DEPTH_EXCEEDS_BATH\n4 &lt;NA&gt;              \n\n\nWe will now plot our dataset on a map and use the information in the flags column to color code the observations. This can help us decide whether we should include or exclude them from further analyses.\nFirst we will load the region map that was saved in the Region page\n\nfil &lt;- here::here(\"data\", \"region\", \"region_map_label.rda\")\nload(fil)\n\n\nregion_map_label +\n  geom_point(data = caretta_obs, \n             #Using coordinates to plot and color based on value in flags column\n             aes(decimalLongitude, decimalLatitude, color = flags))\n\nScale on map varies by more than 10%, scale bar may be inaccurate\n\n\nWarning: Removed 231 rows containing missing values (`geom_text()`).\n\n\n\n\n\nFrom the plot above, we should consider removing at least some of the observations classified as NO_DEPTH,ON_LAND. This is because loggerhead sea turtles are not present inland. Instead, they are found in temperate and subtropical ocean waters and in sandy beaches.\nSome of these observations appear to be quite close to the shore, so they may have occurred in a sandy beach. We can check the proximity of the observation to the shore using the shoredistance column, which provides the distance to shore in meters.\n\ncaretta_obs %&gt;% \n  filter(flags == \"NO_DEPTH,ON_LAND\") %&gt;% \n  select(shoredistance) %&gt;% \n  arrange(desc(shoredistance))\n\n# A tibble: 25 × 1\n   shoredistance\n           &lt;int&gt;\n 1          -231\n 2          -394\n 3          -971\n 4         -1403\n 5         -3895\n 6         -5896\n 7         -8319\n 8         -8562\n 9        -17661\n10        -19763\n# ℹ 15 more rows\n\n\nThe inland observations are at least 231 meters away from the coast and up to 515 kilometers. For simplicity, we will remove all points flagged as NO_DEPTH,ON_LAND, but it is recommended that locations are looked more in depth and determine how likely it was that an individual was present at that location.\nWe can also check if any other observations have been reported in land. We will filter out the NO_DEPTH,ON_LAND flags and check for any negative values in the shoredistance column.\n\ncaretta_obs %&gt;% \n  filter(flags != \"NO_DEPTH,ON_LAND\" & shoredistance &lt; 0)\n\n# A tibble: 0 × 103\n# ℹ 103 variables: associatedReferences &lt;chr&gt;, basisOfRecord &lt;chr&gt;,\n#   bibliographicCitation &lt;chr&gt;, catalogNumber &lt;chr&gt;, collectionCode &lt;chr&gt;,\n#   coordinatePrecision &lt;chr&gt;, coordinateUncertaintyInMeters &lt;dbl&gt;,\n#   datasetID &lt;chr&gt;, datasetName &lt;chr&gt;, dateIdentified &lt;chr&gt;,\n#   decimalLatitude &lt;dbl&gt;, decimalLongitude &lt;dbl&gt;, eventDate &lt;chr&gt;,\n#   eventTime &lt;chr&gt;, family &lt;chr&gt;, footprintWKT &lt;chr&gt;, genus &lt;chr&gt;,\n#   geodeticDatum &lt;chr&gt;, georeferencedDate &lt;chr&gt;, …\n\n\nNo observations were returned, which is good news.\nAnother feature worth pointing out in our data is that some of the observations appear to be gridded as they are evenly spaced. This is confirmed by the occurrenceRemarks column, which states that some observations are: Telemetry locations aggregated per species per 1-degree cell. This is not ideal and you may need to consider if the inclusion of these data points are suitable for your project. In this example, we will remove them from our analysis.",
    "crumbs": [
      "Background",
      "Presence data"
    ]
  },
  {
    "objectID": "tutorial/01_Presence_Data.html#problematic-observations",
    "href": "tutorial/01_Presence_Data.html#problematic-observations",
    "title": "Obtaining presence data for loggerhead turtles from OBIS",
    "section": "Problematic observations",
    "text": "Problematic observations\nIn this step, we will remove observations with coordinate uncertainty over 100 km, any observations with the NO_DEPTH,ON_LAND flag, and any records that have been aggregated to a 1-degree cell.\n\ncaretta_obs &lt;- caretta_obs %&gt;%\n  #Removing on land observations\n  filter(flags != \"NO_DEPTH,ON_LAND\" | is.na(flags)) %&gt;%\n  #Removing observations with uncertainty over 100 km\n  filter(coordinateUncertaintyInMeters &lt;= 100000 | is.na(coordinateUncertaintyInMeters)) %&gt;%\n  #Removing records aggregated to 1 degree \n  filter(!str_detect(occurrenceRemarks, \"degree\"))",
    "crumbs": [
      "Background",
      "Presence data"
    ]
  },
  {
    "objectID": "tutorial/01_Presence_Data.html#saving-clean-data",
    "href": "tutorial/01_Presence_Data.html#saving-clean-data",
    "title": "Obtaining presence data for loggerhead turtles from OBIS",
    "section": "Saving clean data",
    "text": "Saving clean data\nNow that we have removed the problematic observations, we can save the new dataset into our local machine. We will save this under the data folder.\n\nfil &lt;- here::here(\"data\", \"raw-bio\", \"loggerhead-robis.csv\")\nwrite_csv(caretta_obs, fil)",
    "crumbs": [
      "Background",
      "Presence data"
    ]
  },
  {
    "objectID": "tutorial/03_sdmpredictors-variables.html",
    "href": "tutorial/03_sdmpredictors-variables.html",
    "title": "Marine SDM Variables",
    "section": "",
    "text": "Here we discuss an approach for finding a set of environmental variables to use for our sea turtle SDM. In this case, we are not sea turtle experts so we used AI to help us search for variables to include. The workflow has two steps. We are using the sdmpredictors R package to extract data layers for the marine environment.",
    "crumbs": [
      "Background",
      "Environmental data"
    ]
  },
  {
    "objectID": "tutorial/03_sdmpredictors-variables.html#querying-ai",
    "href": "tutorial/03_sdmpredictors-variables.html#querying-ai",
    "title": "Marine SDM Variables",
    "section": "Querying AI",
    "text": "Querying AI\nThe sdmpredictors package was created in 2022 and ChatGPT does not have data this recent so we used Google Bard to help us find marine environmental data variables for sea turtles.\nTo obtain the marine environmental data for our SDMs for predicting the occurrence of green sea turtle in the Arabian Sea, we used the sdmpredictors R package. There are over 100 environmental data layers that can be found in the sdmpredictors package. These data layers cover a wide range of environmental variables, including climate, land cover, marine, freshwater, and soil properties.\nIn order to define the best variables for using in our sea turtle prediction, we used the assistance of the artificial intelligence chatbot developed by Google - Google Bard. Google Bard has access to a vast amount of information on sea turtles and their habitat and so can understand complex relationships between environmental variables and sea turtle distribution.\nThe prompt used for achieving the best variables for green sea turtles was:\nWhat is the R package sdmpredictors?\nHow to use it to obtain environmental datasets from an especific region?\nWhich marine datasets available in sdmpreditors can be used for create a sdm to sea turtles? give me some examples\nList all the names of these layers\nWhich are all the variables I should use to create a sdm for sea turtles?\nGive me a table with all the information I need to create a sdm for green sea turtles\nCreate the most exaustive list possible\nThe generated table with all the relevant information:\n\n\n\n\n\n\n\n\nVariable\nDescription\nData source\n\n\n\n\nBathymetry\nThe depth of the ocean floor is important for green sea turtles because they need to be able to reach the seafloor to feed and nest.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nSea surface temperature\nGreen sea turtles prefer warmer waters, but they can also tolerate cooler temperatures.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nChlorophyll concentration\nGreen sea turtles eat algae, so chlorophyll concentration is a useful predictor of their food availability.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nSeagrass cover\nSeagrass is an important food source and nesting habitat for green sea turtles.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nSalinity\nGreen sea turtles are adapted to specific ranges of salinity.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nNitrate concentration\nNitrate is a nutrient that is essential for the growth of algae, which is a food source for green sea turtles.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nDistance to shore\nGreen sea turtles need to be able to reach the ocean floor to feed and nest.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nMean annual precipitation\nGreen sea turtles are adapted to a variety of precipitation regimes, but they avoid areas that are too dry or too wet.\nWorldClim\n\n\nMean annual temperature\nGreen sea turtles are adapted to a variety of temperature regimes, but they avoid areas that are too cold or too hot.\nWorldClim\n\n\nMean monthly temperature\nGreen sea turtles are adapted to a variety of temperature regimes, but they avoid areas that have extreme variations in monthly temperatures.\nWorldClim\n\n\nMean monthly precipitation\nGreen sea turtles are adapted to a variety of precipitation regimes, but they avoid areas that have extreme variations in monthly precipitation.\nWorldClim\n\n\nSolar radiation\nSolar radiation is a source of energy for algae and other organisms that green sea turtles eat.\nWorldClim\n\n\nWind speed\nWind can stir up sediment and make the water murky, which green sea turtles prefer to avoid.\nERA5\n\n\nWave height\nWave height can make it difficult for green sea turtles to feed and nest, so they avoid areas with high wave heights.\nERA5\n\n\nTurbidity\nTurbidity is the amount of suspended sediment in the water. Green sea turtles prefer clear water, so turbidity can be a useful predictor of their distribution.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nLight availability\nLight is essential for photosynthesis, which is the process that algae use to produce food. Green sea turtles eat algae, so light availability is an important factor in their distribution.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nOxygen concentration\nOxygen is essential for all life. Green sea turtles avoid areas with low oxygen concentrations.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nFood availability\nThe amount of food available to green sea turtles in an area is a major factor that influences their distribution. Green sea turtles eat a variety of organisms, including algae, seagrass, jellyfish, and fish.\nSurveys of sea turtle prey organisms\n\n\nPredation risk\nGreen sea turtles are preyed upon by a variety of animals, including sharks, crocodiles, and birds. The risk of predation can be a major factor that influences the distribution of green sea turtles.\nStudies of sea turtle predators\n\n\nHuman activity\nHuman activities, such as pollution, habitat destruction, and overfishing, can have a negative impact on the distribution of green sea turtles.\nGovernment reports and scientific studies\n\n\n\nWith this information in hands, we are now able to find these variables in the sdmpredictors.",
    "crumbs": [
      "Background",
      "Environmental data"
    ]
  },
  {
    "objectID": "tutorial/03_sdmpredictors-variables.html#view-the-sdmpredictors-variables",
    "href": "tutorial/03_sdmpredictors-variables.html#view-the-sdmpredictors-variables",
    "title": "Marine SDM Variables",
    "section": "View the sdmpredictors variables",
    "text": "View the sdmpredictors variables\nsdmpredictors has many variables.\n\nlibrary(tidyverse)\nlibrary(DT)\nlibrary(sdmpredictors)\nlibrary(sf)\n\nThere are two marine data sources.\n\nenv_datasets &lt;- list_datasets(terrestrial = FALSE, marine = TRUE)\nenv_datasets %&gt;% \n  select(dataset_code, description, citation) %&gt;% \n  DT::datatable()\n\n\n\n\n\n\nenv_datasets_vec &lt;- c(\"Bio-ORACLE\", \"MARSPEC\")\nenv_layers &lt;- sdmpredictors::list_layers(env_datasets_vec)\nDT::datatable(env_layers)\n\n\n\n\n\nFor this tutorial, we chose the “mean” variable from the sdmpredictors package for each marine environmental parameter recommended by Bard.\n\n\n\nVariable\nData source\n\n\n\n\nBathymetry\nBO_bathymean\n\n\nSea surface temperature\nBO2_tempmean_ss\n\n\nChlorophyll concentration\nBO2_chlomean_ss\n\n\nSalinity\nBO2_salinitymean_ss\n\n\nNitrate concentration\nBO21_nitratemean_ss\n\n\nDistance to shore\nMS_biogeo05_dist_shore_5m\n\n\nMean annual temperature\nMS_biogeo13_sst_mean_5m\n\n\nSolar radiation\nBO22_parmean\n\n\nTurbidity\nBO22_damean\n\n\nOxygen concentration\nBO2_dissoxmean_bdmean",
    "crumbs": [
      "Background",
      "Environmental data"
    ]
  },
  {
    "objectID": "tutorial/03_sdmpredictors-variables.html#extract-these-variables",
    "href": "tutorial/03_sdmpredictors-variables.html#extract-these-variables",
    "title": "Marine SDM Variables",
    "section": "Extract these variables",
    "text": "Extract these variables\nFirst we will load a bounding box for our area of interest. This was saved in []\n\n#Loading bounding box for the area of interest\nfil &lt;- here::here(\"data\", \"region\", \"BoundingBox.shp\")\nextent_polygon &lt;- read_sf(fil)\n\n#Extract polygon geometry \npol_geometry &lt;- st_as_text(extent_polygon$geometry)\n\nThe objective is to extract all these variables for our presence and absence locations.\nWe will show this in the SDM examples. This is where the team ran into a numbers of hiccups.",
    "crumbs": [
      "Background",
      "Environmental data"
    ]
  },
  {
    "objectID": "tutorial/05_fitting.html",
    "href": "tutorial/05_fitting.html",
    "title": "Fitting models",
    "section": "",
    "text": "In general, when fitting any SDM in R, one uses a data frame where each row is an observation or absence. The first column is typically a presence/absence column (0/1). This is followed by columns of the environmental variables for each presence/absence. For debugging, it is probably wise to keep the lat/lon columns and date values associated with the points and perhaps a id column. In the turtorial, we did not do that.",
    "crumbs": [
      "Background",
      "Fitting models"
    ]
  },
  {
    "objectID": "tutorial/05_fitting.html#data-frame",
    "href": "tutorial/05_fitting.html#data-frame",
    "title": "Fitting models",
    "section": "",
    "text": "In general, when fitting any SDM in R, one uses a data frame where each row is an observation or absence. The first column is typically a presence/absence column (0/1). This is followed by columns of the environmental variables for each presence/absence. For debugging, it is probably wise to keep the lat/lon columns and date values associated with the points and perhaps a id column. In the turtorial, we did not do that.",
    "crumbs": [
      "Background",
      "Fitting models"
    ]
  },
  {
    "objectID": "tutorial/05_fitting.html#fitting",
    "href": "tutorial/05_fitting.html#fitting",
    "title": "Fitting models",
    "section": "Fitting",
    "text": "Fitting\nOnce one has the data frame, fitting will generally look like\nfun(pres ~ ., data = df)\nFor example,\nmod &lt;- gam(pres ~ ., data = df)\nTo fit a generalized additive model.\nThus presence is defined as a function of all the variables in the data frame and fun() specifies the model.\nFor maxnet, format is slightly different:\nmod &lt;- maxnet(pres, df %&gt;% select(-pres))\nThus the 0/1 for each row is the first argument and the second argument is the environmental variables only.",
    "crumbs": [
      "Background",
      "Fitting models"
    ]
  },
  {
    "objectID": "tutorial/Steps_Region.html",
    "href": "tutorial/Steps_Region.html",
    "title": "Saving region files",
    "section": "",
    "text": "As a preliminary, we will define some shape files and plots of our region that we will use in later steps.",
    "crumbs": [
      "SDM Steps",
      "Save region objects"
    ]
  },
  {
    "objectID": "tutorial/Steps_Region.html#load-libraries",
    "href": "tutorial/Steps_Region.html#load-libraries",
    "title": "Saving region files",
    "section": "Load libraries",
    "text": "Load libraries\n\nlibrary(sf)\nlibrary(rnaturalearth)\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(ggspatial)",
    "crumbs": [
      "SDM Steps",
      "Save region objects"
    ]
  },
  {
    "objectID": "tutorial/Steps_Region.html#create-a-bounding-box",
    "href": "tutorial/Steps_Region.html#create-a-bounding-box",
    "title": "Saving region files",
    "section": "Create a bounding box",
    "text": "Create a bounding box\nOur interest is the Persian Gulf and northern Arabian Sea.\nWe create a bounding box using minimum and maximum coordinate pairs and assign a standared WGS 84 coordinate reference system. We will turn this into a polygon and then an sf object.\n\nbbox &lt;- sf::st_bbox(c(xmin = 41.875, xmax = 65.125, ymax = -0.125, ymin = 32.125), \n                          crs = sf::st_crs(4326))\n# this creates a sf object with a sfs_POLYGON from which we can get a polygon string\nextent_polygon &lt;-  bbox %&gt;% sf::st_as_sfc() %&gt;% st_sf()\n\n\nSave\nSaving the bounding box for future use.\n\nfil &lt;- here::here(\"data\", \"region\", \"BoundingBox.shp\")\nwrite_sf(extent_polygon, fil)\n\nWe will also save the polygon in string format. The polygon text is the first element in the object.\n\npol_geometry &lt;-  extent_polygon$geometry %&gt;% sf::st_as_text()\nfil &lt;- here::here(\"data\", \"region\", \"pol_geometry.txt\")\nwriteLines(pol_geometry, fil)",
    "crumbs": [
      "SDM Steps",
      "Save region objects"
    ]
  },
  {
    "objectID": "tutorial/Steps_Region.html#create-a-world-map",
    "href": "tutorial/Steps_Region.html#create-a-world-map",
    "title": "Saving region files",
    "section": "Create a world map",
    "text": "Create a world map\nWe can create a world map to show where our study region is and save these for later use.\n\nPlotting region of interest\nThis allows us to check our polygon of interest is located in the correct region.\n\n#Getting base map\nworld &lt;- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\n#Plotting map\nworld_box &lt;- ggplot() + \n  #Adding base map\n  geom_sf(data = world) +\n  #Adding bounding box\n  geom_sf(data = extent_polygon, color = \"red\", fill = NA)+\n  #Setting theme of plots to not include a grey background\n  theme_bw()\n\nworld_box\n\n\n\n\nSave the plot.\n\nfil &lt;- here::here(\"data\", \"region\", \"world_box.rda\")\nsave(world_box, file=fil)",
    "crumbs": [
      "SDM Steps",
      "Save region objects"
    ]
  },
  {
    "objectID": "tutorial/Steps_Region.html#create-a-region-map",
    "href": "tutorial/Steps_Region.html#create-a-region-map",
    "title": "Saving region files",
    "section": "Create a region map",
    "text": "Create a region map\nWe can create a base map of our region and save it.\n\nbase_region_map &lt;- ggplot()+\n  #Adding base layer (world map)\n  geom_sf(data = world, fill = \"antiquewhite\")+\n  #Constraining map to original bounding box\n  lims(x = c(st_bbox(extent_polygon)$xmin, st_bbox(extent_polygon)$xmax),\n       y = c(st_bbox(extent_polygon)$ymin, st_bbox(extent_polygon)$ymax))\nbase_region_map\n\n\n\n\nSave it\n\nfil &lt;- here::here(\"data\", \"region\", \"base_region_map.rda\")\nsave(base_region_map, file=fil)\n\nWe will add some more features to our map: colors, scale and compass.\n\nregion_map &lt;- base_region_map +\n  #Add scale bar on the top right of the plot\n  annotation_scale(location = \"tr\", width_hint = 0.5)+\n  #Add north arrow on the top left of plot\n  annotation_north_arrow(location = \"tl\", which_north = \"true\",\n                         #Include small buffer from plot edge\n                         pad_x = unit(0.01, \"in\"), pad_y = unit(0.05, \"in\"),\n                         #Set style of north arrow\n                         style = north_arrow_fancy_orienteering) +\n  #Changing color, type and size of grid lines\n  theme(panel.grid.major = element_line(color = gray(.5), linetype = \"dashed\", size = 0.5), \n  #Change background of map\n  panel.background = element_rect(fill = \"aliceblue\")) +\n  labs(x = \"longitude\", y = \"latitude\")\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\nregion_map\n\nScale on map varies by more than 10%, scale bar may be inaccurate\n\n\n\n\n\nSave.\n\nfil &lt;- here::here(\"data\", \"region\", \"region_map.rda\")\nsave(region_map, file=fil)\n\nWe add some labels for the countries.\n\n#Extracting labels for countries in base map\nworld_points &lt;- world %&gt;% \n  st_make_valid(world) %&gt;%\n  #Getting centroids for all polygons in the world base map\n  st_centroid(geometry) %&gt;% \n  #Getting coordinates for each centroid\n  st_coordinates() %&gt;% \n  #Adding centroids to original base map\n  bind_cols(world)\n\n#Do not use spherical geometry\nsf_use_s2(FALSE)\n\n#Adding labels to map\nregion_map_label &lt;- region_map +\n  geom_text(data = world_points, \n            #Point to coordinates and column with country names\n            aes(x = X, y = Y, label = name),\n            #Changing color and size of labels\n            color = \"darkblue\", size = 3, \n            #Avoid label overlap\n            check_overlap = TRUE)\n# Save\nfil &lt;- here::here(\"data\", \"region\", \"region_map_label.rda\")\nsave(region_map_label, file=fil)\n\n#Checking final map\nregion_map_label",
    "crumbs": [
      "SDM Steps",
      "Save region objects"
    ]
  },
  {
    "objectID": "tutorial/Steps_Region.html#loading-in-the-save-files",
    "href": "tutorial/Steps_Region.html#loading-in-the-save-files",
    "title": "Saving region files",
    "section": "Loading in the save files",
    "text": "Loading in the save files\nLater when we need the extent polygon, we use\n\n#Loading bounding box for the area of interest\nfil &lt;- here::here(\"data\", \"region\", \"BoundingBox.shp\")\nextent_polygon &lt;- read_sf(fil)\n\nWe often will need a sf bbox (bounding box object). To create that from the sf polygon object use\n\nbbox &lt;- sf::st_bbox(extent_polygon)\n\nWe load the maps as\n\nfil &lt;- here::here(\"data\", \"region\", \"region_map_label.rda\")\nload(fil)",
    "crumbs": [
      "SDM Steps",
      "Save region objects"
    ]
  },
  {
    "objectID": "tutorial/Steps_occ_env.html",
    "href": "tutorial/Steps_occ_env.html",
    "title": "Get environmental data for the occurrence locations",
    "section": "",
    "text": "We are going to download environment data layers using sdmpredictors R package. We need to specify the directory where we will do this. We created the env directory in the data directory for this purpose.\nUltimately we need to get a data frame with the environmental data for the occurrence and absence lat/lon locations.",
    "crumbs": [
      "SDM Steps",
      "Environmental Data"
    ]
  },
  {
    "objectID": "tutorial/Steps_occ_env.html#set-up",
    "href": "tutorial/Steps_occ_env.html#set-up",
    "title": "Get environmental data for the occurrence locations",
    "section": "Set up",
    "text": "Set up\n\nlibrary(ggplot2)\nlibrary(sdmpredictors)\nlibrary(DT)\nlibrary(sf)\n\nLinking to GEOS 3.11.0, GDAL 3.5.3, PROJ 9.1.0; sf_use_s2() is TRUE\n\nlibrary(raster)\n\nLoading required package: sp\n\n\nSet the directory where we will save environmental data layers.\n\ndir_env &lt;- here::here(\"data\", \"env\")\noptions(sdmpredictors_datadir = dir_env)",
    "crumbs": [
      "SDM Steps",
      "Environmental Data"
    ]
  },
  {
    "objectID": "tutorial/Steps_occ_env.html#add-datasets",
    "href": "tutorial/Steps_occ_env.html#add-datasets",
    "title": "Get environmental data for the occurrence locations",
    "section": "Add datasets",
    "text": "Add datasets\nWe will use the sdmpredictors R package which has marine data layers.\n\n# choose marine\nenv_datasets &lt;- sdmpredictors::list_datasets(terrestrial = FALSE, marine = TRUE)",
    "crumbs": [
      "SDM Steps",
      "Environmental Data"
    ]
  },
  {
    "objectID": "tutorial/Steps_occ_env.html#show-the-available-variables",
    "href": "tutorial/Steps_occ_env.html#show-the-available-variables",
    "title": "Get environmental data for the occurrence locations",
    "section": "Show the available variables",
    "text": "Show the available variables\nThe dataframe is large. We will use the DT package to make the table pretty in html.\n\nenv_layers &lt;- sdmpredictors::list_layers(env_datasets$dataset_code)\nDT::datatable(env_layers)",
    "crumbs": [
      "SDM Steps",
      "Environmental Data"
    ]
  },
  {
    "objectID": "tutorial/Steps_occ_env.html#variables",
    "href": "tutorial/Steps_occ_env.html#variables",
    "title": "Get environmental data for the occurrence locations",
    "section": "Variables",
    "text": "Variables\nSee the Background discussion on how we decided on the environmental variables that we would use from the sdmpredictors R package.\n\nlayercodes &lt;- c(\"BO_sstmean\", \"BO_bathymean\", \"BO22_ph\", \"BO2_dissoxmean_bdmean\", \"BO2_salinitymean_ss\", \"BO2_chlomean_ss\", \"BO21_nitratemean_ss\")\n\n\nLoad layers\nWe want to set rasterstack equal true to get one file for our variables. This will save the files to data/env and we can load the files in later steps.\n\nenv &lt;- sdmpredictors::load_layers(layercodes, rasterstack = TRUE)",
    "crumbs": [
      "SDM Steps",
      "Environmental Data"
    ]
  },
  {
    "objectID": "tutorial/Steps_occ_env.html#visualize-the-environment-data",
    "href": "tutorial/Steps_occ_env.html#visualize-the-environment-data",
    "title": "Get environmental data for the occurrence locations",
    "section": "Visualize the environment data",
    "text": "Visualize the environment data\nLoad the bounding box.\n\n#Loading bounding box for the area of interest\nfil &lt;- here::here(\"data\", \"region\", \"BoundingBox.shp\")\nextent_polygon &lt;- read_sf(fil)\n\nMake a plot of all the layers cropped to our bounding box.\n\nio.rast &lt;- raster::crop(env, raster::extent(extent_polygon))\nplot(io.rast)",
    "crumbs": [
      "SDM Steps",
      "Environmental Data"
    ]
  },
  {
    "objectID": "tutorial/Steps_occ_env.html#environmental-predictors-for-points",
    "href": "tutorial/Steps_occ_env.html#environmental-predictors-for-points",
    "title": "Get environmental data for the occurrence locations",
    "section": "Environmental predictors for points",
    "text": "Environmental predictors for points\nWe will use the stars package to sample from our raster layers.\nLoad in our point data as data frames.\n\n# presence data\nfil &lt;- here::here(\"data\", \"raw-bio\", \"io-sea-turtles-clean.csv\")\ndf.occ &lt;- read.csv(fil) \n\n# absence data\nfil &lt;- here::here(\"data\", \"raw-bio\", \"pts_absence.csv\")\ndf.abs &lt;- read.csv(fil)\ncolnames(df.abs) &lt;- c(\"lon\", \"lat\")\n\nConvert data frames to sf points objects. This is what stars needs.\n\ndf.abs &lt;- na.omit(df.abs) # just in case\nsf.abs &lt;- sf::st_as_sf(df.abs, coords = c(\"lon\", \"lat\"), crs = 4326)\nsf.occ &lt;- sf::st_as_sf(df.occ, coords = c(\"lon\", \"lat\"), crs = 4326)\n\nConvert the raster stack to a stars object.\n\nenv.stars &lt;- stars::st_as_stars(env) # convert to stars object\nenv.stars &lt;- terra::split(env.stars)\n\nGet environment values for the absence points. Each row in sf.abs is a row in env.abs.\n\nenv.abs &lt;- stars::st_extract(env.stars, sf::st_coordinates(sf.abs)) %&gt;% \n  dplyr::as_tibble() %&gt;% \n  na.omit()\n\nhead(env.abs)\n\n# A tibble: 6 × 7\n  BO_sstmean BO_bathymean BO22_ph BO2_dissoxmean_bdmean BO2_salinitymean_ss\n       &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;                 &lt;dbl&gt;               &lt;dbl&gt;\n1       28.4        -2445    8.16                  111.                36.2\n2       26.9        -3142    8.12                  119.                36.5\n3       28.3        -4549    8.19                  159.                36.0\n4       27.1        -4970    8.17                  180.                35.5\n5       26.8        -3869    8.16                  156.                36.0\n6       28.0        -5095    8.17                  183.                35.4\n# ℹ 2 more variables: BO2_chlomean_ss &lt;dbl&gt;, BO21_nitratemean_ss &lt;dbl&gt;\n\n\nGet environment values for the occurence points. Each row in sf.occ is a row in env.occ.\n\nenv.occ &lt;- stars::st_extract(env.stars, sf::st_coordinates(sf.occ)) %&gt;% \n  dplyr::as_tibble() %&gt;% \n  na.omit()\n\nhead(env.occ)\n\n# A tibble: 6 × 7\n  BO_sstmean BO_bathymean BO22_ph BO2_dissoxmean_bdmean BO2_salinitymean_ss\n       &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;                 &lt;dbl&gt;               &lt;dbl&gt;\n1       28.6        -3158    8.18                 154.                 35.7\n2       27.6           -8    8.13                 198.                 38.7\n3       27.6           -4    8.13                 198.                 38.7\n4       26.9        -2759    8.14                 127.                 36.1\n5       26.9        -2067    8.14                  98.6                36.0\n6       27.6           -6    8.13                 198.                 38.7\n# ℹ 2 more variables: BO2_chlomean_ss &lt;dbl&gt;, BO21_nitratemean_ss &lt;dbl&gt;\n\n\nNow make this into one data frame with a pa column for 1 is a occurrence row and 0 if an absence row.\n\npres &lt;- c(rep(1, nrow(env.occ)), rep(0, nrow(env.abs)))\nsdm_data &lt;- data.frame(pa = pres, rbind(env.occ, env.abs))\nhead(sdm_data)\n\n  pa BO_sstmean BO_bathymean BO22_ph BO2_dissoxmean_bdmean BO2_salinitymean_ss\n1  1     28.648        -3158   8.181             154.32448            35.73521\n2  1     27.585           -8   8.133             197.65898            38.71139\n3  1     27.553           -4   8.133             197.66029            38.65246\n4  1     26.883        -2759   8.142             127.38091            36.10051\n5  1     26.942        -2067   8.139              98.57215            36.04962\n6  1     27.606           -6   8.133             197.74764            38.67334\n  BO2_chlomean_ss BO21_nitratemean_ss\n1        0.107879            0.132562\n2        0.141303            0.000003\n3        0.141299            0.000002\n4        0.293972            0.691326\n5        0.517558            1.127677\n6        0.141344            0.000002\n\n\nSave to a file. We will use for other models.\n\nfil &lt;- here::here(\"data\", \"raw-bio\", \"sdm_data.csv\")\nwrite.csv(sdm_data, row.names = FALSE, file=fil)",
    "crumbs": [
      "SDM Steps",
      "Environmental Data"
    ]
  },
  {
    "objectID": "tutorial/Steps_sdm_maxnet.html",
    "href": "tutorial/Steps_sdm_maxnet.html",
    "title": "Fit SDM",
    "section": "",
    "text": "We will use the presence and absence data and the environmental layers that we created in the previous steps to assemble the data frames needed to fit our SDM model.",
    "crumbs": [
      "SDM Steps",
      "Fit with Maxnet"
    ]
  },
  {
    "objectID": "tutorial/Steps_sdm_maxnet.html#pre-sdm-set-up",
    "href": "tutorial/Steps_sdm_maxnet.html#pre-sdm-set-up",
    "title": "Fit SDM",
    "section": "Pre-SDM Set-up",
    "text": "Pre-SDM Set-up\nYou will need to install a new version of maxnet for this tutorial. No need to do this on the JupyterHub. It is already installed.\n\ndevtools::install_github(\"BigelowLab/maxnet\")\ninstall.packages(c(\"dplyr\", \"sf\", \"stars\", \"geodata\",\n                   \"dismo\", \"lubridate\", \"sdmpredictors\", \n                   \"ggplot2\", \"cmocean\", \"janitor\", \"DT\",\n                   \"here\"))\n\nLoad the needed packages.\n\nsuppressPackageStartupMessages({\nlibrary(maxnet)\nlibrary(dplyr)\nlibrary(sf)\nlibrary(stars)\nlibrary(geodata)\nlibrary(dismo)\nlibrary(lubridate)\nlibrary(sdmpredictors)\n#library(zoon)\nlibrary(ggplot2)\nlibrary(cmocean)\nlibrary(janitor)\nlibrary(DT)\n})\n\nSet the file location.\n\nhere::i_am(\"tutorial/Steps_sdm_maxnet.Rmd\")\n\nhere() starts at /Users/eli.holmes/Documents/GitHub/ohw23_proj_marinesdms\n\n\nLoad region files. We created our region objects in a separate file Region data and saved these in data/region. We will load these now.\nLoad the bounding box polygon and create a bounding box.\n\n#Loading bounding box for the area of interest\nfil &lt;- here::here(\"data\", \"region\", \"BoundingBox.shp\")\nextent_polygon &lt;- sf::read_sf(fil)\nbbox &lt;- sf::st_bbox(extent_polygon)",
    "crumbs": [
      "SDM Steps",
      "Fit with Maxnet"
    ]
  },
  {
    "objectID": "tutorial/Steps_sdm_maxnet.html#load-occurence-data",
    "href": "tutorial/Steps_sdm_maxnet.html#load-occurence-data",
    "title": "Fit SDM",
    "section": "Load occurence data",
    "text": "Load occurence data\nHere we load the data prepared in the previous step.\n\n# presence data\nfil &lt;- here::here(\"data\", \"raw-bio\", \"io-sea-turtles-clean.csv\")\nocc.sub &lt;- read.csv(fil)\n\nCreate sf_points data frame.\n\nocc.points &lt;- sf::st_as_sf(occ.sub, coords = c(\"lon\", \"lat\"), crs = 4326)\nhead(occ.points)\n\nSimple feature collection with 6 features and 7 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 53.083 ymin: 6.40193 xmax: 59.87883 ymax: 24.577\nGeodetic CRS:  WGS 84\n         sci.name        obsv.datetime life.stage bathy   SST   SSS common.name\n1 Caretta caretta 2011-04-12T19:12:41Z   Juvenile  3051 28.67 35.74  Loggerhead\n2  Chelonia mydas 2018-03-31T06:44:00Z       &lt;NA&gt;    14 27.96 38.71       Green\n3  Chelonia mydas 2019-05-28T12:15:00Z       &lt;NA&gt;     2 27.93 38.65       Green\n4 Caretta caretta 2011-04-11T04:03:19Z   Juvenile  2736 26.92 36.10  Loggerhead\n5 Caretta caretta 2011-03-24T14:33:23Z   Juvenile  2030 26.68 36.05  Loggerhead\n6  Chelonia mydas 2018-04-05T23:33:00Z       &lt;NA&gt;     2 27.94 38.67       Green\n                   geometry\n1  POINT (59.87883 6.40193)\n2     POINT (53.201 24.508)\n3     POINT (53.083 24.577)\n4 POINT (54.28696 16.05778)\n5 POINT (53.83602 16.52469)\n6     POINT (53.092 24.549)",
    "crumbs": [
      "SDM Steps",
      "Fit with Maxnet"
    ]
  },
  {
    "objectID": "tutorial/Steps_sdm_maxnet.html#load-background-data",
    "href": "tutorial/Steps_sdm_maxnet.html#load-background-data",
    "title": "Fit SDM",
    "section": "Load background data",
    "text": "Load background data\n\n# absence data\nfil &lt;- here::here(\"data\", \"raw-bio\", \"pts_absence.csv\")\npts.abs &lt;- read.csv(fil) # X is lon and Y is lat\n\nCheck column names.\n\ncolnames(pts.abs)\n\n[1] \"X\" \"Y\"\n\n\nChange columns names to lon and lat and remove any NAs in the data.\n\ncolnames(pts.abs) &lt;- c(\"lon\",\"lat\")\npts.abs &lt;- na.omit(pts.abs)\n\nConvert to sf_points object. Set the crs to 4326.\n\nabs.points &lt;- sf::st_as_sf(pts.abs, coords = c(\"lon\", \"lat\"), crs = 4326)",
    "crumbs": [
      "SDM Steps",
      "Fit with Maxnet"
    ]
  },
  {
    "objectID": "tutorial/Steps_sdm_maxnet.html#get-the-environment-for-the-latlon-locations",
    "href": "tutorial/Steps_sdm_maxnet.html#get-the-environment-for-the-latlon-locations",
    "title": "Fit SDM",
    "section": "Get the environment for the lat/lon locations",
    "text": "Get the environment for the lat/lon locations\nHere we create the data frame with the environmental variables for our presence and absence locations.\n\nLoad environmental layers\nSet the location of the data directory.\n\ndir_env &lt;- here::here(\"data\", \"env\")\noptions(sdmpredictors_datadir = dir_env)\n\nSpecify the layers that we want. The layers were saved to the data/env directory.\n\nlayercodes &lt;- c(\"BO_sstmean\", \"BO_bathymean\", \"BO22_ph\", \"BO2_dissoxmean_bdmean\", \"BO2_salinitymean_ss\", \"BO2_chlomean_ss\", \"BO21_nitratemean_ss\")\n\nLoad the layers into the env object. We want to set rasterstack equal true to get one file for our variables.\n\nenv &lt;- sdmpredictors::load_layers(layercodes, rasterstack = TRUE)\n\n\n\nCreate a stars object\nThere are a few ways that we can get the values of the environmental variables in our raster stack for the lat/lon locations. We will use the stars and terra functions as these are the new (2023) packages in R for this purpose. You will find older approaches if you search and possibly AI will suggest older approaches.\nStep one is to convert our raster stack to a stars object and split the stars object into layers.\n\nenv.stars &lt;- stars::st_as_stars(env) # convert to stars object\nenv.stars &lt;- terra::split(env.stars)\n\n\n\nExtract the variables for our points\nNow we can extract the variables for our presence and absence points.\n\nocc.env &lt;- stars::st_extract(env.stars, sf::st_coordinates(occ.points)) %&gt;%\n  dplyr::as_tibble()\n\nabs.env &lt;- stars::st_extract(env.stars, sf::st_coordinates(abs.points)) %&gt;% \n  dplyr::as_tibble()\n\nNow we have a data frame with the variables for presence and absence.\n\nhead(abs.env)\n\n# A tibble: 6 × 7\n  BO_sstmean BO_bathymean BO22_ph BO2_dissoxmean_bdmean BO2_salinitymean_ss\n       &lt;dbl&gt;        &lt;dbl&gt;   &lt;dbl&gt;                 &lt;dbl&gt;               &lt;dbl&gt;\n1       28.4        -2445    8.16                  111.                36.2\n2       26.9        -3142    8.12                  119.                36.5\n3       28.3        -4549    8.19                  159.                36.0\n4       27.1        -4970    8.17                  180.                35.5\n5       26.8        -3869    8.16                  156.                36.0\n6       28.0        -5095    8.17                  183.                35.4\n# ℹ 2 more variables: BO2_chlomean_ss &lt;dbl&gt;, BO21_nitratemean_ss &lt;dbl&gt;\n\n\nLet’s check the sizes. They should have the same number of rows.\n\ndim(occ.points)\n\n[1] 2064    8\n\ndim(occ.env)\n\n[1] 2064    7\n\n\nLet’s check the sizes. They should have the same number of rows.\n\ndim(abs.points)\n\n[1] 1000    1\n\ndim(abs.env)\n\n[1] 1000    7\n\n\nOur environmental data have some NAs. We need to remove these.\n\nany(is.na(occ.env))\n\n[1] TRUE\n\nany(is.na(abs.env))\n\n[1] TRUE\n\n\nRemove the NAs.\n\nocc.env &lt;- na.omit(occ.env)\nabs.env &lt;- na.omit(abs.env)",
    "crumbs": [
      "SDM Steps",
      "Fit with Maxnet"
    ]
  },
  {
    "objectID": "tutorial/Steps_sdm_maxnet.html#sdm-model",
    "href": "tutorial/Steps_sdm_maxnet.html#sdm-model",
    "title": "Fit SDM",
    "section": "SDM Model",
    "text": "SDM Model\nWe will fit with MaxEnt using the maxnet package. The function is\nmod &lt;- maxnet::maxnet(pres, env_df)\nenv_df is a data frame of environmental data (in columns) for each location (in rows) of the presences and absences. presis a string of 0s and 1s specifying if the row inenviron` is a presence (1) or absence (0).\n\nSet up the env_df\nWe combining the two data frames with rbind().\n\nenv_df &lt;- rbind(occ.env, abs.env)\n\n\n\nSet up the pres string\nThe rows of occ.env are all 1 (presence) and the rows of abs.env are all 0 (absent).\n\npres &lt;- c(rep(1, nrow(occ.env)), rep(0, nrow(abs.env)))",
    "crumbs": [
      "SDM Steps",
      "Fit with Maxnet"
    ]
  },
  {
    "objectID": "tutorial/Steps_sdm_maxnet.html#run-the-model",
    "href": "tutorial/Steps_sdm_maxnet.html#run-the-model",
    "title": "Fit SDM",
    "section": "Run the model",
    "text": "Run the model\n\nsdm.model &lt;- maxnet::maxnet(pres, env_df)\n\n\nModel metrics\n\nresponses &lt;- plot(sdm.model, type = \"cloglog\")",
    "crumbs": [
      "SDM Steps",
      "Fit with Maxnet"
    ]
  },
  {
    "objectID": "tutorial/Steps_sdm_maxnet.html#save-model",
    "href": "tutorial/Steps_sdm_maxnet.html#save-model",
    "title": "Fit SDM",
    "section": "Save model",
    "text": "Save model\n\nenv.stars.crop &lt;- env.stars %&gt;% sf::st_crop(bbox)\nfil &lt;- here::here(\"data\", \"models\", \"io-turtle.RData\")\nsave(sdm.model, env.stars.crop, occ.points, abs.points, file=fil)",
    "crumbs": [
      "SDM Steps",
      "Fit with Maxnet"
    ]
  }
]