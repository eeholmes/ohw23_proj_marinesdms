[
  {
    "objectID": "index.html",
    "href": "index.html",
    "title": "2023 Ocean Hackweek",
    "section": "",
    "text": "Click to hear our song! Inspired by Myranda and AI!\n\n\n\n(Chorus) Under the sea, where turtles roam so free, Using models to unlock their mystery, Species distribution, a vital contribution, In the Arabian Sea, our quest for clarity!"
  },
  {
    "objectID": "index.html#overview",
    "href": "index.html#overview",
    "title": "2023 Ocean Hackweek",
    "section": "Overview",
    "text": "Overview\nThis tutorial was developed during OceanHackWeek2023 to provide a simple workflow to developing a marine Species Distribution Model (SDM) using R programming."
  },
  {
    "objectID": "index.html#background",
    "href": "index.html#background",
    "title": "2023 Ocean Hackweek",
    "section": "Background",
    "text": "Background\nSpecies Distribution Modelling (SDM) also known as niche/environmental/ecological modelling uses an algorithm to predict the distribution of a species across space and time using environmental data. An understanding of the relationship between the species of interest and the physical environment they occupy will inform the selection of relevant environmental factors that will be included in the model.\nBiotic information is also needed by SDMs and at the very least locations of individuals are needed. Abundance or densities can also be used as inputs, but are not compulsory. It is worth noting that absences, that is, the locations where individuals of a species are NOT present is just as important because it provides information about the environmental conditions where individuals are not usually sighted. Often absences are not recorded in biological data, but we can use background points (also known as pseudo-absences), which provide information about the full range of environmental conditions available for the species interest in our study area.\nFor a review of the performance of different SDM algorithms, see the following publications:\n- Valavi, Guillera-Arroita, Lahoz-Monfort, Elith (2021). Predictive performance of presence-only species distribution models: a benchmark study with reproducible code. DOI: 10.1002/ecm.1486\n\nElith et al (2006). Novel methods improve prediction of species’ distributions from occurrence data. DOI: 10.1111/j.2006.0906-7590.04596.x"
  },
  {
    "objectID": "index.html#goals",
    "href": "index.html#goals",
    "title": "2023 Ocean Hackweek",
    "section": "Goals",
    "text": "Goals\nMany tutorials exist to run SDM models, however, most readily available tutorials focus on terrestrial-based models. Our goal through this tutorial is to highlight a marine-based SDM tutorial."
  },
  {
    "objectID": "index.html#datasets",
    "href": "index.html#datasets",
    "title": "2023 Ocean Hackweek",
    "section": "Datasets",
    "text": "Datasets\n\nBiological Data\nOur dataset includes biological presence-only data of four species of sea turtles found in the Indian Ocean. The four species of sea turtles included in our tutorial are:\n- Loggerhead, Caretta caretta - Green, Chelonia mydas - Olive Ridley, Lepidochelys olivacea - Hawksbill, Eretmochelys imbricata\nHowever, for this tutorial example model, we will focus on Loggerhead sea turtles data from 2000 until 2023 sourced from the Ocean Biodiversity Information System (OBIS) via the robis package.\n\n\nEnvironmental Data\nThis tutorial focuses on regions in the northern Indian Sea, specifically the western Arabian Sea, Persian Gulf, Gulf of Oman, Gulf of Aden and Red Sea. Environmental predictor variables were sourced via the SMDpredictor R package and includes:\n\n(https://oceanhackweek.org/ohw23_proj_marinesdms/tutorial/03_sdmpredictors-variables.html)"
  },
  {
    "objectID": "index.html#workflowroadmap",
    "href": "index.html#workflowroadmap",
    "title": "2023 Ocean Hackweek",
    "section": "Workflow/Roadmap",
    "text": "Workflow/Roadmap\nThis tutorial is based on the notes by Ben Tupper (Biglow Lab, Maine), and highlights modeling presence-only data via maxnet R package.\nTutorial roadmap\n\nPresence Data – obtain sea turtle data via robis\nAbsence Data – obtain random occurances within our area of interest using robis\nEnvironmental Data – obtain environmental predictors of interest using SDMpredictors\nModel – run species distribution model and predict using maxnet\nData Visualizations"
  },
  {
    "objectID": "index.html#references",
    "href": "index.html#references",
    "title": "2023 Ocean Hackweek",
    "section": "References",
    "text": "References\n\nBosch S, Fernandez S (2022). sdmpredictors: Species Distribution Modelling Predictor Datasets. R package version 0.2.14, http://lifewatch.github.io/sdmpredictors/.\nOBIS (2023) Ocean Biodiversity Information System. Intergovernmental Oceanographic Commission of UNESCO. www.obis.org. Accessed: 2023-08-08.\nSteven J. Phillips, Miroslav Dudík, Robert E. Schapire. [Internet] Maxent software for modeling species niches and distributions (Version 3.4.1). Available from url: http://biodiversityinformatics.amnh.org/open_source/maxent/. Accessed on 2023-08-10."
  },
  {
    "objectID": "index.html#tutorial-developers",
    "href": "index.html#tutorial-developers",
    "title": "2023 Ocean Hackweek",
    "section": "Tutorial developers",
    "text": "Tutorial developers\n\nCatherine Courtier:\nMackenzie Fiss: Third-year PhD student at Northeastern University studying marine biogeochemistry (DOM) and microbial ecology.\nDenisse Fierro Arcos: PhD candidate at the Institute for Marine and Antarctic Studies (IMAS) and Data Officer at the Integrated Marine Observing System (IMOS)\n\nPaulo Freire: PhD candidate at the University of North Carolina at Charlotte (UNCC) studying marine microbial ecology.\nEli Holmes: Research Fisheries Biologist, Northwest Fisheries Science Center, NOAA Fisheries.\n\nJade Hong: Recently finished ungraduate studies majoring Biology and Marine Science at Boston University.\nTylar Murray: USF IMaRS Software Engineer - code whisperer, data viz enthusiast, scientific generalist, compulsive overengineerer, & UX PhD\n\nCaitlin O’Brien: Research Scientist, Columbia Basin Research, School of Aquatic Fishery and Sciences, University of Washington\nCollins Ongore\nMary Solokas: John A. Knauss Marine Policy Fellow, National Oceanic and Atmospheric Administration\nLaura Tsang:\nBen Tupper: Senior Research Associate at Bigelow Laboratory for Ocean Science"
  },
  {
    "objectID": "index.html#who-this-tutorial-is-intended",
    "href": "index.html#who-this-tutorial-is-intended",
    "title": "2023 Ocean Hackweek",
    "section": "Who this tutorial is intended:",
    "text": "Who this tutorial is intended:\nSome experience programming in R is needed to make the most of this tutorial. To run this tutorial make sure you clone this repository into your local machine by creating a new project that uses version control (git).\nThe tutorial content was developed in a R version 4.2.2 for Linux. Full session information is included below:\nR version 4.2.2 (2022-10-31)\nPlatform: x86_64-conda-linux-gnu (64-bit)\nRunning under: Debian GNU/Linux 11 (bullseye)\n\nMatrix products: default\nBLAS/LAPACK: /opt/conda/lib/libopenblasp-r0.3.21.so\n\nlocale:\n [1] LC_CTYPE=C.UTF-8       LC_NUMERIC=C           LC_TIME=C.UTF-8       \n [4] LC_COLLATE=C.UTF-8     LC_MONETARY=C.UTF-8    LC_MESSAGES=C.UTF-8   \n [7] LC_PAPER=C.UTF-8       LC_NAME=C              LC_ADDRESS=C          \n[10] LC_TELEPHONE=C         LC_MEASUREMENT=C.UTF-8 LC_IDENTIFICATION=C   \n\nattached base packages:\n[1] stats     graphics  grDevices utils     datasets  methods   base     \n\nloaded via a namespace (and not attached):\n[1] compiler_4.2.2 tools_4.2.2"
  },
  {
    "objectID": "index.html#additional-resources",
    "href": "index.html#additional-resources",
    "title": "2023 Ocean Hackweek",
    "section": "Additional resources",
    "text": "Additional resources\nIf you need additional support with R programming, you can check the following resources:\n- R for Data Science - 2nd edition by Wickham, Çetinkaya-Rundel and Grolemund.\n- Data analysis and visualisation in R for ecologists\nFor information on how to use git and GitHub with R, Happy Git and GitHub for the useR by Jenny Bryan is a great resource."
  },
  {
    "objectID": "tutorial/00_Region.html",
    "href": "tutorial/00_Region.html",
    "title": "Setting up the region",
    "section": "",
    "text": "As a preliminary, we will define some shape files and plots of our region that we will use in later steps."
  },
  {
    "objectID": "tutorial/00_Region.html#load-libraries",
    "href": "tutorial/00_Region.html#load-libraries",
    "title": "Setting up the region",
    "section": "Load libraries",
    "text": "Load libraries\n\n#Dealing with spatial data\nlibrary(sf)\n#Getting base maps\nlibrary(rnaturalearth)\n#Data manipulation and visualisation\nlibrary(tidyverse)\nlibrary(janitor)\nlibrary(ggspatial)"
  },
  {
    "objectID": "tutorial/00_Region.html#create-a-bounding-box",
    "href": "tutorial/00_Region.html#create-a-bounding-box",
    "title": "Setting up the region",
    "section": "Create a bounding box",
    "text": "Create a bounding box\nWe will use a bounding box for the region of our interest (Arabian Sea and the Bay of Bengal) to extract C. caretta data relevant to our study area.\n\n#We create a bounding box using minimum and maximum coordinate pairs\nextent_polygon <- st_bbox(c(xmin = 41.875, xmax = 65.125, \n                            ymax = -0.125, ymin = 32.125), \n                          #Assign reference system\n                          crs = st_crs(4326)) %>% \n  #Turn into sf object\n  st_as_sfc()\n\n#Extract polygon geometry \npol_geometry <- st_as_text(extent_polygon[[1]])\n\n#Saving bounding box for future use\nfil <- here::here(\"data\", \"region\", \"BoundingBox.shp\")\nwrite_sf(extent_polygon, fil)"
  },
  {
    "objectID": "tutorial/00_Region.html#create-a-world-map",
    "href": "tutorial/00_Region.html#create-a-world-map",
    "title": "Setting up the region",
    "section": "Create a world map",
    "text": "Create a world map\nWe can create a world map to show where our study region is. ### Plotting region of interest This allows us to check our polygon of interest is located in the correct region.\n\n#Getting base map\nworld <- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\n#Plotting map\nworld_box <- ggplot() + \n  #Adding base map\n  geom_sf(data = world) +\n  #Adding bounding box\n  geom_sf(data = extent_polygon, color = \"red\", fill = NA)+\n  #Setting theme of plots to not include a grey background\n  theme_bw()\nfil <- here::here(\"data\", \"region\", \"world_box.rda\")\nsave(world_box, file=fil)\n\nworld_box"
  },
  {
    "objectID": "tutorial/00_Region.html#create-a-region-map",
    "href": "tutorial/00_Region.html#create-a-region-map",
    "title": "Setting up the region",
    "section": "Create a region map",
    "text": "Create a region map\nFirst we create a base map of our region and save it.\n\nbase_region_map <- ggplot()+\n  #Adding base layer (world map)\n  geom_sf(data = world, fill = \"antiquewhite\")+\n  #Constraining map to original bounding box\n  lims(x = c(st_bbox(extent_polygon)$xmin, st_bbox(extent_polygon)$xmax),\n       y = c(st_bbox(extent_polygon)$ymin, st_bbox(extent_polygon)$ymax))\nfil <- here::here(\"data\", \"region\", \"base_region_map.rda\")\nsave(base_region_map, file=fil)\n\nbase_region_map\n\n\n\n\nWe will add some more features to our map: colors, scale and compass.\n\nregion_map <- base_region_map +\n  #Add scale bar on the top right of the plot\n  annotation_scale(location = \"tr\", width_hint = 0.5)+\n  #Add north arrow on the top left of plot\n  annotation_north_arrow(location = \"tl\", which_north = \"true\",\n                         #Include small buffer from plot edge\n                         pad_x = unit(0.01, \"in\"), pad_y = unit(0.05, \"in\"),\n                         #Set style of north arrow\n                         style = north_arrow_fancy_orienteering) +\n  #Changing color, type and size of grid lines\n  theme(panel.grid.major = element_line(color = gray(.5), linetype = \"dashed\", size = 0.5), \n  #Change background of map\n  panel.background = element_rect(fill = \"aliceblue\")) +\n  labs(x = \"longitude\", y = \"latitude\")\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\nfil <- here::here(\"data\", \"region\", \"region_map.rda\")\nsave(region_map, file=fil)\n\nregion_map\n\nScale on map varies by more than 10%, scale bar may be inaccurate\n\n\n\n\n\nWe add some labels for the countries.\n\n#Extracting labels for countries in base map\nworld_points <- world %>% \n  st_make_valid(world) %>%\n  #Getting centroids for all polygons in the world base map\n  st_centroid(geometry) %>% \n  #Getting coordinates for each centroid\n  st_coordinates() %>% \n  #Adding centroids to original base map\n  bind_cols(world)\n\n#Do not use spherical geometry\nsf_use_s2(FALSE)\n\n#Adding labels to map\nregion_map_label <- region_map +\n  geom_text(data = world_points, \n            #Point to coordinates and column with country names\n            aes(x = X, y = Y, label = name),\n            #Changing color and size of labels\n            color = \"darkblue\", size = 3, \n            #Avoid label overlap\n            check_overlap = TRUE)\nfil <- here::here(\"data\", \"region\", \"region_map_label.rda\")\nsave(region_map_label, file=fil)\n\n#Checking final map\nregion_map_label"
  },
  {
    "objectID": "tutorial/00_Roadmap.html",
    "href": "tutorial/00_Roadmap.html",
    "title": "SDM Roadmap",
    "section": "",
    "text": "This section (Background) discusses the steps of the Species Distribution Model (SDM) Workflow and shows some different approaches that you might take."
  },
  {
    "objectID": "tutorial/00_Roadmap.html#sdm-workflow",
    "href": "tutorial/00_Roadmap.html#sdm-workflow",
    "title": "SDM Roadmap",
    "section": "SDM Workflow",
    "text": "SDM Workflow\nCreating a Species Distribution Model (SDM) has five steps. In the “Background” section, we discuss these steps in the context of marine SDMs using the example of the Loggerhead sea turtle in the Arabian Sea. In the “Our workflow” section, we show the specific approaches that we used in OHW23. Then in the “Turtle SDMs” section, we show the SDMs created by the team.\n\nSpecify the region\n– shows how to create a bounding box for the region and some base maps\nObtain presence Data\n– shows how to obtain sea turtle presence data from OBIS via robis\nCreate Absence (also called background) Points\n– discusses three methods to create random background points within a area of interest\nExtract environmental variables\n– shows how to obtain environmental predictors of interest using sdmpredictors\nModels\n– discusses different SDM modeling options and discusses the maxent model that we use in this tutorial\nData Visualizations"
  },
  {
    "objectID": "tutorial/01_Presence_Data.html",
    "href": "tutorial/01_Presence_Data.html",
    "title": "Obtaining presence data for loggerhead turtles from OBIS",
    "section": "",
    "text": "In this section, we will explore Loggerhead sea turtle (Caretta caretta) data from 2000 until present from the Ocean Biodiversity Information System (OBIS). We will use the robis package to search the OBIS library and download relevant data. We will then check for quality control flags and remove problematic observations from the data (i.e., sea turtle observations on land)."
  },
  {
    "objectID": "tutorial/01_Presence_Data.html#load-libraries",
    "href": "tutorial/01_Presence_Data.html#load-libraries",
    "title": "Obtaining presence data for loggerhead turtles from OBIS",
    "section": "Load libraries",
    "text": "Load libraries\n\n#Dealing with spatial data\nlibrary(sf)\n#Getting base maps\nlibrary(rnaturalearth)\n#Access to OBIS\nlibrary(robis)\n#Data manipulation and visualisation\nlibrary(tidyverse)\nlibrary(janitor)"
  },
  {
    "objectID": "tutorial/01_Presence_Data.html#load-the-region-data",
    "href": "tutorial/01_Presence_Data.html#load-the-region-data",
    "title": "Obtaining presence data for loggerhead turtles from OBIS",
    "section": "Load the region data",
    "text": "Load the region data\nWe defined our region and bounding box in the Region page.\nLoad the bounding box.\n\n#Loading bounding box for the area of interest\nfil <- here::here(\"data\", \"region\", \"BoundingBox.shp\")\nextent_polygon <- read_sf(fil)\n\n#Extract polygon geometry \npol_geometry <- st_as_text(extent_polygon$geometry)"
  },
  {
    "objectID": "tutorial/01_Presence_Data.html#get-observations",
    "href": "tutorial/01_Presence_Data.html#get-observations",
    "title": "Obtaining presence data for loggerhead turtles from OBIS",
    "section": "Get Observations",
    "text": "Get Observations\nWe will use the robis package to find observations of Loggerhead sea turtles (C. caretta) published in OBIS.\n\n#Search OBIS for loggerhead observations from 2000\ncaretta_obs <- occurrence(\"Caretta caretta\", \n                          startdate = as.Date(\"2000-01-01\"),\n                          #Apply spatial constraint\n                          geometry = pol_geometry,\n                          #Include absence records if available\n                          absence = \"include\")\n\n\nRetrieved 5000 records of approximately 5269 (94%)\nRetrieved 5269 records of\napproximately 5269 (100%)\n\n#Check structure of results\nglimpse(caretta_obs)\n\nRows: 5,269\nColumns: 103\n$ associatedReferences          <chr> \"[{\\\"crossref\\\":{\\\"citeinfo\\\":{\\\"origin\\…\n$ basisOfRecord                 <chr> \"MachineObservation\", \"MachineObservatio…\n$ bibliographicCitation         <chr> \"[{\\\"crossref\\\":{\\\"citeinfo\\\":{\\\"origin\\…\n$ catalogNumber                 <chr> \"1014_8853\", \"1014_9766\", \"1014_8861\", \"…\n$ collectionCode                <chr> \"1014\", \"1014\", \"1014\", \"1014\", \"1014\", …\n$ coordinatePrecision           <chr> \"9.99999999999999955e-07\", \"9.9999999999…\n$ coordinateUncertaintyInMeters <chr> \"0.11\", \"0.11\", \"0.11\", \"0.11\", \"0.11\", …\n$ datasetID                     <chr> \"1014\", \"1014\", \"1014\", \"1014\", \"1014\", …\n$ datasetName                   <chr> \"IFREMER/Kélonia satellite tracked late …\n$ dateIdentified                <chr> \"2012-03-30T08:55:10\", \"2011-04-12T19:12…\n$ decimalLatitude               <dbl> 9.14804, 6.40193, 9.21307, 15.39172, 15.…\n$ decimalLongitude              <dbl> 50.69448, 59.87883, 50.82211, 55.71303, …\n$ eventDate                     <chr> \"2012-03-30T08:55:10\", \"2011-04-12T19:12…\n$ eventTime                     <chr> \"05:55:10Z\", \"15:12:41Z\", \"23:43:31Z\", \"…\n$ family                        <chr> \"Cheloniidae\", \"Cheloniidae\", \"Cheloniid…\n$ footprintWKT                  <chr> \"POINT(50.69448 9.14804)\", \"POINT(59.878…\n$ genus                         <chr> \"Caretta\", \"Caretta\", \"Caretta\", \"Carett…\n$ geodeticDatum                 <chr> \"EPSG:4326 WGS84\", \"EPSG:4326 WGS84\", \"E…\n$ georeferencedDate             <chr> \"2012-03-30T08:55:10\", \"2011-04-12T19:12…\n$ identificationRemarks         <chr> \"Identification Type:Telemetry\", \"Identi…\n$ individualCount               <chr> \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", \"1\", …\n$ institutionCode               <chr> \"IFREMER and Kélonia\", \"IFREMER and Kélo…\n$ kingdom                       <chr> \"Animalia\", \"Animalia\", \"Animalia\", \"Ani…\n$ license                       <chr> \"http://creativecommons.org/licenses/by-…\n$ lifeStage                     <chr> \"Juvenile\", \"Juvenile\", \"Juvenile\", \"Juv…\n$ modified                      <chr> \"2013-10-25 13:35:20\", \"2013-10-25 13:35…\n$ nomenclaturalCode             <chr> \"WoRMS LSID\", \"WoRMS LSID\", \"WoRMS LSID\"…\n$ occurrenceID                  <chr> \"1014_8853\", \"1014_9766\", \"1014_8861\", \"…\n$ occurrenceRemarks             <chr> \"Telemetry\", \"Telemetry\", \"Telemetry\", \"…\n$ occurrenceStatus              <chr> \"present\", \"present\", \"present\", \"presen…\n$ order                         <chr> \"Testudines\", \"Testudines\", \"Testudines\"…\n$ organismID                    <chr> \"57684\", \"66818\", \"57684\", \"66839\", \"668…\n$ organismRemarks               <chr> \"Tagged animal. organismID may refer to …\n$ ownerInstitutionCode          <chr> \"IFREMER and Kélonia\", \"IFREMER and Kélo…\n$ phylum                        <chr> \"Chordata\", \"Chordata\", \"Chordata\", \"Cho…\n$ recordNumber                  <chr> \"1014_8853\", \"1014_9766\", \"1014_8861\", \"…\n$ scientificName                <chr> \"Caretta caretta\", \"Caretta caretta\", \"C…\n$ scientificNameAuthorship      <chr> \"(Linnaeus, 1758)\", \"(Linnaeus, 1758)\", …\n$ scientificNameID              <chr> \"urn:lsid:marinespecies.org:taxname:1372…\n$ specificEpithet               <chr> \"caretta\", \"caretta\", \"caretta\", \"carett…\n$ taxonRank                     <chr> \"Species\", \"Species\", \"Species\", \"Specie…\n$ taxonRemarks                  <chr> \"Taxon recorded as \\\"Caretta caretta\\\" b…\n$ taxonomicStatus               <chr> \"valid\", \"valid\", \"valid\", \"valid\", \"val…\n$ type                          <chr> \"Event\", \"Event\", \"Event\", \"Event\", \"Eve…\n$ verbatimEventDate             <chr> \"2012-03-30 08:55:10\", \"2011-04-12 19:12…\n$ vernacularName                <chr> \"Loggerhead Sea Turtle\", \"Loggerhead Sea…\n$ waterBody                     <chr> \"Reunion Island,Oman,South-Africa\", \"Reu…\n$ id                            <chr> \"000341f8-f206-4120-bc73-432a0c729d7a\", …\n$ dataset_id                    <chr> \"7687b242-05b7-48d7-a316-ba6dc34e72b5\", …\n$ node_id                       <chr> \"573654c1-4ce7-4ea2-b2f1-e4d42f8f9c31\", …\n$ date_start                    <dbl> 1.333066e+12, 1.302566e+12, 1.333152e+12…\n$ date_mid                      <dbl> 1.333066e+12, 1.302566e+12, 1.333152e+12…\n$ date_end                      <dbl> 1.333066e+12, 1.302566e+12, 1.333152e+12…\n$ date_year                     <int> 2012, 2011, 2012, 2011, 2011, 2011, 2011…\n$ dropped                       <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE…\n$ absence                       <lgl> FALSE, FALSE, FALSE, FALSE, FALSE, FALSE…\n$ marine                        <lgl> TRUE, TRUE, TRUE, TRUE, TRUE, TRUE, TRUE…\n$ subphylum                     <chr> \"Vertebrata\", \"Vertebrata\", \"Vertebrata\"…\n$ infraphylum                   <chr> \"Gnathostomata\", \"Gnathostomata\", \"Gnath…\n$ megaclass                     <chr> \"Tetrapoda\", \"Tetrapoda\", \"Tetrapoda\", \"…\n$ superclass                    <chr> \"Reptilia\", \"Reptilia\", \"Reptilia\", \"Rep…\n$ suborder                      <chr> \"Cryptodira\", \"Cryptodira\", \"Cryptodira\"…\n$ superfamily                   <chr> \"Chelonioidea\", \"Chelonioidea\", \"Cheloni…\n$ species                       <chr> \"Caretta caretta\", \"Caretta caretta\", \"C…\n$ kingdomid                     <int> 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2, 2…\n$ phylumid                      <int> 1821, 1821, 1821, 1821, 1821, 1821, 1821…\n$ subphylumid                   <int> 146419, 146419, 146419, 146419, 146419, …\n$ infraphylumid                 <int> 1828, 1828, 1828, 1828, 1828, 1828, 1828…\n$ megaclassid                   <int> 1831, 1831, 1831, 1831, 1831, 1831, 1831…\n$ superclassid                  <int> 1838, 1838, 1838, 1838, 1838, 1838, 1838…\n$ orderid                       <int> 2689, 2689, 2689, 2689, 2689, 2689, 2689…\n$ suborderid                    <int> 148741, 148741, 148741, 148741, 148741, …\n$ superfamilyid                 <int> 987094, 987094, 987094, 987094, 987094, …\n$ familyid                      <int> 136999, 136999, 136999, 136999, 136999, …\n$ genusid                       <int> 137066, 137066, 137066, 137066, 137066, …\n$ speciesid                     <int> 137205, 137205, 137205, 137205, 137205, …\n$ aphiaID                       <int> 137205, 137205, 137205, 137205, 137205, …\n$ originalScientificName        <chr> \"Caretta caretta\", \"Caretta caretta\", \"C…\n$ category                      <chr> \"VU\", \"VU\", \"VU\", \"VU\", \"VU\", \"VU\", \"VU\"…\n$ flags                         <chr> \"NO_DEPTH\", \"NO_DEPTH\", \"NO_DEPTH\", \"NO_…\n$ bathymetry                    <int> 35, 3051, 136, 2784, 2453, 2736, 2880, 2…\n$ shoredistance                 <int> 4680, 899682, 12208, 193567, 143853, 100…\n$ sst                           <dbl> 26.21, 28.67, 26.21, 27.00, 26.92, 26.92…\n$ sss                           <dbl> 35.63, 35.74, 35.65, 36.09, 36.09, 36.10…\n$ dynamicProperties             <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ sex                           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ continent                     <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ country                       <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ day                           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ georeferenceRemarks           <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ locality                      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ maximumDepthInMeters          <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ maximumElevationInMeters      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ minimumDepthInMeters          <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ minimumElevationInMeters      <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ month                         <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ recordedBy                    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ references                    <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ samplingProtocol              <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ year                          <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ depth                         <dbl> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ superdomain                   <chr> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …\n$ superdomainid                 <int> NA, NA, NA, NA, NA, NA, NA, NA, NA, NA, …"
  },
  {
    "objectID": "tutorial/01_Presence_Data.html#explore-obis-results",
    "href": "tutorial/01_Presence_Data.html#explore-obis-results",
    "title": "Obtaining presence data for loggerhead turtles from OBIS",
    "section": "Explore OBIS results",
    "text": "Explore OBIS results\nOur search produced 5269 results for the area of our interest. However, before we continue to use this data as input for our species distribution models, we must clean it first to ensure we have a good quality dataset.\nIn this section, we will explore the results of our OBIS search so we can design a data cleaning workflow. We will check the content of some of the columns in our data frame.\nYou may want to refer to the OBIS manual and the OBIS webpage about Data Access.\n\n#Checking values in basis of record column\ncaretta_obs %>% \n  distinct(basisOfRecord)\n\n# A tibble: 2 × 1\n  basisOfRecord     \n  <chr>             \n1 MachineObservation\n2 Occurrence        \n\n\nIn this context, MachineObservation refers to records obtained with satellite tags. While Occurrence refers to records obtained by human observers on the field. These two datasets cannot be treated in the same way as MachineObservation records are not independent as they record the movements of a single individual.\nWe can also check whether or not absence data is available for the loggerhead se a turtles in our area of interest.\n\ncaretta_obs %>% \n  distinct(absence)\n\n# A tibble: 1 × 1\n  absence\n  <lgl>  \n1 FALSE  \n\n\nWe only have presence data available, which is an important factor to consider when designing our species distribution model workflow.\nWe can also check the coordinateUncertaintyInMeters, which gives us an indication of the error associated with a particular record. If we look at the names of the columns printed at the beginning of the script, you may notice that this column has been read as characters. We will change it to numbers before looking at the values in the column.\n\n#Changing column from characters to numeric\ncaretta_obs <- caretta_obs %>% \n  mutate(coordinateUncertaintyInMeters = as.numeric(coordinateUncertaintyInMeters))\n\n#Checking uncertainty values for coordinates\ncaretta_obs %>% \n  distinct(coordinateUncertaintyInMeters)\n\n# A tibble: 3 × 1\n  coordinateUncertaintyInMeters\n                          <dbl>\n1                          0.11\n2                     111319.  \n3                         NA   \n\n\nIt is worth noting that not all providers share a measurement of uncertainty, but we can use this whenever is available to apply some sort of quality control to our data.\nHere, we see that some observations have uncertainty of centimeters (0.11 m), but there are other observations with uncertainty over 100 km. For this example, we will remove these observations with large uncertainties."
  },
  {
    "objectID": "tutorial/01_Presence_Data.html#quality-control-flags",
    "href": "tutorial/01_Presence_Data.html#quality-control-flags",
    "title": "Obtaining presence data for loggerhead turtles from OBIS",
    "section": "Quality control flags",
    "text": "Quality control flags\nOBIS provides some quality control (QC) flags for each record that may help us identify observations of lower quality. For an explanation of OBIS flags, check this repository.\nFirst, we will check the quality flags included in our results.\n\ncaretta_obs %>% \n  distinct(flags)\n\n# A tibble: 4 × 1\n  flags             \n  <chr>             \n1 NO_DEPTH          \n2 NO_DEPTH,ON_LAND  \n3 DEPTH_EXCEEDS_BATH\n4 <NA>              \n\n\nWe will now plot our dataset on a map and use the information in the flags column to color code the observations. This can help us decide whether we should include or exclude them from further analyses.\nFirst we will load the region map that was saved in the Region page\n\nfil <- here::here(\"data\", \"region\", \"region_map_label.rda\")\nload(fil)\n\n\nregion_map_label +\n  geom_point(data = caretta_obs, \n             #Using coordinates to plot and color based on value in flags column\n             aes(decimalLongitude, decimalLatitude, color = flags))\n\nScale on map varies by more than 10%, scale bar may be inaccurate\n\n\nWarning: Removed 231 rows containing missing values (`geom_text()`).\n\n\n\n\n\nFrom the plot above, we should consider removing at least some of the observations classified as NO_DEPTH,ON_LAND. This is because loggerhead sea turtles are not present inland. Instead, they are found in temperate and subtropical ocean waters and in sandy beaches.\nSome of these observations appear to be quite close to the shore, so they may have occurred in a sandy beach. We can check the proximity of the observation to the shore using the shoredistance column, which provides the distance to shore in meters.\n\ncaretta_obs %>% \n  filter(flags == \"NO_DEPTH,ON_LAND\") %>% \n  select(shoredistance) %>% \n  arrange(desc(shoredistance))\n\n# A tibble: 25 × 1\n   shoredistance\n           <int>\n 1          -231\n 2          -394\n 3          -971\n 4         -1403\n 5         -3895\n 6         -5896\n 7         -8319\n 8         -8562\n 9        -17661\n10        -19763\n# … with 15 more rows\n\n\nThe inland observations are at least 231 meters away from the coast and up to 515 kilometers. For simplicity, we will remove all points flagged as NO_DEPTH,ON_LAND, but it is recommended that locations are looked more in depth and determine how likely it was that an individual was present at that location.\nWe can also check if any other observations have been reported in land. We will filter out the NO_DEPTH,ON_LAND flags and check for any negative values in the shoredistance column.\n\ncaretta_obs %>% \n  filter(flags != \"NO_DEPTH,ON_LAND\" & shoredistance < 0)\n\n# A tibble: 0 × 103\n# … with 103 variables: associatedReferences <chr>, basisOfRecord <chr>,\n#   bibliographicCitation <chr>, catalogNumber <chr>, collectionCode <chr>,\n#   coordinatePrecision <chr>, coordinateUncertaintyInMeters <dbl>,\n#   datasetID <chr>, datasetName <chr>, dateIdentified <chr>,\n#   decimalLatitude <dbl>, decimalLongitude <dbl>, eventDate <chr>,\n#   eventTime <chr>, family <chr>, footprintWKT <chr>, genus <chr>,\n#   geodeticDatum <chr>, georeferencedDate <chr>, …\n\n\nNo observations were returned, which is good news.\nAnother feature worth pointing out in our data is that some of the observations appear to be gridded as they are evenly spaced. This is confirmed by the occurrenceRemarks column, which states that some observations are: Telemetry locations aggregated per species per 1-degree cell. This is not ideal and you may need to consider if the inclusion of these data points are suitable for your project. In this example, we will remove them from our analysis."
  },
  {
    "objectID": "tutorial/01_Presence_Data.html#problematic-observations",
    "href": "tutorial/01_Presence_Data.html#problematic-observations",
    "title": "Obtaining presence data for loggerhead turtles from OBIS",
    "section": "Problematic observations",
    "text": "Problematic observations\nIn this step, we will remove observations with coordinate uncertainty over 100 km, any observations with the NO_DEPTH,ON_LAND flag, and any records that have been aggregated to a 1-degree cell.\n\ncaretta_obs <- caretta_obs %>%\n  #Removing on land observations\n  filter(flags != \"NO_DEPTH,ON_LAND\" | is.na(flags)) %>%\n  #Removing observations with uncertainty over 100 km\n  filter(coordinateUncertaintyInMeters <= 100000 | is.na(coordinateUncertaintyInMeters)) %>%\n  #Removing records aggregated to 1 degree \n  filter(!str_detect(occurrenceRemarks, \"degree\"))"
  },
  {
    "objectID": "tutorial/01_Presence_Data.html#saving-clean-data",
    "href": "tutorial/01_Presence_Data.html#saving-clean-data",
    "title": "Obtaining presence data for loggerhead turtles from OBIS",
    "section": "Saving clean data",
    "text": "Saving clean data\nNow that we have removed the problematic observations, we can save the new dataset into our local machine. We will save this under the data folder.\n\nfil <- here::here(\"data\", \"raw-bio\", \"loggerhead-robis.csv\")\nwrite_csv(caretta_obs, fil)"
  },
  {
    "objectID": "tutorial/02_Background_Data.html",
    "href": "tutorial/02_Background_Data.html",
    "title": "Getting background data from OBIS",
    "section": "",
    "text": "In this notebook, we will explore three approaches to create background samples, aka pseudo absences. These are points where turtles were not recorded. These absences are needed for our choice of species distribution model algorithm. “Absences” does not mean that turtle could not be sighted here but that we have no records at these locations, either because we didn’t look or looked and didn’t see them.\nThese three approaches are as follows:\nIn both cases, points will be constrained to fit within our area of interest."
  },
  {
    "objectID": "tutorial/02_Background_Data.html#loading-libraries",
    "href": "tutorial/02_Background_Data.html#loading-libraries",
    "title": "Getting background data from OBIS",
    "section": "Loading libraries",
    "text": "Loading libraries\n\n#Deal with spatial data\nlibrary(sf)\n#Base maps and plotting spatial data\nlibrary(rnaturalearth)\nlibrary(mapview)\nlibrary(raster)\n#Data visualisation and manipulation\nlibrary(tidyverse)\n#Find files easily\nlibrary(here)\n#Access to OBIS\nlibrary(robis)\n#SDM\nlibrary(sdmpredictors)\nlibrary(dismo)\nlibrary(ggspatial)"
  },
  {
    "objectID": "tutorial/02_Background_Data.html#set-up",
    "href": "tutorial/02_Background_Data.html#set-up",
    "title": "Getting background data from OBIS",
    "section": "Set-up",
    "text": "Set-up\n\nSetting base directories\nThese directories contain the biological data (i.e., presence locations of loggerhead sea turtles) and environmental data.\n\n#Setting directories containing input data\ndir_data <- file.path(here::here(), \"data/raw-bio\")\ndir_env <- file.path(here::here(), \"data/env\")\n\n\n\nLoading bounding box for region of interest\nIn the Region page, we created a bounding box for our region of interest. We will load this bounding box here to spatially constrain our data.\n\n#Loading bounding box for the area of interest\nfil <- here::here(\"data\", \"region\", \"BoundingBox.shp\")\nextent_polygon <- read_sf(fil)\n\n#Extract polygon geometry \npol_geometry <- st_as_text(extent_polygon$geometry)"
  },
  {
    "objectID": "tutorial/02_Background_Data.html#approach-1-use-other-species",
    "href": "tutorial/02_Background_Data.html#approach-1-use-other-species",
    "title": "Getting background data from OBIS",
    "section": "Approach 1: Use other species",
    "text": "Approach 1: Use other species\nIn this approach we use other marine species presence locations as our locations for our background samples.\n\nGetting occurrence data from OBIS\nWe will use robis to get observations for marine species from OBIS within our bounding box. OBIS data includes about 100 different columns, but not all of these columns are relevant to us. We will define the columns that we need and then we will perform a search of the OBIS database.\n\n\nDefining relevant columns\n\ncols.to.use <- c(\"scientificName\", \"dateIdentified\", \"eventDate\", \"decimalLatitude\", \"decimalLongitude\", \"coordinateUncertaintyInMeters\", \"bathymetry\",  \"shoredistance\", \"sst\", \"sss\")\n\n\n\nQuerying OBIS\nBy setting the wrims parameter to TRUE we include observations of species registerd in the World Register of Introduced Marine Species (WRiMS).\n\n#Applying bounding box and including WRiMS species\nbackground <- occurrence(geometry = pol_geometry, wrims = TRUE, \n                         #DNA data is not needed, subsetting columns of interest\n                         dna = FALSE, fields = cols.to.use,\n                         #Excluding records labelled as being on land\n                         exclude = \"ON_LAND\")\n\n\nRetrieved 5000 records of approximately 20428 (24%)\nRetrieved 10000 records of\napproximately 20428 (48%)\nRetrieved 15000 records of approximately 20428\n(73%)\nRetrieved 20000 records of approximately 20428 (97%)\nRetrieved 20428\nrecords of approximately 20428 (100%)\n\n\n\n\nSaving background data\n\n#Setting full file path to save background information\nfile_path_out <- file.path(dir_data, \"io-background.csv\")\n\n#Saving background data as csv\nwrite_csv(background, file_path_out)\n\n\n\n(Optional) Load background data\nIf you have previously downloaded the background data, you can simply load the data to the environment instead of downloading it again. To do this, you can use the code below.\n\n#Find background file in our biological data folder\nfile_path_bg <- list.files(dir_data, pattern = \"background\", full.names = TRUE)\n\n#Load file\nbackground_1 <- read_csv(file_path_bg)\n\n\n\nPlotting background data\nWe will create a map with all the observations we obtained from OBIS within our region of interest.\nFirst we will load the region map that was saved in the Region page\n\nfil <- here::here(\"data\", \"region\", \"region_map_label.rda\")\nload(fil)\n\nSaving map into variable\n\n# load our base map and add points\nregion_map_label +\n  geom_point(data = background, \n             #Point to coordinates for background points\n             aes(x = decimalLongitude, y = decimalLatitude), \n             #Changing color and size of points for background data\n             color = \"red\", size = 0.1)\n\nScale on map varies by more than 10%, scale bar may be inaccurate\n\n\nWarning: Removed 231 rows containing missing values (`geom_text()`).\n\n\n\n\n\nAs you can see from the map above, this approach is not truly random. This is why we are including a second method to create background samples."
  },
  {
    "objectID": "tutorial/02_Background_Data.html#approach-2.-random-points-in-our-region",
    "href": "tutorial/02_Background_Data.html#approach-2.-random-points-in-our-region",
    "title": "Getting background data from OBIS",
    "section": "Approach 2. Random points in our region",
    "text": "Approach 2. Random points in our region\nThis section has been adapted from this online tutorial.\n\nLoading raster layer for area of interest\nWe will be using sdmpredictors for our environmental data layers (variables). We need to load a raster layer from sdmpredictors so we can sample locations from this raster. It doesn’t matter what variable we use, it just needs to not have NAs. Using a marine layer from sdmpredictors ensures that we will not sample from the land. See the sdmpredictors section for discussion of accessing rasters with sdmpredictors and how to find out what layers are available.\nWe used a bathymetery layer: “MS_bathy_5m”. We will load this data and crop it using our bounding box.\n\n#Set default directory for environmental data\noptions(sdmpredictors_datadir = dir_env)\n#Loading bathymetry\nenv_stack <- load_layers(\"MS_bathy_5m\") %>% \n  #Cropping to our area of interest\n  crop(extent_polygon)\n\nWe can plot the cropped bathymetry to ensure it matches our study region and we did not make any mistakes.\n\nplot(env_stack)\n\n\n\n\nWe can see the outline of our area of interest. Now we can continue with creating our background points.\n\n\nSample points from bathymetry layer\nUsing the dismo package, we will create random points over the bathymetry layer that we will use as background points. In this example, we have chosen to produce 1000 background points.\nIt is worth noting that the distribution and number of background points has a strong influence on SDM results. See the README file for resources discussing this issue.\n\n#Setting seed for reproducibility\nset.seed(42)\n\n#Setting number of background points required\nnsamp <- 1000\n\n#Create background points\nbackground <- randomPoints(env_stack, nsamp) %>% \n  #Transform to tibble\n  as_tibble() %>% \n  #Transform to sf object\n  st_as_sf(coords = c(\"x\", \"y\"), crs = 4326)\n\n\n\nPlotting results\nWe will plot results to make sure our background points are in the ocean only. Here we use an alternate why to plot points on a map.\n\nmapview(background, col.regions = \"gray\")\n\nWarning in cbind(`Feature ID` = fid, mat): number of rows of result is not a\nmultiple of vector length (arg 1)\n\n\n\n\n\n\n\n\n\nSaving background samples\nWe can now save the background locations to our local machine.\n\nabsence_geo <- file.path(dir_data, \"absence.geojson\")\npts_absence_csv <- file.path(dir_data, \"pts_absence.csv\")\nst_write(background, pts_absence_csv, layer_options = \"GEOMETRY=AS_XY\", append = FALSE)\n\nDeleting layer `pts_absence' using driver `CSV'\nWriting layer `pts_absence' to data source \n  `/home/jovyan/R/ohw23_proj_marinesdms/data/raw-bio/pts_absence.csv' using driver `CSV'\noptions:        GEOMETRY=AS_XY \nUpdating existing layer pts_absence\nWriting 1000 features with 0 fields and geometry type Point."
  },
  {
    "objectID": "tutorial/02_Background_Data.html#approach-3.-random-points-a-convex-hull",
    "href": "tutorial/02_Background_Data.html#approach-3.-random-points-a-convex-hull",
    "title": "Getting background data from OBIS",
    "section": "Approach 3. Random points a convex hull",
    "text": "Approach 3. Random points a convex hull\nThis section has been adapted from this online tutorial and this online tutorial.\nNEED TO ADD\nThe next notebook will discuss how to get environmental data that we will use as inputs in our SDM from the sdmpredictors package."
  },
  {
    "objectID": "tutorial/03_sdmpredictors-variables.html",
    "href": "tutorial/03_sdmpredictors-variables.html",
    "title": "Marine SDM Variables",
    "section": "",
    "text": "Here we discuss an approach for finding a set of environmental variables to use for our sea turtle SDM. In this case, we are not sea turtle experts so we used AI to help us search for variables to include. The workflow has two steps. We are using the sdmpredictors R package to extract data layers for the marine environment."
  },
  {
    "objectID": "tutorial/03_sdmpredictors-variables.html#querying-ai",
    "href": "tutorial/03_sdmpredictors-variables.html#querying-ai",
    "title": "Marine SDM Variables",
    "section": "Querying AI",
    "text": "Querying AI\nThe sdmpredictors package was created in 2022 and ChatGPT does not have data this recent so we used Google Bard to help us find marine environmental data variables for sea turtles.\nTo obtain the marine environmental data for our SDMs for predicting the occurrence of green sea turtle in the Arabian Sea, we used the sdmpredictors R package. There are over 100 environmental data layers that can be found in the sdmpredictors package. These data layers cover a wide range of environmental variables, including climate, land cover, marine, freshwater, and soil properties.\nIn order to define the best variables for using in our sea turtle prediction, we used the assistance of the artificial intelligence chatbot developed by Google - Google Bard. Google Bard has access to a vast amount of information on sea turtles and their habitat and so can understand complex relationships between environmental variables and sea turtle distribution.\nThe prompt used for achieving the best variables for green sea turtles was:\nWhat is the R package sdmpredictors?\nHow to use it to obtain environmental datasets from an especific region?\nWhich marine datasets available in sdmpreditors can be used for create a sdm to sea turtles? give me some examples\nList all the names of these layers\nWhich are all the variables I should use to create a sdm for sea turtles?\nGive me a table with all the information I need to create a sdm for green sea turtles\nCreate the most exaustive list possible\nThe generated table with all the relevant information:\n\n\n\n\n\n\n\n\nVariable\nDescription\nData source\n\n\n\n\nBathymetry\nThe depth of the ocean floor is important for green sea turtles because they need to be able to reach the seafloor to feed and nest.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nSea surface temperature\nGreen sea turtles prefer warmer waters, but they can also tolerate cooler temperatures.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nChlorophyll concentration\nGreen sea turtles eat algae, so chlorophyll concentration is a useful predictor of their food availability.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nSeagrass cover\nSeagrass is an important food source and nesting habitat for green sea turtles.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nSalinity\nGreen sea turtles are adapted to specific ranges of salinity.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nNitrate concentration\nNitrate is a nutrient that is essential for the growth of algae, which is a food source for green sea turtles.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nDistance to shore\nGreen sea turtles need to be able to reach the ocean floor to feed and nest.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nMean annual precipitation\nGreen sea turtles are adapted to a variety of precipitation regimes, but they avoid areas that are too dry or too wet.\nWorldClim\n\n\nMean annual temperature\nGreen sea turtles are adapted to a variety of temperature regimes, but they avoid areas that are too cold or too hot.\nWorldClim\n\n\nMean monthly temperature\nGreen sea turtles are adapted to a variety of temperature regimes, but they avoid areas that have extreme variations in monthly temperatures.\nWorldClim\n\n\nMean monthly precipitation\nGreen sea turtles are adapted to a variety of precipitation regimes, but they avoid areas that have extreme variations in monthly precipitation.\nWorldClim\n\n\nSolar radiation\nSolar radiation is a source of energy for algae and other organisms that green sea turtles eat.\nWorldClim\n\n\nWind speed\nWind can stir up sediment and make the water murky, which green sea turtles prefer to avoid.\nERA5\n\n\nWave height\nWave height can make it difficult for green sea turtles to feed and nest, so they avoid areas with high wave heights.\nERA5\n\n\nTurbidity\nTurbidity is the amount of suspended sediment in the water. Green sea turtles prefer clear water, so turbidity can be a useful predictor of their distribution.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nLight availability\nLight is essential for photosynthesis, which is the process that algae use to produce food. Green sea turtles eat algae, so light availability is an important factor in their distribution.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nOxygen concentration\nOxygen is essential for all life. Green sea turtles avoid areas with low oxygen concentrations.\nBio-ORACLE, ENVIREM, MARSPEC\n\n\nFood availability\nThe amount of food available to green sea turtles in an area is a major factor that influences their distribution. Green sea turtles eat a variety of organisms, including algae, seagrass, jellyfish, and fish.\nSurveys of sea turtle prey organisms\n\n\nPredation risk\nGreen sea turtles are preyed upon by a variety of animals, including sharks, crocodiles, and birds. The risk of predation can be a major factor that influences the distribution of green sea turtles.\nStudies of sea turtle predators\n\n\nHuman activity\nHuman activities, such as pollution, habitat destruction, and overfishing, can have a negative impact on the distribution of green sea turtles.\nGovernment reports and scientific studies\n\n\n\nWith this information in hands, we are now able to find these variables in the sdmpredictors."
  },
  {
    "objectID": "tutorial/03_sdmpredictors-variables.html#view-the-sdmpredictors-variables",
    "href": "tutorial/03_sdmpredictors-variables.html#view-the-sdmpredictors-variables",
    "title": "Marine SDM Variables",
    "section": "View the sdmpredictors variables",
    "text": "View the sdmpredictors variables\nsdmpredictors has many variables.\n\nlibrary(tidyverse)\nlibrary(DT)\nlibrary(sdmpredictors)\nlibrary(sf)\n\nThere are two marine data sources.\n\nenv_datasets <- list_datasets(terrestrial = FALSE, marine = TRUE)\nenv_datasets %>% \n  select(dataset_code, description, citation) %>% \n  DT::datatable()\n\n\n\n\n\n\n\nenv_datasets_vec <- c(\"Bio-ORACLE\", \"MARSPEC\")\nenv_layers <- sdmpredictors::list_layers(env_datasets_vec)\nDT::datatable(env_layers)\n\n\n\n\n\n\nFor this tutorial, we chose the “mean” variable from the sdmpredictors package for each marine environmental parameter recommended by Bard.\n\n\n\nVariable\nData source\n\n\n\n\nBathymetry\nBO_bathymean\n\n\nSea surface temperature\nBO2_tempmean_ss\n\n\nChlorophyll concentration\nBO2_chlomean_ss\n\n\nSalinity\nBO2_salinitymean_ss\n\n\nNitrate concentration\nBO21_nitratemean_ss\n\n\nDistance to shore\nMS_biogeo05_dist_shore_5m\n\n\nMean annual temperature\nMS_biogeo13_sst_mean_5m\n\n\nSolar radiation\nBO22_parmean\n\n\nTurbidity\nBO22_damean\n\n\nOxygen concentration\nBO2_dissoxmean_bdmean"
  },
  {
    "objectID": "tutorial/03_sdmpredictors-variables.html#extract-these-variables",
    "href": "tutorial/03_sdmpredictors-variables.html#extract-these-variables",
    "title": "Marine SDM Variables",
    "section": "Extract these variables",
    "text": "Extract these variables\nFirst we will load a bounding box for our area of interest. This was saved in []\n\n#Loading bounding box for the area of interest\nfil <- here::here(\"data\", \"region\", \"BoundingBox.shp\")\nextent_polygon <- read_sf(fil)\n\n#Extract polygon geometry \npol_geometry <- st_as_text(extent_polygon$geometry)\n\nThe objective is to extract all these variables for our presence and absence locations.\nWe will show this in the SDM examples. This is where the team ran into a numbers of hiccups."
  },
  {
    "objectID": "tutorial/04_models.html",
    "href": "tutorial/04_models.html",
    "title": "Marine Species Distribution Models",
    "section": "",
    "text": "Species distribution modeling (SDM) involves various statistical and machine learning techniques to predict the spatial distribution of species based on environmental variables. Some of the main models used for SDMs include:\n\nMaxent (Maximum Entropy Model): Maxent is a widely used model for SDMs. It aims to find the distribution that is the most spread out (has the highest entropy) while satisfying the constraints of observed species presences and environmental variables. It’s particularly useful when dealing with presence-only data. More on Maxent\nGLM (Generalized Linear Model): GLMs are a broad class of models that include linear regression as a special case. In the context of SDMs, GLMs can be extended to model species presence or absence based on environmental predictors.\nRandom Forest: Random Forest is an ensemble learning technique that builds multiple decision trees and combines their predictions. It’s robust and can handle complex interactions between variables, making it suitable for SDMs.\nBoosted Regression Trees (BRT): BRT is another ensemble method that combines multiple decision trees, but unlike Random Forest, it builds trees sequentially, with each tree trying to correct the errors of the previous one.\nSVM (Support Vector Machine): SVMs are used for classification tasks and can be adapted to predict species presence or absence based on environmental variables.\nANN (Artificial Neural Networks): Neural networks can capture complex relationships in the data and have been used for SDMs, particularly for large datasets.\nGAM (Generalized Additive Model): GAMs extend GLMs by allowing non-linear relationships between predictors and the response variable. They’re useful for capturing complex species-environment relationships.\nMaxlike (Maximum Likelihood Model): Maxlike models use maximum likelihood estimation to predict species distribution based on observed data and environmental predictors.\nMARS (Multivariate Adaptive Regression Splines): MARS models can capture non-linear relationships and interactions between predictors. They’re particularly useful when the relationships are complex and not well represented by linear models.\nSDMs with Hierarchical Models: Some researchers use hierarchical models, such as Bayesian models, to incorporate prior knowledge and uncertainty in SDMs.\n\nThe choice of model depends on the nature of your data, the assumptions you’re willing to make, the complexity of relationships, and the specific goals of your analysis. It’s often recommended to compare multiple models and evaluate their performance using appropriate metrics before deciding on the best model for your SDM."
  },
  {
    "objectID": "tutorial/04_models.html#maxent",
    "href": "tutorial/04_models.html#maxent",
    "title": "Marine Species Distribution Models",
    "section": "Maxent",
    "text": "Maxent\nThe Maxent algorithm, short for “Maximum Entropy,” is a machine learning technique used primarily for species distribution modeling. It’s designed to model the probability distribution of a species across geographic space based on environmental variables. Maxent aims to find the distribution that is the most spread out or has the highest entropy while satisfying a set of constraints provided by the available data.\nHere’s a high-level overview of how the Maxent algorithm works:\n\nInput Data: Maxent requires two main types of input data: presence data (locations where the species is known to occur) and environmental variables (such as temperature, precipitation, land cover, etc.). The presence data provides information about where the species has been observed.\nFeature Creation: Maxent uses the presence data to create a set of features (combinations of environmental variables) that represent the observed conditions at the presence locations.\nModel Training: The goal of Maxent is to find a probability distribution of environmental conditions that matches the observed presence locations while maximizing entropy (spreading out the distribution as much as possible). It’s formulated as a constrained optimization problem, where the model seeks to find the distribution that is closest to uniform (highest entropy) while satisfying constraints based on the presence data.\nRegularization: Maxent uses regularization to avoid overfitting the model to the presence data. Regularization adds a penalty for overly complex models. This helps prevent the model from fitting the noise in the presence data.\nProbability Prediction: Once the Maxent model is trained, it can be used to predict the probability of species presence across the entire study area based on the input environmental variables.\nModel Evaluation: The model’s predictive performance can be evaluated using various metrics, such as Area Under the Receiver Operating Characteristic Curve (AUC-ROC) or Area Under the Precision-Recall Curve (AUC-PR), which assess how well the model discriminates between presence and absence locations.\n\nMaxent is popular for species distribution modeling because it’s able to handle presence-only data (locations where the species is known to occur) and work with complex relationships between species and environmental variables. However, it’s important to note that Maxent models can still be subject to bias and limitations based on data quality and the assumptions of the algorithm."
  },
  {
    "objectID": "tutorial/Mackenzie_SDM_with_maxent.html",
    "href": "tutorial/Mackenzie_SDM_with_maxent.html",
    "title": "Maxent SDM attempt",
    "section": "",
    "text": "You will need to install a new version of maxnet for this tutorial.\n\ndevtools::install_github(\"BigelowLab/maxnet\")\n\n\nsuppressPackageStartupMessages({\nlibrary(maxnet)\nlibrary(dplyr)\nlibrary(maxnet)\nlibrary(sf)\nlibrary(stars)\nlibrary(geodata)\nlibrary(dismo)\nlibrary(lubridate)\nlibrary(sdmpredictors)\nlibrary(zoon)\nlibrary(ggplot2)\nlibrary(cmocean)\nlibrary(janitor)\nlibrary(DT)\n})\n\n\n\n\n\n# presence data\nio.turtles <- read.csv(\"/home/jovyan/R/ohw23_proj_marinesdms/data/raw-bio/io-sea-turtles.csv\") \n\n# absence data\npts.abs <- read.csv(\"/home/jovyan/R/ohw23_proj_marinesdms/data/raw-bio/pts_absence.csv\") # X is lon and Y is lat\n\n\n\n\n\nspp <- c(\"Chelonia mydas\", \"Caretta caretta\", \"Eretmochelys imbricata\", \"Lepidochelys olivacea\", \"Natator depressus\", \"Dermochelys coriacea\") # turtle species we're interested in\n\nocc <- io.turtles %>% \n  subset(scientificName == spp) # subsetting all the occurence data to just those turtles \n\ntable(occ$scientificName) # seeing how often each species occurs\n\n\n       Caretta caretta         Chelonia mydas Eretmochelys imbricata \n                   891                   1307                     36 \n Lepidochelys olivacea \n                     9 \n\nocc <- occ %>% # but we also need to subset the occurences to include just those in the water (not the ones on land)\n  subset(bathymetry > 0 & \n                        shoredistance > 0 & \n                        coordinateUncertaintyInMeters < 200)\n\ntable(occ$scientificName) # seeing how often each species occurs now\n\n\nCaretta caretta  Chelonia mydas \n            874            1190 \n\n# Caretta caretta is Loggerhead and Chelonia mydas is Green sea turtles \n\nocc.sub <- occ[,c(2,4,5,6,9,11,13,14)] # choosing the cols I want\n\nocc.sub$eventDate <- lubridate::ymd_hms(occ.sub$eventDate) # changing to datetime format\n\ncolnames(occ.sub) <- c(\"sci.name\", \"obsv.datetime\", \"lat\", \"lon\", \"life.stage\", \"bathy\", \"SST\", \"SSS\") # renaming\n\n\n# format background/absence points\n\ncolnames(pts.abs) <- c(\"lon\",\"lat\")\npts.abs <- na.omit(pts.abs)\n\nabs.points <- sf::st_as_sf(pts.abs, coords = c(\"lon\", \"lat\"), crs = 4326)\n\n\n# format prescence/occurrence points\n\nhead(occ.sub)\n\n          sci.name       obsv.datetime      lat      lon life.stage bathy   SST\n2  Caretta caretta 2011-04-12 19:12:41  6.40193 59.87883   Juvenile  3051 28.67\n7   Chelonia mydas 2018-03-31 06:44:00 24.50800 53.20100       <NA>    14 27.96\n13  Chelonia mydas 2019-05-28 12:15:00 24.57700 53.08300       <NA>     2 27.93\n14 Caretta caretta 2011-04-11 04:03:19 16.05778 54.28696   Juvenile  2736 26.92\n20 Caretta caretta 2011-03-24 14:33:23 16.52469 53.83602   Juvenile  2030 26.68\n25  Chelonia mydas 2018-04-05 23:33:00 24.54900 53.09200       <NA>     2 27.94\n     SSS\n2  35.74\n7  38.71\n13 38.65\n14 36.10\n20 36.05\n25 38.67\n\nocc.points <- sf::st_as_sf(occ.sub, coords = c(\"lon\", \"lat\"), crs = 4326)\nhead(occ.points)\n\nSimple feature collection with 6 features and 6 fields\nGeometry type: POINT\nDimension:     XY\nBounding box:  xmin: 53.083 ymin: 6.40193 xmax: 59.87883 ymax: 24.577\nGeodetic CRS:  WGS 84\n          sci.name       obsv.datetime life.stage bathy   SST   SSS\n2  Caretta caretta 2011-04-12 19:12:41   Juvenile  3051 28.67 35.74\n7   Chelonia mydas 2018-03-31 06:44:00       <NA>    14 27.96 38.71\n13  Chelonia mydas 2019-05-28 12:15:00       <NA>     2 27.93 38.65\n14 Caretta caretta 2011-04-11 04:03:19   Juvenile  2736 26.92 36.10\n20 Caretta caretta 2011-03-24 14:33:23   Juvenile  2030 26.68 36.05\n25  Chelonia mydas 2018-04-05 23:33:00       <NA>     2 27.94 38.67\n                    geometry\n2   POINT (59.87883 6.40193)\n7      POINT (53.201 24.508)\n13     POINT (53.083 24.577)\n14 POINT (54.28696 16.05778)\n20 POINT (53.83602 16.52469)\n25     POINT (53.092 24.549)\n\nocc.points <- occ.points %>% \n  mutate(common.name = case_when(sci.name == \"Caretta caretta\" ~ \"Loggerhead\",\n                                 sci.name == \"Chelonia mydas\" ~ \"Green\"))\n\n\n\n\n\n#Setting directories containing input data\ndir_env <- file.path(here::here(), \"data/env\")\n#Set default directory for environmental data\noptions(sdmpredictors_datadir = dir_env)\n\nLoading in\n\ndatasets <- sdmpredictors::list_datasets(terrestrial = FALSE, marine = TRUE)\n\nlayers <- list_layers(datasets)\n#View(layers)\n\nChoosing and formatting\n\nlayercodes = c(\"BO_sstmean\", \"BO_bathymean\", \"BO22_ph\", \"BO2_dissoxmean_bdmean\", \"BO2_salinitymean_ss\", \"BO2_chlomean_ss\", \"BO21_nitratemean_ss\") # the env variables I chose from SDMpredictors\n\nenv <- load_layers(layercodes, rasterstack = T) # take out the equalarea arg or you will be sad AND add rasterstack = T\nenv.stars <- stars::st_as_stars(env) # convert to stars object\nenv.stars <- split(env.stars)\n\nlats <- c(-0.125, 32.125); lons <- c(41.875, 70.125) # IO lat/lon range\n# raster extent is defined by west lon, east lon, south lat, north lat\n\next <- raster::extent(lons[1], lons[2], lats[1], lats[2])\nextent_polygon <- as(ext, \"SpatialPolygons\") %>% \n  st_as_sf()\n# we need to assign a coordinate system; 4326 is the default for maps in sf\nsf::st_crs(extent_polygon) <- 4326 # applying a coordinate system\n\nplot(extent_polygon) # look a special rectangle\n\n\n\nbb <- sf::st_bbox(extent_polygon) # make a bounding box \n\n# plot(env.stars[\"BO_bathymean\"] %>% sf::st_crop(bb)) # looking at bathymetry\n\nenv.obs <- stars::st_extract(env.stars,\n                             sf::st_coordinates(occ.points)) %>%\n  dplyr::as_tibble()\n\nio.rast <- raster::crop(env, extent(extent_polygon))\nplot(io.rast) # look NOT a rectangle- your env variables cropped to the Indian Ocean!\n\n\n\n\n\n\n\n\nenv.back <- stars::st_extract(env.stars, sf::st_coordinates(abs.points)) %>% \n  dplyr::as_tibble() %>% \n  na.omit()\n\nhead(env.back)\n\n# A tibble: 6 × 7\n  BO_sstmean BO_bathymean BO22_ph BO2_dissoxmean_bdmean BO2_sa…¹ BO2_c…² BO21_…³\n       <dbl>        <dbl>   <dbl>                 <dbl>    <dbl>   <dbl>   <dbl>\n1       28.4        -2445    8.16                  111.     36.2  0.213   0.192 \n2       26.9        -3142    8.12                  119.     36.5  0.110   0.0300\n3       28.3        -4549    8.19                  159.     36.0  0.0715  0.0129\n4       27.1        -4970    8.17                  180.     35.5  0.199   1.05  \n5       26.8        -3869    8.16                  156.     36.0  0.227   1.05  \n6       28.0        -5095    8.17                  183.     35.4  0.179   0.715 \n# … with abbreviated variable names ¹​BO2_salinitymean_ss, ²​BO2_chlomean_ss,\n#   ³​BO21_nitratemean_ss"
  },
  {
    "objectID": "tutorial/Mackenzie_SDM_with_maxent.html#sdm-model",
    "href": "tutorial/Mackenzie_SDM_with_maxent.html#sdm-model",
    "title": "Maxent SDM attempt",
    "section": "SDM Model",
    "text": "SDM Model\n\nRunning model\n\nenv.obs <- na.omit(env.obs); env.back <- na.omit(env.back) # remove NA values\n\npres <- c(rep(1, nrow(env.obs)), rep(0, nrow(env.back))) # create values of 1 for presence data and 0 for absence data\n\nsdm.model <- maxnet::maxnet(pres, rbind(env.obs, env.back))\n\n\n\nModel metrics\n\nresponses <- plot(sdm.model, type = \"cloglog\")"
  },
  {
    "objectID": "tutorial/Mackenzie_SDM_with_maxent.html#predicting",
    "href": "tutorial/Mackenzie_SDM_with_maxent.html#predicting",
    "title": "Maxent SDM attempt",
    "section": "Predicting",
    "text": "Predicting\n\nclamp <- TRUE       # see ?predict.maxnet for details\ntype <- \"cloglog\"\npredicted <- predict(sdm.model, env.stars %>% sf::st_crop(bb), clamp = clamp, type = type)\npredicted\n\nstars object with 2 dimensions and 1 attribute\nattribute(s):\n             Min.    1st Qu.    Median      Mean   3rd Qu.      Max.  NA's\npred  0.004169259 0.03760357 0.1309148 0.1481357 0.2085298 0.9996747 58655\ndimension(s):\n  from   to offset      delta                       refsys point values x/y\nx 2663 3002   -180  0.0833333 +proj=longlat +datum=WGS8...    NA   NULL [x]\ny  695 1082     90 -0.0833333 +proj=longlat +datum=WGS8...    NA   NULL [y]"
  },
  {
    "objectID": "tutorial/Mackenzie_SDM_with_maxent.html#visualization",
    "href": "tutorial/Mackenzie_SDM_with_maxent.html#visualization",
    "title": "Maxent SDM attempt",
    "section": "Visualization",
    "text": "Visualization\n\n# ggplot - with occurrence data points\n\nggplot() +\n  geom_stars(data = predicted) +\n  scale_fill_cmocean(name = \"ice\", direction = -1, guide = guide_colorbar(barwidth = 1, barheight = 10, ticks = FALSE, nbin = 1000, frame.colour = \"black\"), limits = c(0, 1)) +\n  theme_linedraw() +\n  theme(panel.background = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank()) +\n  labs(title = \"Loggerhead and green sea turtle SDM in the Arabian Sea\",\n       x = \"Longitude\",\n       y = \"Latitude\",\n       fill = \"Probability\",\n       shape = \"Species (presence)\",\n       subtitle = \"Environmental predictors: mean SS temp, mean SS salinity, mean bathymetry, \\nmean pH, mean DO, mean SS chlorophyll-a, mean SS nitrate\") +\n  geom_point(occ.points, mapping = aes(shape = common.name, geometry = geometry), stat = \"sf_coordinates\", alpha = 0.3, color = \"purple\") +\n  #scale_x_continuous(breaks = seq(40, 70, 10), limits = c(42, 70))+\n  scale_y_continuous(breaks = seq(0, 30, 10))\n\n\n\n# ggsave(\"SDM_loggerhead_green_w points.pdf\", height = 6, width = 8.5)\n\n\n# ggplot - without occurrence data points\n\nggplot() +\n  geom_stars(data = predicted) +\n  scale_fill_cmocean(name = \"ice\", direction = -1, guide = guide_colorbar(barwidth = 1, barheight = 10, ticks = FALSE, nbin = 1000, frame.colour = \"black\"), limits = c(0, 1)) +\n  theme_linedraw() +\n  theme(panel.background = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank()) +\n  labs(title = \"Loggerhead and green sea turtle SDM in the Arabian Sea\",\n       x = \"Longitude\",\n       y = \"Latitude\",\n       fill = \"Probability\",\n       shape = \"Species (presence)\",\n       subtitle = \"Environmental predictors: mean SS temp, mean SS salinity, mean bathymetry,\\nmean pH, mean DO, mean SS chlorophyll-a, mean SS nitrate\") +\n  #geom_point(occ.points, mapping = aes(shape = common.name, geometry = geometry), stat = \"sf_coordinates\", alpha = 0.3, color = \"purple\") +\n  #scale_x_continuous(breaks = seq(40, 70, 10), limits = c(42, 70))+\n  scale_y_continuous(breaks = seq(0, 30, 10))\n\n\n\n# ggsave(\"SDM_loggerhead_green.pdf\", height = 6, width = 8.5)\n\n\n# ggplot - with occurrence (purple) and absence (green) data points\n\nggplot() +\n  geom_stars(data = predicted) +\n  scale_fill_cmocean(name = \"ice\", direction = -1, guide = guide_colorbar(barwidth = 1, barheight = 10, ticks = FALSE, nbin = 1000, frame.colour = \"black\"), limits = c(0, 1)) +\n  theme_linedraw() +\n  theme(panel.background = element_blank(),\n        panel.grid.major = element_blank(),\n        panel.grid.minor = element_blank()) +\n  labs(title = \"Loggerhead and green sea turtle SDM in the Arabian Sea\",\n       x = \"Longitude\",\n       y = \"Latitude\",\n       fill = \"Probability\",\n       shape = \"Species (presence)\",\n       subtitle = \"Environmental predictors: mean SS temp, mean SS salinity, mean bathymetry, \\nmean pH, mean DO, mean SS chlorophyll-a, mean SS nitrate\") +\n  geom_point(occ.points, mapping = aes(shape = common.name, geometry = geometry), stat = \"sf_coordinates\", alpha = 0.3, color = \"purple\") +\n  #scale_x_continuous(breaks = seq(40, 70, 10), limits = c(42, 70))+\n  scale_y_continuous(breaks = seq(0, 30, 10)) +\n  geom_point(abs.points, mapping = aes(geometry = geometry), stat = \"sf_coordinates\", alpha = 0.3, color = \"green\") # adding in absence data"
  },
  {
    "objectID": "tutorial/Roadmap.html",
    "href": "tutorial/Roadmap.html",
    "title": "SDM Workflow",
    "section": "",
    "text": "Creating a Species Distribution Model (SDM) has five steps. In the “Background” section, we discuss these steps in the context of marine SDMs using the example of the Loggerhead sea turtle in the Arabian Sea. In the “Our workflow” section, we show the specific approaches that we used in OHW23. Then in the “Turtle SDMs” section, we show the SDMs created by the team.\n\nPresence Data\n\nobtain Loggerhead sea turtle (C. caretta) presence data from OBIS via robis\n\nBackground Points\n\ndiscusses three methods to create random background points within our area of interest\n\nEnvironmental Data\n\nshows how to obtain environmental predictors of interest using sdmpredictors\n\nModel\n\nrun species distribution model and predict using maxnet\n\nData Visualizations"
  },
  {
    "objectID": "tutorial/background.html",
    "href": "tutorial/background.html",
    "title": "Get background data",
    "section": "",
    "text": "We used the random samples within our region of interest to generate a file with the locations for our absences."
  },
  {
    "objectID": "tutorial/background.html#set-up",
    "href": "tutorial/background.html#set-up",
    "title": "Get background data",
    "section": "Set up",
    "text": "Set up\n\nlibrary(ggplot2)\nlibrary(sf)\n\nLinking to GEOS 3.11.1, GDAL 3.6.2, PROJ 9.1.0; sf_use_s2() is TRUE\n\nlibrary(\"rnaturalearth\")\nlibrary(\"rnaturalearthdata\")\n\n\nAttaching package: 'rnaturalearthdata'\n\n\nThe following object is masked from 'package:rnaturalearth':\n\n    countries110\n\nlibrary(raster)\n\nLoading required package: sp\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ dplyr     1.1.0     ✔ readr     2.1.4\n✔ forcats   1.0.0     ✔ stringr   1.5.0\n✔ lubridate 1.9.2     ✔ tibble    3.1.8\n✔ purrr     1.0.1     ✔ tidyr     1.3.0\n\n\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::extract() masks raster::extract()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ dplyr::select()  masks raster::select()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\n\n\ndir_data <- file.path(here::here(), \"data\", \"raw-bio\")\ndir_env <- file.path(here::here(), \"data\", \"env\")\nredo <- TRUE"
  },
  {
    "objectID": "tutorial/background.html#define-the-region-of-interest",
    "href": "tutorial/background.html#define-the-region-of-interest",
    "title": "Get background data",
    "section": "Define the region of interest",
    "text": "Define the region of interest\n\n# lon, lon, lat, lat\nlibrary(sf)\nlats <- c(-0.125, 32.125)\nlons <- c(41.875, 65.125)\n# raster extent is defined by west lon, east lon, south lat, north lat\next <- raster::extent(lons[1], lons[2], lats[1], lats[2])\nextent_polygon <- as(ext, \"SpatialPolygons\") %>% st_as_sf()\n# we need to assign a coordinate system; 4326 is the default for maps in sf\nsf::st_crs(extent_polygon)<-4326\n# convert to a WKT format\nwkt_geometry <- extent_polygon$geometry %>% st_as_text()\nwkt_geometry\n\n[1] \"POLYGON ((41.875 -0.125, 41.875 32.125, 65.125 32.125, 65.125 -0.125, 41.875 -0.125))\"\n\n\nMake a map of our region so we know we have the right area.\n\nworld <- ne_countries(scale = \"medium\", returnclass = \"sf\")\nggplot(data = world) + geom_sf() +\n  geom_sf(data = extent_polygon, color = \"red\", fill=NA)"
  },
  {
    "objectID": "tutorial/background.html#random-samples",
    "href": "tutorial/background.html#random-samples",
    "title": "Get background data",
    "section": "Random samples",
    "text": "Random samples\nThis is adapted from here.\n\nGet a marine raster layer\nWe just need one because we use this to sample lat/lons from the marine environment.\n\n# set a default data directory\noptions(sdmpredictors_datadir = dir_env)\n\n# choosing marine\nenv_datasets <- sdmpredictors::list_datasets(terrestrial = FALSE, marine = TRUE)\nenv_layers <- sdmpredictors::list_layers(\"MARSPEC\")\nenv_stack <- sdmpredictors::load_layers(\"MS_bathy_5m\")\nenv_stack <- env_stack %>% raster::crop(ext)\n\nPlot to check that the layer looks ok. This is bathymetry.\n\nplot(env_stack)\n\n\n\n\n\n\nNext we sample points from this\n\nnsamp <- 1000\nabsence <- dismo::randomPoints(env_stack[[1]], nsamp) %>% \n    as_tibble() %>% \n    st_as_sf(coords = c(\"x\", \"y\"), crs = 4326)\n\n\nmapview::mapview(absence, col.regions = \"gray\")\n\nWarning in cbind(`Feature ID` = fid, mat): number of rows of result is not a\nmultiple of vector length (arg 1)\n\n\n\n\n\n\n\nSave the absence locations to a file.\n\nabsence_geo <- file.path(dir_data, \"absence.geojson\")\npts_absence_csv <- file.path(dir_data, \"pts_absence.csv\")\nst_write(absence, pts_absence_csv, layer_options = \"GEOMETRY=AS_XY\", append=FALSE)\n\nDeleting layer `pts_absence' using driver `CSV'\nWriting layer `pts_absence' to data source \n  `/home/jovyan/R/ohw23_proj_marinesdms/data/raw-bio/pts_absence.csv' using driver `CSV'\noptions:        GEOMETRY=AS_XY \nUpdating existing layer pts_absence\nWriting 1000 features with 0 fields and geometry type Point."
  },
  {
    "objectID": "tutorial/maxent-sdm.html",
    "href": "tutorial/maxent-sdm.html",
    "title": "Marine Species Distribution Models",
    "section": "",
    "text": "This example steps through the process of presence-only modeling using the maxnet package. The example is based on the notes by Ben Tupper (Biglow Lab, Maine) https://github.com/BigelowLab/maxnet/wiki/stars"
  },
  {
    "objectID": "tutorial/maxent-sdm.html#step-1-define-the-region-of-interest",
    "href": "tutorial/maxent-sdm.html#step-1-define-the-region-of-interest",
    "title": "Marine Species Distribution Models",
    "section": "Step 1: Define the region of interest",
    "text": "Step 1: Define the region of interest\nWe are looking at the western Arabian Sea, Persian Gulf, Gulf of Oman, Gulf of Aden and Red Sea.\n\nlibrary(sf)\nlats <- c(-0.125, 32.125); lons <- c(41.875, 70.125)\n# raster extent is defined by west lon, east lon, south lat, north lat\next <- raster::extent(lons[1], lons[2], lats[1], lats[2])\nextent_polygon <- as(ext, \"SpatialPolygons\") %>% st_as_sf()\n# we need to assign a coordinate system; 4326 is the default for maps in sf\nsf::st_crs(extent_polygon)<-4326\n\nGet a polygon of the world.\n\nlibrary(\"rnaturalearth\")\nlibrary(\"rnaturalearthdata\")\n\n\nAttaching package: 'rnaturalearthdata'\n\n\nThe following object is masked from 'package:rnaturalearth':\n\n    countries110\n\nworld <- ne_countries(scale = \"medium\", returnclass = \"sf\")\n\nMake a map of our region with the polygon of interest. reference\n\nlibrary(ggplot2)\nlibrary(sf)\nggplot(data = world) +\n    geom_sf() + \n  geom_sf(data = extent_polygon, color = \"red\", fill=NA)"
  },
  {
    "objectID": "tutorial/maxent-sdm.html#step-2-load-the-occurrence-data",
    "href": "tutorial/maxent-sdm.html#step-2-load-the-occurrence-data",
    "title": "Marine Species Distribution Models",
    "section": "Step 2: Load the occurrence data",
    "text": "Step 2: Load the occurrence data\nThis was queried using the robis package.\nspp <- c(\"Chelonia mydas\", \"Caretta caretta\", \"Eretmochelys imbricata\", \"Lepidochelys olivacea\", \"Natator depressus\", \"Dermochelys coriacea\")\nwkt_geometry <- extent_polygon$geometry %>% st_as_text()\ndf <- occurrence(spp, startdate = as.Date(\"2000-01-01\"), geometry = wkt_geometry)\n\nspp <- \"Chelonia mydas\"\nfil <- file.path(here::here(), \"data\", \"raw-bio\", \"io-sea-turtles.csv\")\nocc <- read.csv(fil)\nocc <- occ %>% subset(scientificName == spp)\n\nLook at the column names\n\nlibrary(tidyverse)\n\n── Attaching core tidyverse packages ──────────────────────── tidyverse 2.0.0 ──\n✔ forcats 1.0.0     ✔ stringr 1.5.0\n✔ purrr   1.0.1     ✔ tibble  3.1.8\n✔ readr   2.1.4     ✔ tidyr   1.3.0\n── Conflicts ────────────────────────────────────────── tidyverse_conflicts() ──\n✖ tidyr::extract() masks raster::extract(), terra::extract()\n✖ dplyr::filter()  masks stats::filter()\n✖ dplyr::lag()     masks stats::lag()\n✖ raster::select() masks dplyr::select()\nℹ Use the \u001b]8;;http://conflicted.r-lib.org/\u0007conflicted package\u001b]8;;\u0007 to force all conflicts to become errors\n\ncolnames(occ)\n\n [1] \"occurrenceID\"                  \"scientificName\"               \n [3] \"dateIdentified\"                \"eventDate\"                    \n [5] \"decimalLatitude\"               \"decimalLongitude\"             \n [7] \"coordinateUncertaintyInMeters\" \"individualCount\"              \n [9] \"lifeStage\"                     \"sex\"                          \n[11] \"bathymetry\"                    \"shoredistance\"                \n[13] \"sst\"                           \"sss\"                          \n[15] \"date\"                         \n\n\nMake sure the turtle was at sea.\n\nocc <- occ %>% subset(bathymetry > 0 & \n                        shoredistance > 0 & \n                        coordinateUncertaintyInMeters < 200)\ndim(occ)\n\n[1] 7060   15\n\n\nChange the occurrence data into an sf object with a coordinate system. Add a date column with YYYY-MM-DD format.\n\nocc$date <- as.Date(occ$eventDate)\nocc.sf <- sf::st_as_sf(occ, coords = c(\"decimalLongitude\", \"decimalLatitude\"), crs = 4326)\n\nPlot the occurrence data\n\nlibrary(ggplot2)\nlibrary(\"ggspatial\")\nlibrary(\"sf\")\ntheme_set(theme_bw())\nworld <- st_make_valid(world)\nworld_points <- st_centroid(world)\n\nWarning in st_centroid.sf(world): st_centroid assumes attributes are constant\nover geometries of x\n\nworld_points <- cbind(world, st_coordinates(st_centroid(world$geometry)))\n\n\nplt <- ggplot(data = world) +\n    geom_sf(fill= \"antiquewhite\") +\n    geom_point(data = occ, aes(x=decimalLongitude, y=decimalLatitude), color = \"red\", size=0.1) +\n    annotation_scale(location = \"bl\", width_hint = 0.5) +\n    annotation_north_arrow(location = \"bl\", which_north = \"true\", \n        pad_x = unit(0.15, \"in\"), pad_y = unit(0.25, \"in\"),\n        style = north_arrow_fancy_orienteering) +\n    coord_sf(xlim = lons, ylim = lats) +\n    theme(panel.grid.major = element_line(color = gray(.5), linetype = \"dashed\", size = 0.5), panel.background = element_rect(fill = \"aliceblue\"))\n\nWarning: The `size` argument of `element_line()` is deprecated as of ggplot2 3.4.0.\nℹ Please use the `linewidth` argument instead.\n\nsf_use_s2(FALSE)\n\nSpherical geometry (s2) switched off\n\nplt + geom_text(data = world_points, aes(x=X, y=Y, label=name),\n          color = \"darkblue\", size=2, check_overlap = TRUE) +\n  xlab(\"longitude\") + ylab(\"latitude\") + \n  ggtitle(spp, subtitle = \"occurences since 2000\")\n\nScale on map varies by more than 10%, scale bar may be inaccurate"
  },
  {
    "objectID": "tutorial/maxent-sdm.html#use-the-sdmpredictors-package-to-assemble-predictor-variable-data",
    "href": "tutorial/maxent-sdm.html#use-the-sdmpredictors-package-to-assemble-predictor-variable-data",
    "title": "Marine Species Distribution Models",
    "section": "Use the sdmpredictors package to assemble predictor variable data",
    "text": "Use the sdmpredictors package to assemble predictor variable data"
  },
  {
    "objectID": "tutorial/maxent-sdm.html#collect-background-points-within-the-region-occupied-by-the-presence-points-using-sf-package",
    "href": "tutorial/maxent-sdm.html#collect-background-points-within-the-region-occupied-by-the-presence-points-using-sf-package",
    "title": "Marine Species Distribution Models",
    "section": "Collect background points within the region occupied by the presence points using sf package",
    "text": "Collect background points within the region occupied by the presence points using sf package"
  },
  {
    "objectID": "tutorial/maxent-sdm.html#model-and-predict-using-the-maxnet-package",
    "href": "tutorial/maxent-sdm.html#model-and-predict-using-the-maxnet-package",
    "title": "Marine Species Distribution Models",
    "section": "Model and predict using the maxnet package",
    "text": "Model and predict using the maxnet package"
  },
  {
    "objectID": "tutorial/occ_env.html",
    "href": "tutorial/occ_env.html",
    "title": "Get environmental data for the occurrence locationa",
    "section": "",
    "text": "We need to get a data frame with the environmental data for the occurrence locations."
  },
  {
    "objectID": "tutorial/occ_env.html#set-up",
    "href": "tutorial/occ_env.html#set-up",
    "title": "Get environmental data for the occurrence locationa",
    "section": "Set up",
    "text": "Set up\n\nlibrary(ggplot2)\nlibrary(sdmpredictors)\n\nSet the directory where we will save environmental data layers.\n\ndir_env <- here::here(\"data\", \"env\")\noptions(sdmpredictors_datadir = dir_env)"
  },
  {
    "objectID": "tutorial/occ_env.html#add-datasets",
    "href": "tutorial/occ_env.html#add-datasets",
    "title": "Get environmental data for the occurrence locationa",
    "section": "Add datasets",
    "text": "Add datasets\nWe will use the sdmpredictors R package which has marine data layers.\n\n# choose marine\nenv_datasets <- sdmpredictors::list_datasets(terrestrial = FALSE, marine = TRUE)"
  },
  {
    "objectID": "tutorial/occ_env.html#show-the-available-variables",
    "href": "tutorial/occ_env.html#show-the-available-variables",
    "title": "Get environmental data for the occurrence locationa",
    "section": "Show the available variables",
    "text": "Show the available variables\nThe dataframe is large. We will use the DT package to make the table pretty in html.\n\nenv_layers <- sdmpredictors::list_layers(env_datasets$dataset_code)\nDT::datatable(env_layers)"
  },
  {
    "objectID": "tutorial/occ_env.html#variables",
    "href": "tutorial/occ_env.html#variables",
    "title": "Get environmental data for the occurrence locationa",
    "section": "Variables",
    "text": "Variables\n#Loading in environmental marine data datasets <- list_datasets(terrestrial = FALSE, marine = TRUE) layers <- list_layers(datasets) #View(layers) layercodes <- c(“BO_sstmean”,“BO_salinity”) env <- load_layers(layercodes)"
  },
  {
    "objectID": "tutorial/seaturtle_robis.html",
    "href": "tutorial/seaturtle_robis.html",
    "title": "Get turtle data",
    "section": "",
    "text": "Here we download from OBIS using the robis package."
  },
  {
    "objectID": "tutorial/seaturtle_robis.html#step-1-define-the-region-of-interest",
    "href": "tutorial/seaturtle_robis.html#step-1-define-the-region-of-interest",
    "title": "Get turtle data",
    "section": "Step 1 define the region of interest",
    "text": "Step 1 define the region of interest\n\n# lon, lon, lat, lat\nlibrary(sf)\n\nLinking to GEOS 3.11.1, GDAL 3.6.2, PROJ 9.1.0; sf_use_s2() is TRUE\n\nlats <- c(-0.125, 32.125)\nlons <- c(41.875, 65.125)\n# raster extent is defined by west lon, east lon, south lat, north lat\next <- raster::extent(lons[1], lons[2], lats[1], lats[2])\nextent_polygon <- as(ext, \"SpatialPolygons\") %>% st_as_sf()\n# we need to assign a coordinate system; 4326 is the default for maps in sf\nsf::st_crs(extent_polygon)<-4326\n# convert to a WKT format\nwkt_geometry <- extent_polygon$geometry %>% st_as_text()\nwkt_geometry\n\n[1] \"POLYGON ((41.875 -0.125, 41.875 32.125, 65.125 32.125, 65.125 -0.125, 41.875 -0.125))\"\n\n\nMake a map of our region so we know we have the right area.\n\nlibrary(ggplot2)\nlibrary(sf)\nlibrary(\"rnaturalearth\")\nlibrary(\"rnaturalearthdata\")\n\n\nAttaching package: 'rnaturalearthdata'\n\n\nThe following object is masked from 'package:rnaturalearth':\n\n    countries110\n\nworld <- ne_countries(scale = \"medium\", returnclass = \"sf\")\nggplot(data = world) + geom_sf() +\n  geom_sf(data = extent_polygon, color = \"red\", fill=NA)"
  },
  {
    "objectID": "tutorial/seaturtle_robis.html#get-occurrence-data-from-robis",
    "href": "tutorial/seaturtle_robis.html#get-occurrence-data-from-robis",
    "title": "Get turtle data",
    "section": "Get occurrence data from robis",
    "text": "Get occurrence data from robis\nWe will download data for four sea turtles found in the Arabian sea and save to one file. We will use the occurrence() function in the robis package.\n\nlibrary(robis)\nspp <- c(\"Chelonia mydas\", \"Caretta caretta\", \"Eretmochelys imbricata\", \"Lepidochelys olivacea\", \"Natator depressus\", \"Dermochelys coriacea\")\n\nobs <- robis::occurrence(spp, startdate = as.Date(\"2000-01-01\"), geometry = wkt_geometry)\n\nThis has many columns that we don’t need. We reduced to fewer columns.\n\ncols.to.use <- c(\"occurrenceID\", \"scientificName\", \n                 \"dateIdentified\", \"eventDate\", \n                 \"decimalLatitude\", \"decimalLongitude\", \"coordinateUncertaintyInMeters\",\n                 \"individualCount\",\"lifeStage\", \"sex\",\n                 \"bathymetry\",  \"shoredistance\", \"sst\", \"sss\")\nobs <- obs[,cols.to.use]\n\nWe also added a cleaner date with YYYY-MM-DD format.\n\nobs$date <- as.Date(obs$eventDate)"
  },
  {
    "objectID": "tutorial/seaturtle_robis.html#save-our-data",
    "href": "tutorial/seaturtle_robis.html#save-our-data",
    "title": "Get turtle data",
    "section": "Save our data",
    "text": "Save our data\nSet up the file names\n\ndir_data <- here::here(\"data\", \"raw-bio\")\nfilname <- \"io-sea-turtles\"\nobs_csv <- file.path(dir_data, paste0(filname, \".csv\"))\nobs_geo <- file.path(dir_data, paste0(filname, \".geojson\"))\nobs_gpkg <- file.path(dir_data, paste0(filname, \".gpkg\"))\n\nChange the data frame to a sf dataframe.\n\nobs_sf <- obs %>% \n    sf::st_as_sf(\n      coords = c(\"decimalLongitude\", \"decimalLatitude\"),\n      crs = st_crs(4326))\n\nSave files in different formats to facilitate loading into geospatial packages.\n\nredo   <- TRUE\n\nif (!file.exists(obs_csv) | redo)  readr::write_csv(obs, obs_csv)\nif (!file.exists(obs_geo) | redo)  sf::write_sf(obs_sf, obs_geo, delete_dsn=TRUE)\nif (!file.exists(obs_gpkg) | redo)  sf::write_sf(obs_sf, obs_gpkg, delete_dsn=TRUE)\n\nLater we can reload our data as\n\ntmp <- sf::read_sf(obs_gpkg)\nclass(tmp)"
  }
]